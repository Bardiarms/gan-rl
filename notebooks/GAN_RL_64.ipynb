{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638cbfaf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/bardiarms/gan-rl.git\n",
    "%cd gan-rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2862d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio tqdm matplotlib pandas pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c9c9a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/content/drive/MyDrive/gan-rl-data\"\n",
    "RUN_DIR  = \"/content/drive/MyDrive/gan-rl-runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5110957",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ls -la \"$DATA_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DIR = \"/content/gan-rl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b70e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "print(\"DATA_DIR exists:\", os.path.exists(DATA_DIR))\n",
    "print(\"RUN_DIR:\", RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23908dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_ROOT = \"/content/cartoonset100k\"\n",
    "DATA_ROOT = \"/content/drive/MyDrive/gan-rl-data/cartoonset100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346636e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(DATA_ROOT)\n",
    "\n",
    "pairs, missing_meta, missing_img = [], [], []\n",
    "\n",
    "for d in sorted(data_root.iterdir()):\n",
    "\n",
    "    for png_path in d.glob(\"*.png\"):\n",
    "        csv_path = png_path.with_suffix(\".csv\")\n",
    "        if csv_path.exists():\n",
    "            pairs.append((str(png_path), str(csv_path), int(d.name)))   # If the pair exists, add them to pairs\n",
    "        else:\n",
    "            missing_meta.append(str(png_path))\n",
    "\n",
    "\n",
    "print(\"Total pairs:\", len(pairs))\n",
    "print(\"Missing CSV for PNG:\", len(missing_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(pairs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.sort(key=lambda x: x[0])  # sort by image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert we can open the first image + read first metadata line\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "img_path, meta_path, folder_id = pairs[0]\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "df = pd.read_csv(meta_path, header=None, names=[\"attr\", \"value\", \"max\"])\n",
    "\n",
    "print(\"Sample folder:\", folder_id)\n",
    "print(\"Image size:\", img.size)\n",
    "print(\"Metadata shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one metadata file\n",
    "def read_meta_csv(meta_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(meta_path, header=None, names=[\"attr\", \"value\", \"max\"])\n",
    "    # ensure types\n",
    "    df[\"attr\"] = df[\"attr\"].astype(str)\n",
    "    df[\"value\"] = df[\"value\"].astype(int)\n",
    "    df[\"max\"] = df[\"max\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ce6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buil a schema for one-hot encoding\n",
    "def build_schema(pairs, max_files=20):\n",
    "    # pairs: list of (img_path, meta_path, folder_id)\n",
    "    attr_to_num_classes = {}  # attr -> (max+1)\n",
    "    attr_order = []           # stable order of attrs as discovered\n",
    "\n",
    "    for i, (_, meta_path, _) in enumerate(pairs[:max_files]):\n",
    "        df = read_meta_csv(meta_path)\n",
    "        for _, row in df.iterrows():\n",
    "            attr = row[\"attr\"]\n",
    "            num_classes = row[\"max\"] + 1\n",
    "\n",
    "            if attr not in attr_to_num_classes:\n",
    "                attr_to_num_classes[attr] = num_classes\n",
    "                attr_order.append(attr)\n",
    "            else:\n",
    "                # keep the maximum seen (in case some files differ)\n",
    "                attr_to_num_classes[attr] = max(attr_to_num_classes[attr], num_classes)\n",
    "\n",
    "    # offsets for packing one big vector\n",
    "    offsets = {}\n",
    "    total_dim = 0\n",
    "    for attr in attr_order:\n",
    "        offsets[attr] = total_dim\n",
    "        total_dim += attr_to_num_classes[attr]\n",
    "\n",
    "    return attr_order, attr_to_num_classes, offsets, total_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efbdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_order, attr_to_num_classes, offsets, meta_dim = build_schema(pairs)\n",
    "print(\"num attributes:\", len(attr_order))\n",
    "print(\"meta vector dim:\", meta_dim)\n",
    "print(attr_order[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the schema (Run Once)\n",
    "\n",
    "import json\n",
    "\n",
    "schema = {\n",
    "    \"attr_order\": attr_order,\n",
    "    \"attr_to_num_classes\": attr_to_num_classes,\n",
    "    \"offsets\": offsets,\n",
    "    \"total_dim\": meta_dim,\n",
    "}\n",
    "\n",
    "SCHEMA_PATH = \"/content/drive/MyDrive/gan-rl-runs/meta_schema.json\"\n",
    "os.makedirs(os.path.dirname(SCHEMA_PATH), exist_ok=True)\n",
    "\n",
    "with open(SCHEMA_PATH, \"w\") as f:\n",
    "    json.dump(schema, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8387b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 64      # We convert 500*500 pixel images into 128*128.\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44da00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata and store them in pandas dataframe\n",
    "def read_meta(meta_path: str)-> pd.DataFrame:\n",
    "\n",
    "  df = pd.read_csv(meta_path, header=None, names=[\"attr\", \"value\", \"max\"])\n",
    "  df[\"attr\"] = df[\"attr\"].astype(str)\n",
    "  df[\"value\"] = df[\"value\"].astype(int)\n",
    "  df[\"max\"] = df[\"max\"].astype(int)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9892b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding\n",
    "def encode_onehot(meta_path: str,\n",
    "                  attr_to_num_classes: dict,\n",
    "                  offsets: dict,\n",
    "                  total_dim: int\n",
    "                  )-> torch.Tensor:\n",
    "\n",
    "    df = read_meta(meta_path)\n",
    "    vec = np.zeros((total_dim,), dtype=np.float32)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        attr = row[\"attr\"]\n",
    "        val = int(row[\"value\"])\n",
    "\n",
    "        if attr not in offsets:\n",
    "          continue\n",
    "\n",
    "        n = attr_to_num_classes[attr]\n",
    "        if val < 0 or val >= n:\n",
    "            val = max(0, min(val, n - 1))\n",
    "\n",
    "        vec[offsets[attr] + val] = 1.0\n",
    "\n",
    "    return torch.from_numpy(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartoonSetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, pairs, img_transform, meta_cache = None):\n",
    "        self.pairs = pairs\n",
    "        self.img_transform = img_transform\n",
    "        self.meta_cache = meta_cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, meta_path, folder_id = self.pairs[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.img_transform(img)\n",
    "\n",
    "        if self.meta_cache is not None:\n",
    "            meta = self.meta_cache[meta_path]\n",
    "            return img, meta, folder_id\n",
    "\n",
    "        else:\n",
    "            return img, folder_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640141c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720fa385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CartoonSetDataset(pairs=pairs, img_transform=img_transform)\n",
    "\n",
    "dl = DataLoader(\n",
    "    ds,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n",
    "imgs, folder_ids = next(iter(dl))\n",
    "print(\"imgs:\", imgs.shape, imgs.min().item(), imgs.max().item())\n",
    "#print(\"metas:\", metas.shape, metas.min().item(), metas.max().item())\n",
    "print(\"folder_ids:\", folder_ids[:8])\n",
    "#print(\"meta sums (first 8):\", metas[:8].sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src import models\n",
    "IMG_SIZE = 64\n",
    "Z_DIM = 128\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cuda\"\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edd349",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = models.Generator(z_dim=Z_DIM).to(DEVICE)\n",
    "D = models.Discriminator().to(DEVICE)\n",
    "\n",
    "imgs, folder_ids = next(iter(dl))  # from your existing DataLoader\n",
    "imgs = imgs.to(DEVICE)\n",
    "\n",
    "z = torch.randn(imgs.size(0), Z_DIM, device=DEVICE)\n",
    "fake = G(z)\n",
    "\n",
    "print(\"Real:\", imgs.shape, imgs.min().item(), imgs.max().item())\n",
    "print(\"Fake:\", fake.shape, fake.min().item(), fake.max().item())\n",
    "\n",
    "d_real = D(imgs)\n",
    "d_fake = D(fake.detach())\n",
    "\n",
    "print(\"D(real) shape:\", d_real.shape, \"min/max:\", d_real.min().item(), d_real.max().item())\n",
    "print(\"D(fake) shape:\", d_fake.shape, \"min/max:\", d_fake.min().item(), d_fake.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485dd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = models.Generator(z_dim=Z_DIM).to(DEVICE)\n",
    "D = models.Discriminator().to(DEVICE)\n",
    "\n",
    "imgs, folder_ids = next(iter(dl))  # from your existing DataLoader\n",
    "imgs = imgs.to(DEVICE)\n",
    "\n",
    "z = torch.randn(imgs.size(0), Z_DIM, device=DEVICE)\n",
    "fake = G(z)\n",
    "\n",
    "print(\"Real:\", imgs.shape, imgs.min().item(), imgs.max().item())\n",
    "print(\"Fake:\", fake.shape, fake.min().item(), fake.max().item())\n",
    "\n",
    "d_real = D(imgs)\n",
    "d_fake = D(fake.detach())\n",
    "\n",
    "print(\"D(real) shape:\", d_real.shape, \"min/max:\", d_real.min().item(), d_real.max().item())\n",
    "print(\"D(fake) shape:\", d_fake.shape, \"min/max:\", d_fake.min().item(), d_fake.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46d0ef",
   "metadata": {},
   "source": [
    "### Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecde02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize pixels for viewing\n",
    "def denorm(x):\n",
    "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_samples(G, step, fixed_z, out_dir, nrow=8):\n",
    "    G.eval()\n",
    "    fake = G(fixed_z)\n",
    "    grid = make_grid(denorm(fake), nrow=nrow)\n",
    "    path = os.path.join(out_dir, f\"step_{step:06d}.png\")\n",
    "    save_image(grid, path)\n",
    "    G.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ce45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian Noise to Discriminator's inputs\n",
    "def noise_sigma(step, sigma0=0.10, hold_steps=1500, decay_steps=4000):\n",
    "    if step < hold_steps:\n",
    "        return sigma0\n",
    "    t = (step - hold_steps) / decay_steps\n",
    "    return sigma0 * max(0.0, 1.0 - t)\n",
    "\n",
    "# Noise Helper\n",
    "def add_instance_noise(x, sigma):\n",
    "    if sigma <= 0:\n",
    "        return x\n",
    "    return x + sigma * torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd86037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(RUN_DIR: str,\n",
    "               iters: int,\n",
    "               SAMPLE_EVERY: int,\n",
    "               CHKPT_EVERY: int\n",
    "               )-> None:\n",
    "\n",
    "    SAMPLES_DIR = os.path.join(RUN_DIR, f\"samples_128_{iters}_iters\")\n",
    "    CHKPT_DIR = os.path.join(RUN_DIR, f\"checkpoints_128_{iters}_iters\")\n",
    "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "    os.makedirs(CHKPT_DIR, exist_ok=True)\n",
    "\n",
    "    fixed_z = torch.randn(64, Z_DIM, device=DEVICE)\n",
    "\n",
    "    G.train(); D.train()\n",
    "\n",
    "    step = 0\n",
    "    data_iter = iter(dl)\n",
    "\n",
    "    while step < iters:\n",
    "        try:\n",
    "            imgs, folder_ids = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(dl)\n",
    "            imgs, folder_ids = next(data_iter)\n",
    "\n",
    "        real = imgs.to(DEVICE, non_blocking=True)\n",
    "        B = real.size(0)\n",
    "\n",
    "        real_labels = torch.ones(B, device=DEVICE)\n",
    "        fake_labels = torch.zeros(B, device=DEVICE)\n",
    "\n",
    "\n",
    "        # ---Train Discriminator---\n",
    "\n",
    "        opt_D.zero_grad(set_to_none=True)\n",
    "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
    "\n",
    "        sigma = 0 #noise_sigma(step)\n",
    "\n",
    "\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "            fake = G(z)\n",
    "\n",
    "            real_in = add_instance_noise(real, sigma)\n",
    "            fake_in = add_instance_noise(fake.detach(), sigma)\n",
    "\n",
    "            logits_real = D(real_in)\n",
    "            logits_fake = D(fake_in)\n",
    "            loss_D_real = criterion(logits_real, real_labels)\n",
    "            loss_D_fake = criterion(logits_fake, fake_labels)\n",
    "            loss_D = loss_D_real + loss_D_fake\n",
    "\n",
    "        scaler_D.scale(loss_D).backward()\n",
    "        scaler_D.step(opt_D)\n",
    "        scaler_D.update()\n",
    "\n",
    "\n",
    "        # -------------------------\n",
    "        # Train Generator\n",
    "        # -------------------------\n",
    "        # for _ in range(2):          # Generator updates twice as Discriminator\n",
    "        opt_G.zero_grad(set_to_none=True)\n",
    "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
    "\n",
    "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "            fake = G(z)\n",
    "            #fake_in = add_instance_noise(fake, sigma)\n",
    "            logits_fake_for_G = D(fake)\n",
    "            loss_G = criterion(logits_fake_for_G, real_labels)\n",
    "\n",
    "        scaler_G.scale(loss_G).backward()\n",
    "        scaler_G.step(opt_G)\n",
    "        scaler_G.update()\n",
    "\n",
    "        # Logging\n",
    "        if step % 10 == 0:\n",
    "            print(\n",
    "                f\"step {step:04d} | \"\n",
    "                f\"loss_D {loss_D.item():.4f} (r {loss_D_real.item():.4f}, f {loss_D_fake.item():.4f}) | \"\n",
    "                f\"loss_G {loss_G.item():.4f} | \"\n",
    "                f\"D(real) {logits_real.mean().item():+.3f} | D(fake) {logits_fake.mean().item():+.3f}\"\n",
    "            )\n",
    "\n",
    "        # Save samples\n",
    "        if step % SAMPLE_EVERY == 0:\n",
    "            save_samples(G, step, fixed_z, out_dir = SAMPLES_DIR)\n",
    "\n",
    "        # Save checkpoints (optional)\n",
    "        if step > 0 and step % CHKPT_EVERY == 0:\n",
    "            ckpt_path = os.path.join(CHKPT_DIR, f\"gan_step_{step:06d}.pt\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"G\": G.state_dict(),\n",
    "                    \"D\": D.state_dict(),\n",
    "                    \"opt_G\": opt_G.state_dict(),\n",
    "                    \"opt_D\": opt_D.state_dict(),\n",
    "                    \"scaler\": scaler.state_dict(),\n",
    "                },\n",
    "                ckpt_path,\n",
    "            )\n",
    "\n",
    "        step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50beb89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_func(RUN_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters\", iters = 12000, SAMPLE_EVERY = 500, CHKPT_EVERY = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f0f0e",
   "metadata": {},
   "source": [
    "# Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "def denorm(x):\n",
    "    # [-1, 1] -> [0, 1]\n",
    "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_random_grid(G, step, out_dir, z_dim, n=64, nrow=8, device=\"cuda\"):\n",
    "    G.eval()\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    z = torch.randn(n, z_dim, device=device)      # fresh random z\n",
    "    fake = G(z)                                   # [n, 3, H, W] in [-1,1]\n",
    "    grid = make_grid(denorm(fake), nrow=nrow)\n",
    "\n",
    "    path = os.path.join(out_dir, f\"random_step_{step:06d}.png\")\n",
    "    save_image(grid, path)\n",
    "\n",
    "    G.train()\n",
    "    print(\"Saved:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0fc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/samples_128_12000_iters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_random_grid(G, step=500, out_dir=SAMPLES_DIR, z_dim=Z_DIM, device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
