{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "638cbfaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "638cbfaf",
        "outputId": "416e1ba4-dd0d-4a62-9aa0-acdfbdce9bb3",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'gan-rl'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 78 (delta 37), reused 60 (delta 21), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (78/78), 471.91 KiB | 8.43 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "/content/gan-rl\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bardiarms/gan-rl.git\n",
        "%cd gan-rl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5bd6faac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bd6faac",
        "outputId": "5a3df850-61e4-43a3-aefb-8ef381495c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2862d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2862d9",
        "outputId": "0377e089-c6b8-423e-8bc0-dc6f7541d594",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio tqdm matplotlib pandas pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e33c9c9a",
      "metadata": {
        "id": "e33c9c9a",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/gan-rl-data\"\n",
        "RUN_DIR  = \"/content/drive/MyDrive/gan-rl-runs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6f45a59c",
      "metadata": {
        "id": "6f45a59c"
      },
      "outputs": [],
      "source": [
        "REPO_DIR = \"/content/gan-rl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "68b70e02",
      "metadata": {
        "id": "68b70e02"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c1e8668c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1e8668c",
        "outputId": "13361572-579d-4b03-96ee-9bf9bac16c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA_DIR exists: True\n",
            "RUN_DIR: /content/drive/MyDrive/gan-rl-runs\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "print(\"DATA_DIR exists:\", os.path.exists(DATA_DIR))\n",
        "print(\"RUN_DIR:\", RUN_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "23908dec",
      "metadata": {
        "id": "23908dec"
      },
      "outputs": [],
      "source": [
        "# DATA_ROOT = \"/content/cartoonset100k\"\n",
        "DATA_ROOT = \"/content/drive/MyDrive/gan-rl-data/cartoonset100k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "346636e5",
      "metadata": {
        "id": "346636e5"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b191e94",
      "metadata": {
        "id": "6b191e94"
      },
      "source": [
        "### Storing images, corresponding metadata and their directory name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c08e470f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c08e470f",
        "outputId": "6d3be2d3-d5d5-429d-b51d-7a3729e7447d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pairs: 100000\n",
            "Missing CSV for PNG: 17\n"
          ]
        }
      ],
      "source": [
        "data_root = Path(DATA_ROOT)\n",
        "\n",
        "pairs, missing_meta, missing_img = [], [], []\n",
        "\n",
        "for d in sorted(data_root.iterdir()):\n",
        "\n",
        "    for png_path in d.glob(\"*.png\"):\n",
        "        csv_path = png_path.with_suffix(\".csv\")\n",
        "        if csv_path.exists():\n",
        "            pairs.append((str(png_path), str(csv_path), int(d.name)))   # If the pair exists, add them to pairs\n",
        "        else:\n",
        "            missing_meta.append(str(png_path))\n",
        "\n",
        "\n",
        "print(\"Total pairs:\", len(pairs))\n",
        "print(\"Missing CSV for PNG:\", len(missing_meta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b087efec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b087efec",
        "outputId": "05dda2b2-f070-4420-bb26-5e6c4619c0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12694632614924764393.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12694632614924764393.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12110888894984629978.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12110888894984629978.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12783151780612292884.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12783151780612292884.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1182038763634098519.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1182038763634098519.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1213446833171185255.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1213446833171185255.csv', 0)\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(pairs[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "98f1e97e",
      "metadata": {
        "id": "98f1e97e"
      },
      "outputs": [],
      "source": [
        "pairs.sort(key=lambda x: x[0])  # sort by image path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2x3O3KmwFqCH",
      "metadata": {
        "id": "2x3O3KmwFqCH"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3b8387b9",
      "metadata": {
        "id": "3b8387b9"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1fce0614",
      "metadata": {
        "id": "1fce0614"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMG_SIZE = 64      # We convert 500*500 pixel images into 64*64.\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4a2e261a",
      "metadata": {
        "id": "4a2e261a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d44da00d",
      "metadata": {
        "id": "d44da00d"
      },
      "outputs": [],
      "source": [
        "# Read metadata and store them in pandas dataframe\n",
        "def read_meta(meta_path: str)-> pd.DataFrame:\n",
        "\n",
        "  df = pd.read_csv(meta_path, header=None, names=[\"attr\", \"value\", \"max\"])\n",
        "  df[\"attr\"] = df[\"attr\"].astype(str)\n",
        "  df[\"value\"] = df[\"value\"].astype(int)\n",
        "  df[\"max\"] = df[\"max\"].astype(int)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb9892b8",
      "metadata": {
        "id": "bb9892b8"
      },
      "outputs": [],
      "source": [
        "# Apply one-hot encoding\n",
        "def encode_onehot(meta_path: str,\n",
        "                  attr_to_num_classes: dict,\n",
        "                  offsets: dict,\n",
        "                  total_dim: int\n",
        "                  )-> torch.Tensor:\n",
        "\n",
        "    df = read_meta(meta_path)\n",
        "    vec = np.zeros((total_dim,), dtype=np.float32)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        attr = row[\"attr\"]\n",
        "        val = int(row[\"value\"])\n",
        "\n",
        "        if attr not in offsets:\n",
        "          continue\n",
        "\n",
        "        n = attr_to_num_classes[attr]\n",
        "        if val < 0 or val >= n:\n",
        "            val = max(0, min(val, n - 1))\n",
        "\n",
        "        vec[offsets[attr] + val] = 1.0\n",
        "\n",
        "    return torch.from_numpy(vec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3ba9243e",
      "metadata": {
        "id": "3ba9243e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7e51057e",
      "metadata": {
        "id": "7e51057e"
      },
      "outputs": [],
      "source": [
        "class CartoonSetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, pairs, img_transform, meta_cache = None):\n",
        "        self.pairs = pairs\n",
        "        self.img_transform = img_transform\n",
        "        self.meta_cache = meta_cache\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, meta_path, folder_id = self.pairs[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = self.img_transform(img)\n",
        "\n",
        "        if self.meta_cache is not None:\n",
        "            meta = self.meta_cache[meta_path]\n",
        "            return img, meta, folder_id\n",
        "\n",
        "        else:\n",
        "            return img, folder_id\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "640141c8",
      "metadata": {
        "id": "640141c8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "720fa385",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720fa385",
        "outputId": "605242a8-1d21-4464-9647-a6c2c1393827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imgs: torch.Size([4, 3, 64, 64]) -1.0 1.0\n",
            "folder_ids: tensor([1, 4, 6, 3])\n"
          ]
        }
      ],
      "source": [
        "ds = CartoonSetDataset(pairs=pairs, img_transform=img_transform)\n",
        "\n",
        "dl = DataLoader(\n",
        "    ds,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=False\n",
        ")\n",
        "imgs, folder_ids = next(iter(dl))\n",
        "print(\"imgs:\", imgs.shape, imgs.min().item(), imgs.max().item())\n",
        "print(\"folder_ids:\", folder_ids[:8])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1a408e",
      "metadata": {
        "id": "bc1a408e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from model_artifacts import models      \n",
        "IMG_SIZE = 64\n",
        "Z_DIM = 128\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda\"\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0edd349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0edd349",
        "outputId": "f1ec16c4-4cf9-4624-a406-ea408f9a517a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Real: torch.Size([4, 3, 64, 64]) -0.9607843160629272 1.0\n",
            "Fake: torch.Size([4, 3, 64, 64]) -0.9999998807907104 0.9999997019767761\n",
            "D(real) shape: torch.Size([4]) min/max: -0.09946166723966599 -0.0696922019124031\n",
            "D(fake) shape: torch.Size([4]) min/max: -0.13368116319179535 -0.022538205608725548\n"
          ]
        }
      ],
      "source": [
        "G = models.Generator_64(z_dim=Z_DIM).to(DEVICE)\n",
        "D = models.Discriminator_64().to(DEVICE)\n",
        "\n",
        "imgs, folder_ids = next(iter(dl))  # from your existing DataLoader\n",
        "imgs = imgs.to(DEVICE)\n",
        "\n",
        "z = torch.randn(imgs.size(0), Z_DIM, device=DEVICE)\n",
        "fake = G(z)\n",
        "\n",
        "print(\"Real:\", imgs.shape, imgs.min().item(), imgs.max().item())\n",
        "print(\"Fake:\", fake.shape, fake.min().item(), fake.max().item())\n",
        "\n",
        "d_real = D(imgs)\n",
        "d_fake = D(fake.detach())\n",
        "\n",
        "print(\"D(real) shape:\", d_real.shape, \"min/max:\", d_real.min().item(), d_real.max().item())\n",
        "print(\"D(fake) shape:\", d_fake.shape, \"min/max:\", d_fake.min().item(), d_fake.max().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bbf079a",
      "metadata": {
        "id": "2bbf079a"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "lr_G = 2e-4\n",
        "lr_D = 1e-4\n",
        "beta1, beta2 = 0.5, 0.999\n",
        "\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "\n",
        "use_amp = True\n",
        "scaler_D = torch.amp.GradScaler(device=\"cuda\", enabled=use_amp)\n",
        "scaler_G = torch.amp.GradScaler(device=\"cuda\", enabled=use_amp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb46d0ef",
      "metadata": {
        "id": "eb46d0ef"
      },
      "source": [
        "### Train GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd7ff95",
      "metadata": {
        "id": "afd7ff95"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid, save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecde02e",
      "metadata": {
        "id": "0ecde02e"
      },
      "outputs": [],
      "source": [
        "# Denormalize pixels to [0,255]\n",
        "def denorm(x):\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_samples(G, step, fixed_z, out_dir, nrow=8):\n",
        "    G.eval()\n",
        "    fake = G(fixed_z)\n",
        "    grid = make_grid(denorm(fake), nrow=nrow)\n",
        "    path = os.path.join(out_dir, f\"step_{step:06d}.png\")\n",
        "    save_image(grid, path)\n",
        "    G.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "469ce45f",
      "metadata": {
        "id": "469ce45f"
      },
      "outputs": [],
      "source": [
        "# Add Gaussian Noise to Discriminator's inputs\n",
        "def noise_sigma(step, sigma0=0.10, hold_steps=1500, decay_steps=4000):\n",
        "    if step < hold_steps:\n",
        "        return sigma0\n",
        "    t = (step - hold_steps) / decay_steps\n",
        "    return sigma0 * max(0.0, 1.0 - t)\n",
        "\n",
        "# Noise Helper\n",
        "def add_instance_noise(x, sigma):\n",
        "    if sigma <= 0:\n",
        "        return x\n",
        "    return x + sigma * torch.randn_like(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd86037",
      "metadata": {
        "id": "6dd86037"
      },
      "outputs": [],
      "source": [
        "def train_func(RUN_DIR: str,\n",
        "               iters: int,\n",
        "               SAMPLE_EVERY: int,\n",
        "               CHKPT_EVERY: int\n",
        "               )-> None:\n",
        "\n",
        "    SAMPLES_DIR = os.path.join(RUN_DIR, f\"samples_128_{iters}_iters\")\n",
        "    CHKPT_DIR = os.path.join(RUN_DIR, f\"checkpoints_128_{iters}_iters\")\n",
        "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
        "    os.makedirs(CHKPT_DIR, exist_ok=True)\n",
        "\n",
        "    fixed_z = torch.randn(64, Z_DIM, device=DEVICE)\n",
        "\n",
        "    G.train(); D.train()\n",
        "\n",
        "    step = 0\n",
        "    data_iter = iter(dl)\n",
        "\n",
        "    while step < iters:\n",
        "        try:\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(dl)\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "\n",
        "        real = imgs.to(DEVICE, non_blocking=True)\n",
        "        B = real.size(0)\n",
        "\n",
        "        real_labels = torch.ones(B, device=DEVICE)\n",
        "        fake_labels = torch.zeros(B, device=DEVICE)\n",
        "\n",
        "\n",
        "        # ---Train Discriminator---\n",
        "\n",
        "        opt_D.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        sigma = 0\n",
        "\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "\n",
        "            real_in = add_instance_noise(real, sigma)\n",
        "            fake_in = add_instance_noise(fake.detach(), sigma)\n",
        "\n",
        "            logits_real = D(real_in)\n",
        "            logits_fake = D(fake_in)\n",
        "            loss_D_real = criterion(logits_real, real_labels)\n",
        "            loss_D_fake = criterion(logits_fake, fake_labels)\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "\n",
        "        scaler_D.scale(loss_D).backward()\n",
        "        scaler_D.step(opt_D)\n",
        "        scaler_D.update()\n",
        "\n",
        "\n",
        "        # ---Train Generator---\n",
        "\n",
        "        opt_G.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "\n",
        "            logits_fake_for_G = D(fake)\n",
        "            loss_G = criterion(logits_fake_for_G, real_labels)\n",
        "\n",
        "        scaler_G.scale(loss_G).backward()\n",
        "        scaler_G.step(opt_G)\n",
        "        scaler_G.update()\n",
        "\n",
        "        # Logging\n",
        "        if step % 10 == 0:\n",
        "            print(\n",
        "                f\"step {step:04d} | \"\n",
        "                f\"loss_D {loss_D.item():.4f} (r {loss_D_real.item():.4f}, f {loss_D_fake.item():.4f}) | \"\n",
        "                f\"loss_G {loss_G.item():.4f} | \"\n",
        "                f\"D(real) {logits_real.mean().item():+.3f} | D(fake) {logits_fake.mean().item():+.3f}\"\n",
        "            )\n",
        "\n",
        "        # Save samples\n",
        "        if step % SAMPLE_EVERY == 0:\n",
        "            save_samples(G, step, fixed_z, out_dir = SAMPLES_DIR)\n",
        "\n",
        "        # Save checkpoints\n",
        "        if step > 0 and step % CHKPT_EVERY == 0:\n",
        "            ckpt_path = os.path.join(CHKPT_DIR, f\"gan_step_{step:06d}.pt\")\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"step\": step,\n",
        "                    \"G\": G.state_dict(),\n",
        "                    \"D\": D.state_dict(),\n",
        "                    \"opt_G\": opt_G.state_dict(),\n",
        "                    \"opt_D\": opt_D.state_dict(),\n",
        "                    \"scaler_D\": scaler_D.state_dict(),\n",
        "                    \"scaler_G\": scaler_G.state_dict(),\n",
        "                },\n",
        "                ckpt_path,\n",
        "            )\n",
        "\n",
        "        step += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50beb89d",
      "metadata": {
        "id": "50beb89d"
      },
      "outputs": [],
      "source": [
        "train_func(RUN_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters\", iters = 12000, SAMPLE_EVERY = 500, CHKPT_EVERY = 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NMqjHZwaLIMV",
      "metadata": {
        "id": "NMqjHZwaLIMV"
      },
      "source": [
        "## Resume Train From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ivGByHbxLM5q",
      "metadata": {
        "id": "ivGByHbxLM5q"
      },
      "outputs": [],
      "source": [
        "\n",
        "def resume_from_ckpt(\n",
        "    ckpt_path: str,\n",
        "    total_iters: int,\n",
        "    RUN_DIR: str,\n",
        "    SAMPLE_EVERY: int,\n",
        "    CHKPT_EVERY: int,\n",
        "    dl,\n",
        "    G,\n",
        "    D,\n",
        "    opt_G,\n",
        "    opt_D,\n",
        "    criterion,\n",
        "    save_samples,\n",
        "    DEVICE=\"cuda\",\n",
        "    Z_DIM=128,\n",
        "    use_amp=True,\n",
        "    scaler_D=None,\n",
        "    scaler_G=None\n",
        "):\n",
        "    # ---- load ----\n",
        "    ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
        "    G.load_state_dict(ckpt[\"G\"])\n",
        "    D.load_state_dict(ckpt[\"D\"])\n",
        "    opt_G.load_state_dict(ckpt[\"opt_G\"])\n",
        "    opt_D.load_state_dict(ckpt[\"opt_D\"])\n",
        "\n",
        "    start_step = int(ckpt.get(\"step\", 0)) + 1\n",
        "\n",
        "\n",
        "    if \"scaler_D\" in ckpt and ckpt[\"scaler_D\"] is not None:\n",
        "        try:\n",
        "            scaler_D.load_state_dict(ckpt[\"scaler_D\"])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if \"scaler_G\" in ckpt and ckpt[\"scaler_G\"] is not None:\n",
        "        try:\n",
        "            scaler_G.load_state_dict(ckpt[\"scaler_G\"])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # ---- dirs ----\n",
        "    SAMPLES_DIR = os.path.join(RUN_DIR, f\"samples_64_{total_iters}_iters\")\n",
        "    CKPT_DIR    = os.path.join(RUN_DIR, f\"checkpoints_64_{total_iters}_iters\")\n",
        "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
        "    os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "    print(f\"âœ… Loaded: {ckpt_path}\")\n",
        "    print(f\"â–¶ï¸ Resume: step {start_step} -> {total_iters-1}\")\n",
        "\n",
        "    fixed_z = torch.randn(64, Z_DIM, device=DEVICE)\n",
        "\n",
        "    G.train(); D.train()\n",
        "    step = start_step\n",
        "    data_iter = iter(dl)\n",
        "\n",
        "    while step < total_iters:\n",
        "        try:\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(dl)\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "\n",
        "        real = imgs.to(DEVICE, non_blocking=True)\n",
        "        B = real.size(0)\n",
        "\n",
        "        real_labels = torch.ones(B, device=DEVICE)\n",
        "        fake_labels = torch.zeros(B, device=DEVICE)\n",
        "\n",
        "\n",
        "        # ---Train Discriminator---\n",
        "\n",
        "        opt_D.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        sigma = 0\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "\n",
        "            real_in = add_instance_noise(real, sigma)\n",
        "            fake_in = add_instance_noise(fake.detach(), sigma)\n",
        "\n",
        "            logits_real = D(real_in)\n",
        "            logits_fake = D(fake_in)\n",
        "            loss_D_real = criterion(logits_real, real_labels)\n",
        "            loss_D_fake = criterion(logits_fake, fake_labels)\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "\n",
        "        scaler_D.scale(loss_D).backward()\n",
        "        scaler_D.step(opt_D)\n",
        "        scaler_D.update()\n",
        "\n",
        "\n",
        "\n",
        "        # ---Train Generator---\n",
        "\n",
        "        opt_G.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "\n",
        "            logits_fake_for_G = D(fake)\n",
        "            loss_G = criterion(logits_fake_for_G, real_labels)\n",
        "\n",
        "        scaler_G.scale(loss_G).backward()\n",
        "        scaler_G.step(opt_G)\n",
        "        scaler_G.update()\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(\n",
        "                f\"step {step:04d} | loss_D {loss_D.item():.4f} | loss_G {loss_G.item():.4f} | \"\n",
        "                f\"D(real) {logits_real.mean().item():+.3f} | D(fake) {logits_fake.mean().item():+.3f}\"\n",
        "            )\n",
        "\n",
        "        if step % SAMPLE_EVERY == 0:\n",
        "            save_samples(G, step, fixed_z, out_dir=SAMPLES_DIR)\n",
        "\n",
        "        if step > 0 and step % CHKPT_EVERY == 0:\n",
        "            out_path = os.path.join(CKPT_DIR, f\"gan_step_{step:06d}.pt\")\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"step\": step,\n",
        "                    \"G\": G.state_dict(),\n",
        "                    \"D\": D.state_dict(),\n",
        "                    \"opt_G\": opt_G.state_dict(),\n",
        "                    \"opt_D\": opt_D.state_dict(),\n",
        "                    \"scaler_D\": scaler_D.state_dict(),\n",
        "                    \"scaler_G\": scaler_G.state_dict(),\n",
        "                },\n",
        "                out_path,\n",
        "            )\n",
        "            print(\"ðŸ’¾ Saved:\", out_path)\n",
        "\n",
        "        step += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iMnL1vOcLl88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMnL1vOcLl88",
        "outputId": "dca795f9-379c-4957-9465-393d43007d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_128_12000_iters/gan_step_002500.pt\n",
            "â–¶ï¸ Resume: step 2501 -> 11999\n",
            "step 2510 | loss_D 1.2668 | loss_G 0.7779 | D(real) +0.051 | D(fake) -0.241\n",
            "step 2520 | loss_D 0.8847 | loss_G 1.1308 | D(real) +1.030 | D(fake) -0.321\n",
            "step 2530 | loss_D 0.8540 | loss_G 1.2237 | D(real) +0.876 | D(fake) -0.459\n",
            "step 2540 | loss_D 1.2627 | loss_G 1.0067 | D(real) -0.065 | D(fake) -0.349\n",
            "step 2550 | loss_D 1.3379 | loss_G 0.7821 | D(real) +0.273 | D(fake) +0.090\n",
            "step 2560 | loss_D 1.4662 | loss_G 0.8350 | D(real) -0.111 | D(fake) +0.026\n",
            "step 2570 | loss_D 1.4360 | loss_G 0.9077 | D(real) -0.210 | D(fake) -0.173\n",
            "step 2580 | loss_D 1.2204 | loss_G 1.0562 | D(real) +0.464 | D(fake) +0.014\n",
            "step 2590 | loss_D 1.4519 | loss_G 0.9529 | D(real) -0.163 | D(fake) -0.081\n",
            "step 2600 | loss_D 1.0611 | loss_G 0.9488 | D(real) +0.577 | D(fake) -0.197\n",
            "step 2610 | loss_D 1.4531 | loss_G 0.8496 | D(real) -0.121 | D(fake) -0.003\n",
            "step 2620 | loss_D 1.5839 | loss_G 0.8463 | D(real) -0.333 | D(fake) -0.019\n",
            "step 2630 | loss_D 1.6198 | loss_G 1.1080 | D(real) +0.156 | D(fake) +0.431\n",
            "step 2640 | loss_D 1.1308 | loss_G 1.0118 | D(real) +0.820 | D(fake) +0.108\n",
            "step 2650 | loss_D 1.4528 | loss_G 1.1306 | D(real) -0.198 | D(fake) -0.123\n",
            "step 2660 | loss_D 1.2787 | loss_G 0.9003 | D(real) -0.123 | D(fake) -0.406\n",
            "step 2670 | loss_D 1.2577 | loss_G 0.7465 | D(real) +0.506 | D(fake) +0.126\n",
            "step 2680 | loss_D 1.3906 | loss_G 0.8725 | D(real) +0.227 | D(fake) +0.153\n",
            "step 2690 | loss_D 1.5941 | loss_G 1.2928 | D(real) -0.837 | D(fake) -0.774\n",
            "step 2700 | loss_D 1.1631 | loss_G 0.8657 | D(real) +0.612 | D(fake) -0.115\n",
            "step 2710 | loss_D 1.3758 | loss_G 0.9802 | D(real) -0.031 | D(fake) -0.058\n",
            "step 2720 | loss_D 1.1337 | loss_G 0.9134 | D(real) +0.488 | D(fake) -0.159\n",
            "step 2730 | loss_D 1.3521 | loss_G 0.8270 | D(real) -0.271 | D(fake) -0.483\n",
            "step 2740 | loss_D 1.3623 | loss_G 0.8053 | D(real) -0.071 | D(fake) -0.156\n",
            "step 2750 | loss_D 1.3172 | loss_G 0.8349 | D(real) +0.295 | D(fake) +0.049\n",
            "step 2760 | loss_D 1.6362 | loss_G 0.9512 | D(real) -0.604 | D(fake) -0.228\n",
            "step 2770 | loss_D 1.1942 | loss_G 0.7666 | D(real) +0.515 | D(fake) -0.013\n",
            "step 2780 | loss_D 1.1767 | loss_G 1.1213 | D(real) -0.022 | D(fake) -0.526\n",
            "step 2790 | loss_D 1.2040 | loss_G 1.1122 | D(real) +0.166 | D(fake) -0.243\n",
            "step 2800 | loss_D 1.4379 | loss_G 1.1143 | D(real) +0.349 | D(fake) +0.242\n",
            "step 2810 | loss_D 1.6051 | loss_G 0.7526 | D(real) -0.231 | D(fake) +0.146\n",
            "step 2820 | loss_D 1.3954 | loss_G 0.8629 | D(real) -0.001 | D(fake) +0.007\n",
            "step 2830 | loss_D 1.4433 | loss_G 0.8204 | D(real) -0.157 | D(fake) -0.065\n",
            "step 2840 | loss_D 1.1698 | loss_G 0.8069 | D(real) +0.211 | D(fake) -0.347\n",
            "step 2850 | loss_D 1.3727 | loss_G 0.8757 | D(real) -0.049 | D(fake) -0.093\n",
            "step 2860 | loss_D 1.1564 | loss_G 0.9008 | D(real) +0.781 | D(fake) +0.030\n",
            "step 2870 | loss_D 1.0242 | loss_G 1.2727 | D(real) +0.584 | D(fake) -0.887\n",
            "step 2880 | loss_D 1.1892 | loss_G 1.1806 | D(real) +0.491 | D(fake) -0.005\n",
            "step 2890 | loss_D 1.0725 | loss_G 0.9267 | D(real) +0.426 | D(fake) -0.274\n",
            "step 2900 | loss_D 1.5126 | loss_G 0.8136 | D(real) -0.187 | D(fake) -0.028\n",
            "step 2910 | loss_D 1.3098 | loss_G 0.6632 | D(real) +0.356 | D(fake) +0.110\n",
            "step 2920 | loss_D 1.3616 | loss_G 0.7783 | D(real) -0.304 | D(fake) -0.459\n",
            "step 2930 | loss_D 1.1724 | loss_G 0.8899 | D(real) +0.123 | D(fake) -0.494\n",
            "step 2940 | loss_D 1.2696 | loss_G 0.9956 | D(real) +0.304 | D(fake) -0.121\n",
            "step 2950 | loss_D 1.2504 | loss_G 0.9938 | D(real) +0.209 | D(fake) -0.263\n",
            "step 2960 | loss_D 1.4728 | loss_G 0.9104 | D(real) -0.230 | D(fake) -0.153\n",
            "step 2970 | loss_D 1.3901 | loss_G 0.8697 | D(real) +0.002 | D(fake) -0.068\n",
            "step 2980 | loss_D 1.1760 | loss_G 0.9487 | D(real) +0.275 | D(fake) -0.251\n",
            "step 2990 | loss_D 1.2730 | loss_G 1.1521 | D(real) +0.214 | D(fake) -0.295\n",
            "step 3000 | loss_D 1.8537 | loss_G 0.6188 | D(real) -0.651 | D(fake) +0.079\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_003000.pt\n",
            "step 3010 | loss_D 1.1203 | loss_G 1.4056 | D(real) +0.603 | D(fake) -0.176\n",
            "step 3020 | loss_D 1.0257 | loss_G 1.1654 | D(real) +0.221 | D(fake) -0.786\n",
            "step 3030 | loss_D 0.9080 | loss_G 1.2105 | D(real) +1.089 | D(fake) -0.306\n",
            "step 3040 | loss_D 1.4879 | loss_G 1.2435 | D(real) +0.153 | D(fake) +0.187\n",
            "step 3050 | loss_D 1.7255 | loss_G 0.8115 | D(real) -0.059 | D(fake) +0.523\n",
            "step 3060 | loss_D 1.3323 | loss_G 1.3100 | D(real) +0.332 | D(fake) -0.075\n",
            "step 3070 | loss_D 1.2100 | loss_G 1.0014 | D(real) +0.294 | D(fake) -0.131\n",
            "step 3080 | loss_D 1.3333 | loss_G 0.8779 | D(real) -0.104 | D(fake) -0.277\n",
            "step 3090 | loss_D 1.2195 | loss_G 0.7966 | D(real) +0.590 | D(fake) +0.083\n",
            "step 3100 | loss_D 1.5502 | loss_G 0.9552 | D(real) -0.362 | D(fake) -0.160\n",
            "step 3110 | loss_D 1.6270 | loss_G 0.8592 | D(real) -0.505 | D(fake) -0.163\n",
            "step 3120 | loss_D 1.0673 | loss_G 0.8207 | D(real) +0.792 | D(fake) -0.023\n",
            "step 3130 | loss_D 1.3423 | loss_G 1.0565 | D(real) -0.183 | D(fake) -0.419\n",
            "step 3140 | loss_D 1.0384 | loss_G 1.3437 | D(real) +0.445 | D(fake) -0.357\n",
            "step 3150 | loss_D 1.3521 | loss_G 0.7964 | D(real) -0.161 | D(fake) -0.273\n",
            "step 3160 | loss_D 1.3414 | loss_G 0.7786 | D(real) +0.207 | D(fake) +0.087\n",
            "step 3170 | loss_D 1.1828 | loss_G 1.0793 | D(real) +0.590 | D(fake) +0.002\n",
            "step 3180 | loss_D 1.2720 | loss_G 1.0231 | D(real) +0.329 | D(fake) +0.015\n",
            "step 3190 | loss_D 1.0450 | loss_G 1.1513 | D(real) +0.874 | D(fake) -0.234\n",
            "step 3200 | loss_D 1.0410 | loss_G 0.6985 | D(real) +0.642 | D(fake) -0.271\n",
            "step 3210 | loss_D 1.6955 | loss_G 0.9953 | D(real) -0.958 | D(fake) -1.144\n",
            "step 3220 | loss_D 1.2660 | loss_G 0.9454 | D(real) -0.042 | D(fake) -0.347\n",
            "step 3230 | loss_D 1.0140 | loss_G 1.2469 | D(real) +0.382 | D(fake) -0.527\n",
            "step 3240 | loss_D 0.8163 | loss_G 1.4215 | D(real) +1.227 | D(fake) -0.404\n",
            "step 3250 | loss_D 1.3251 | loss_G 1.0631 | D(real) -0.036 | D(fake) -0.321\n",
            "step 3260 | loss_D 1.8883 | loss_G 0.7839 | D(real) -0.873 | D(fake) -0.241\n",
            "step 3270 | loss_D 1.2680 | loss_G 1.1338 | D(real) +0.208 | D(fake) -0.220\n",
            "step 3280 | loss_D 1.4751 | loss_G 0.7205 | D(real) +0.440 | D(fake) +0.389\n",
            "step 3290 | loss_D 1.1994 | loss_G 0.9351 | D(real) +0.132 | D(fake) -0.327\n",
            "step 3300 | loss_D 0.9505 | loss_G 1.2113 | D(real) +0.552 | D(fake) -0.673\n",
            "step 3310 | loss_D 1.0039 | loss_G 1.2613 | D(real) +0.562 | D(fake) -0.606\n",
            "step 3320 | loss_D 1.0080 | loss_G 1.1872 | D(real) +0.812 | D(fake) -0.345\n",
            "step 3330 | loss_D 1.1354 | loss_G 0.8068 | D(real) +0.613 | D(fake) -0.005\n",
            "step 3340 | loss_D 1.6253 | loss_G 1.3091 | D(real) -0.957 | D(fake) -1.006\n",
            "step 3350 | loss_D 1.4228 | loss_G 0.7831 | D(real) -0.025 | D(fake) -0.037\n",
            "step 3360 | loss_D 1.4526 | loss_G 0.9832 | D(real) +0.256 | D(fake) -0.042\n",
            "step 3370 | loss_D 1.3955 | loss_G 0.7407 | D(real) -0.133 | D(fake) -0.173\n",
            "step 3380 | loss_D 1.4983 | loss_G 0.9516 | D(real) +0.373 | D(fake) +0.437\n",
            "step 3390 | loss_D 1.4334 | loss_G 0.9407 | D(real) +0.003 | D(fake) +0.039\n",
            "step 3400 | loss_D 1.3927 | loss_G 0.7156 | D(real) +0.046 | D(fake) +0.052\n",
            "step 3410 | loss_D 1.2153 | loss_G 0.8404 | D(real) +0.260 | D(fake) -0.137\n",
            "step 3420 | loss_D 1.1245 | loss_G 0.9412 | D(real) +0.484 | D(fake) -0.134\n",
            "step 3430 | loss_D 1.1435 | loss_G 0.9926 | D(real) +0.287 | D(fake) -0.292\n",
            "step 3440 | loss_D 1.1936 | loss_G 1.3135 | D(real) +0.296 | D(fake) -0.220\n",
            "step 3450 | loss_D 1.5084 | loss_G 1.0557 | D(real) -0.416 | D(fake) -0.270\n",
            "step 3460 | loss_D 1.1608 | loss_G 1.4069 | D(real) +0.153 | D(fake) -0.413\n",
            "step 3470 | loss_D 1.4549 | loss_G 0.9911 | D(real) -0.504 | D(fake) -0.583\n",
            "step 3480 | loss_D 1.4009 | loss_G 0.8766 | D(real) +0.064 | D(fake) -0.455\n",
            "step 3490 | loss_D 1.2366 | loss_G 0.8814 | D(real) -0.068 | D(fake) -0.476\n",
            "step 3500 | loss_D 1.2822 | loss_G 1.1017 | D(real) +0.470 | D(fake) -0.130\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_003500.pt\n",
            "step 3510 | loss_D 0.9890 | loss_G 0.7919 | D(real) +0.462 | D(fake) -0.576\n",
            "step 3520 | loss_D 1.6266 | loss_G 1.0163 | D(real) +0.094 | D(fake) +0.453\n",
            "step 3530 | loss_D 1.0642 | loss_G 0.8534 | D(real) +0.438 | D(fake) -0.335\n",
            "step 3540 | loss_D 0.8632 | loss_G 1.5923 | D(real) +1.812 | D(fake) -0.103\n",
            "step 3550 | loss_D 1.5676 | loss_G 0.7974 | D(real) -0.549 | D(fake) -0.653\n",
            "step 3560 | loss_D 1.1932 | loss_G 0.6348 | D(real) +0.126 | D(fake) -0.317\n",
            "step 3570 | loss_D 1.2559 | loss_G 1.0370 | D(real) +0.115 | D(fake) -0.195\n",
            "step 3580 | loss_D 1.0638 | loss_G 0.8557 | D(real) +0.325 | D(fake) -0.409\n",
            "step 3590 | loss_D 1.1582 | loss_G 0.9860 | D(real) +0.157 | D(fake) -0.646\n",
            "step 3600 | loss_D 1.2120 | loss_G 0.8430 | D(real) +0.607 | D(fake) -0.334\n",
            "step 3610 | loss_D 1.2473 | loss_G 0.9051 | D(real) +0.023 | D(fake) -0.333\n",
            "step 3620 | loss_D 0.9556 | loss_G 1.1118 | D(real) +0.807 | D(fake) -0.382\n",
            "step 3630 | loss_D 1.3202 | loss_G 1.1401 | D(real) +1.191 | D(fake) +0.302\n",
            "step 3640 | loss_D 1.1685 | loss_G 1.0090 | D(real) +0.183 | D(fake) -0.367\n",
            "step 3650 | loss_D 1.1939 | loss_G 0.9612 | D(real) +0.084 | D(fake) -0.477\n",
            "step 3660 | loss_D 1.3467 | loss_G 0.7567 | D(real) +0.094 | D(fake) -0.159\n",
            "step 3670 | loss_D 1.3330 | loss_G 0.6859 | D(real) +0.175 | D(fake) -0.028\n",
            "step 3680 | loss_D 0.9820 | loss_G 0.7733 | D(real) +0.914 | D(fake) -0.172\n",
            "step 3690 | loss_D 1.0556 | loss_G 1.0109 | D(real) +0.592 | D(fake) -0.268\n",
            "step 3700 | loss_D 1.1519 | loss_G 1.0808 | D(real) +0.076 | D(fake) -0.525\n",
            "step 3710 | loss_D 1.2454 | loss_G 0.9688 | D(real) +0.360 | D(fake) -0.152\n",
            "step 3720 | loss_D 1.5768 | loss_G 1.0385 | D(real) -0.630 | D(fake) -0.452\n",
            "step 3730 | loss_D 0.9790 | loss_G 1.4430 | D(real) +0.354 | D(fake) -0.742\n",
            "step 3740 | loss_D 1.2850 | loss_G 0.9292 | D(real) +0.006 | D(fake) -0.267\n",
            "step 3750 | loss_D 1.0622 | loss_G 0.8778 | D(real) +0.385 | D(fake) -0.426\n",
            "step 3760 | loss_D 1.2054 | loss_G 1.1252 | D(real) -0.189 | D(fake) -0.751\n",
            "step 3770 | loss_D 0.9563 | loss_G 1.4446 | D(real) +0.872 | D(fake) -0.310\n",
            "step 3780 | loss_D 0.8279 | loss_G 1.1783 | D(real) +1.466 | D(fake) -0.220\n",
            "step 3790 | loss_D 1.6436 | loss_G 0.8580 | D(real) -0.612 | D(fake) -0.220\n",
            "step 3800 | loss_D 1.1960 | loss_G 0.6078 | D(real) +0.187 | D(fake) -0.290\n",
            "step 3810 | loss_D 1.7445 | loss_G 1.0386 | D(real) -0.678 | D(fake) -0.162\n",
            "step 3820 | loss_D 1.2056 | loss_G 0.9793 | D(real) +0.031 | D(fake) -0.417\n",
            "step 3830 | loss_D 1.2062 | loss_G 0.9801 | D(real) +0.388 | D(fake) -0.021\n",
            "step 3840 | loss_D 1.0339 | loss_G 1.1000 | D(real) +1.211 | D(fake) -0.149\n",
            "step 3850 | loss_D 1.2090 | loss_G 1.0807 | D(real) +0.344 | D(fake) -0.077\n",
            "step 3860 | loss_D 1.1606 | loss_G 1.1132 | D(real) +0.368 | D(fake) -0.198\n",
            "step 3870 | loss_D 0.9875 | loss_G 0.9424 | D(real) +1.331 | D(fake) +0.027\n",
            "step 3880 | loss_D 1.1681 | loss_G 1.1850 | D(real) -0.006 | D(fake) -0.657\n",
            "step 3890 | loss_D 1.0166 | loss_G 1.4110 | D(real) +0.840 | D(fake) -0.168\n",
            "step 3900 | loss_D 1.6486 | loss_G 1.3384 | D(real) +0.019 | D(fake) -0.728\n",
            "step 3910 | loss_D 0.9903 | loss_G 1.2445 | D(real) +0.907 | D(fake) -0.278\n",
            "step 3920 | loss_D 1.0204 | loss_G 0.7594 | D(real) +1.769 | D(fake) +0.261\n",
            "step 3930 | loss_D 1.1420 | loss_G 1.1729 | D(real) +0.932 | D(fake) -0.133\n",
            "step 3940 | loss_D 1.0380 | loss_G 1.0102 | D(real) +0.211 | D(fake) -0.728\n",
            "step 3950 | loss_D 1.5773 | loss_G 0.8998 | D(real) -0.418 | D(fake) -0.142\n",
            "step 3960 | loss_D 1.1387 | loss_G 0.9060 | D(real) +0.584 | D(fake) -0.148\n",
            "step 3970 | loss_D 1.2126 | loss_G 0.9443 | D(real) -0.051 | D(fake) -0.486\n",
            "step 3980 | loss_D 1.1652 | loss_G 0.9858 | D(real) +0.445 | D(fake) -0.121\n",
            "step 3990 | loss_D 1.3591 | loss_G 0.8134 | D(real) +0.146 | D(fake) +0.067\n",
            "step 4000 | loss_D 0.7979 | loss_G 1.1383 | D(real) +1.131 | D(fake) -0.566\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_004000.pt\n",
            "step 4010 | loss_D 1.1682 | loss_G 1.0333 | D(real) +0.560 | D(fake) -0.066\n",
            "step 4020 | loss_D 0.9821 | loss_G 1.2838 | D(real) +0.183 | D(fake) -0.829\n",
            "step 4030 | loss_D 1.0941 | loss_G 1.1289 | D(real) +1.184 | D(fake) +0.089\n",
            "step 4040 | loss_D 1.9589 | loss_G 0.4363 | D(real) -1.354 | D(fake) -0.880\n",
            "step 4050 | loss_D 1.1602 | loss_G 0.7056 | D(real) +0.141 | D(fake) -0.398\n",
            "step 4060 | loss_D 1.5121 | loss_G 0.7676 | D(real) +0.192 | D(fake) +0.244\n",
            "step 4070 | loss_D 1.3933 | loss_G 1.0477 | D(real) -0.296 | D(fake) -0.401\n",
            "step 4080 | loss_D 1.4418 | loss_G 1.0391 | D(real) -0.268 | D(fake) -0.202\n",
            "step 4090 | loss_D 1.0396 | loss_G 0.9774 | D(real) +0.403 | D(fake) -0.403\n",
            "step 4100 | loss_D 0.7466 | loss_G 1.3716 | D(real) +1.992 | D(fake) -0.729\n",
            "step 4110 | loss_D 1.4260 | loss_G 1.0540 | D(real) -0.195 | D(fake) -0.159\n",
            "step 4120 | loss_D 1.1294 | loss_G 1.0978 | D(real) +0.286 | D(fake) -0.528\n",
            "step 4130 | loss_D 1.2297 | loss_G 0.8677 | D(real) +0.354 | D(fake) -0.013\n",
            "step 4140 | loss_D 1.3045 | loss_G 0.9730 | D(real) -0.388 | D(fake) -0.802\n",
            "step 4150 | loss_D 1.3621 | loss_G 0.9854 | D(real) +0.399 | D(fake) +0.136\n",
            "step 4160 | loss_D 0.6467 | loss_G 1.3333 | D(real) +1.173 | D(fake) -0.896\n",
            "step 4170 | loss_D 1.2638 | loss_G 0.8588 | D(real) +0.821 | D(fake) +0.192\n",
            "step 4180 | loss_D 1.4213 | loss_G 1.4518 | D(real) -0.486 | D(fake) -0.745\n",
            "step 4190 | loss_D 0.6811 | loss_G 1.8914 | D(real) +0.947 | D(fake) -1.131\n",
            "step 4200 | loss_D 1.2519 | loss_G 1.0895 | D(real) -0.077 | D(fake) -0.454\n",
            "step 4210 | loss_D 1.1345 | loss_G 1.0436 | D(real) +0.618 | D(fake) -0.073\n",
            "step 4220 | loss_D 0.9316 | loss_G 0.9467 | D(real) +1.847 | D(fake) +0.064\n",
            "step 4230 | loss_D 1.4651 | loss_G 0.7988 | D(real) -0.176 | D(fake) -0.149\n",
            "step 4240 | loss_D 1.2568 | loss_G 0.8377 | D(real) +0.068 | D(fake) -0.208\n",
            "step 4250 | loss_D 0.9825 | loss_G 1.1339 | D(real) +0.371 | D(fake) -0.620\n",
            "step 4260 | loss_D 1.3749 | loss_G 0.9496 | D(real) -0.071 | D(fake) -0.184\n",
            "step 4270 | loss_D 1.1978 | loss_G 0.9196 | D(real) +0.799 | D(fake) +0.033\n",
            "step 4280 | loss_D 1.2781 | loss_G 0.9311 | D(real) +0.173 | D(fake) -0.238\n",
            "step 4290 | loss_D 0.9983 | loss_G 1.1649 | D(real) +0.581 | D(fake) -0.379\n",
            "step 4300 | loss_D 1.0807 | loss_G 1.1347 | D(real) +1.100 | D(fake) -0.387\n",
            "step 4310 | loss_D 1.4834 | loss_G 0.9934 | D(real) +0.191 | D(fake) +0.193\n",
            "step 4320 | loss_D 1.1505 | loss_G 1.0300 | D(real) +0.342 | D(fake) -0.321\n",
            "step 4330 | loss_D 0.9285 | loss_G 0.7805 | D(real) +0.699 | D(fake) -0.417\n",
            "step 4340 | loss_D 0.9797 | loss_G 1.0824 | D(real) +0.627 | D(fake) -0.341\n",
            "step 4350 | loss_D 1.3472 | loss_G 0.9038 | D(real) +1.289 | D(fake) +0.601\n",
            "step 4360 | loss_D 0.7070 | loss_G 1.3954 | D(real) +1.273 | D(fake) -0.649\n",
            "step 4370 | loss_D 1.6468 | loss_G 0.8839 | D(real) -0.520 | D(fake) -0.095\n",
            "step 4380 | loss_D 1.0117 | loss_G 1.0845 | D(real) +0.505 | D(fake) -0.563\n",
            "step 4390 | loss_D 1.5458 | loss_G 0.6869 | D(real) -0.254 | D(fake) +0.014\n",
            "step 4400 | loss_D 0.8320 | loss_G 1.2642 | D(real) +0.968 | D(fake) -0.607\n",
            "step 4410 | loss_D 1.4667 | loss_G 0.7730 | D(real) +0.101 | D(fake) +0.135\n",
            "step 4420 | loss_D 1.2086 | loss_G 0.9113 | D(real) +0.242 | D(fake) -0.458\n",
            "step 4430 | loss_D 0.9975 | loss_G 1.1003 | D(real) +0.742 | D(fake) -0.259\n",
            "step 4440 | loss_D 1.0899 | loss_G 0.8172 | D(real) +0.289 | D(fake) -0.481\n",
            "step 4450 | loss_D 1.0652 | loss_G 0.9624 | D(real) +0.222 | D(fake) -0.551\n",
            "step 4460 | loss_D 0.8594 | loss_G 1.1427 | D(real) +1.604 | D(fake) -0.260\n",
            "step 4470 | loss_D 1.4424 | loss_G 0.6879 | D(real) +1.380 | D(fake) +0.574\n",
            "step 4480 | loss_D 0.8995 | loss_G 1.5099 | D(real) +0.328 | D(fake) -1.058\n",
            "step 4490 | loss_D 1.0419 | loss_G 1.1319 | D(real) +0.646 | D(fake) -0.318\n",
            "step 4500 | loss_D 1.1798 | loss_G 1.2388 | D(real) +0.918 | D(fake) +0.033\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_004500.pt\n",
            "step 4510 | loss_D 0.9379 | loss_G 1.1311 | D(real) +0.500 | D(fake) -0.581\n",
            "step 4520 | loss_D 1.5631 | loss_G 0.6203 | D(real) +0.321 | D(fake) +0.478\n",
            "step 4530 | loss_D 1.0535 | loss_G 1.0802 | D(real) +0.698 | D(fake) -0.187\n",
            "step 4540 | loss_D 1.1581 | loss_G 0.7308 | D(real) +0.294 | D(fake) -0.228\n",
            "step 4550 | loss_D 0.7293 | loss_G 1.0594 | D(real) +0.930 | D(fake) -0.766\n",
            "step 4560 | loss_D 1.1038 | loss_G 1.1133 | D(real) +0.683 | D(fake) -0.209\n",
            "step 4570 | loss_D 0.9449 | loss_G 1.1918 | D(real) +0.807 | D(fake) -0.583\n",
            "step 4580 | loss_D 1.2627 | loss_G 1.1802 | D(real) +0.813 | D(fake) +0.058\n",
            "step 4590 | loss_D 0.9095 | loss_G 1.0938 | D(real) +0.702 | D(fake) -0.517\n",
            "step 4600 | loss_D 1.2078 | loss_G 1.0188 | D(real) +0.020 | D(fake) -0.450\n",
            "step 4610 | loss_D 1.1744 | loss_G 0.8463 | D(real) +0.672 | D(fake) -0.010\n",
            "step 4620 | loss_D 0.7524 | loss_G 1.5813 | D(real) +1.894 | D(fake) -0.279\n",
            "step 4630 | loss_D 1.3386 | loss_G 1.1379 | D(real) +0.424 | D(fake) +0.146\n",
            "step 4640 | loss_D 0.8828 | loss_G 1.2519 | D(real) +0.935 | D(fake) -0.523\n",
            "step 4650 | loss_D 1.4865 | loss_G 0.7278 | D(real) -0.448 | D(fake) -0.581\n",
            "step 4660 | loss_D 0.9556 | loss_G 1.3458 | D(real) +0.084 | D(fake) -1.280\n",
            "step 4670 | loss_D 1.2689 | loss_G 0.9231 | D(real) +0.477 | D(fake) +0.026\n",
            "step 4680 | loss_D 1.4234 | loss_G 1.0852 | D(real) -0.275 | D(fake) -0.338\n",
            "step 4690 | loss_D 1.3851 | loss_G 1.0856 | D(real) -0.180 | D(fake) -0.270\n",
            "step 4700 | loss_D 0.9687 | loss_G 1.0062 | D(real) +0.822 | D(fake) -0.377\n",
            "step 4710 | loss_D 1.1448 | loss_G 1.1144 | D(real) -0.039 | D(fake) -0.755\n",
            "step 4720 | loss_D 1.4922 | loss_G 0.7755 | D(real) -0.283 | D(fake) -0.227\n",
            "step 4730 | loss_D 0.9005 | loss_G 0.7182 | D(real) +1.544 | D(fake) -0.237\n",
            "step 4740 | loss_D 1.4304 | loss_G 1.1612 | D(real) -0.039 | D(fake) -0.295\n",
            "step 4750 | loss_D 1.4213 | loss_G 1.0454 | D(real) -0.357 | D(fake) -0.423\n",
            "step 4760 | loss_D 1.1005 | loss_G 0.9615 | D(real) +0.976 | D(fake) -0.084\n",
            "step 4770 | loss_D 0.9998 | loss_G 1.2447 | D(real) +0.658 | D(fake) -0.609\n",
            "step 4780 | loss_D 1.0686 | loss_G 1.1137 | D(real) +0.740 | D(fake) -0.300\n",
            "step 4790 | loss_D 0.8744 | loss_G 1.2551 | D(real) +2.078 | D(fake) -0.700\n",
            "step 4800 | loss_D 0.9541 | loss_G 1.3426 | D(real) +0.339 | D(fake) -0.738\n",
            "step 4810 | loss_D 1.5721 | loss_G 1.0287 | D(real) -0.271 | D(fake) -0.439\n",
            "step 4820 | loss_D 1.6050 | loss_G 1.0294 | D(real) -1.062 | D(fake) -1.289\n",
            "step 4830 | loss_D 1.0819 | loss_G 1.3819 | D(real) +0.665 | D(fake) -0.086\n",
            "step 4840 | loss_D 1.1533 | loss_G 1.1607 | D(real) +0.203 | D(fake) -0.479\n",
            "step 4850 | loss_D 1.2619 | loss_G 0.8142 | D(real) +0.243 | D(fake) -0.158\n",
            "step 4860 | loss_D 1.5999 | loss_G 0.8459 | D(real) -0.649 | D(fake) -0.409\n",
            "step 4870 | loss_D 1.2541 | loss_G 0.9739 | D(real) +0.526 | D(fake) +0.082\n",
            "step 4880 | loss_D 0.8119 | loss_G 1.1590 | D(real) +0.795 | D(fake) -0.694\n",
            "step 4890 | loss_D 0.6587 | loss_G 1.3654 | D(real) +1.466 | D(fake) -0.857\n",
            "step 4900 | loss_D 0.7718 | loss_G 2.5332 | D(real) +2.215 | D(fake) -0.126\n",
            "step 4910 | loss_D 0.6914 | loss_G 1.4834 | D(real) +0.642 | D(fake) -1.266\n",
            "step 4920 | loss_D 1.3059 | loss_G 0.9800 | D(real) -0.019 | D(fake) -0.401\n",
            "step 4930 | loss_D 0.9012 | loss_G 1.1308 | D(real) +0.563 | D(fake) -0.796\n",
            "step 4940 | loss_D 1.1220 | loss_G 1.0617 | D(real) +1.119 | D(fake) -0.145\n",
            "step 4950 | loss_D 0.7570 | loss_G 1.2541 | D(real) +0.799 | D(fake) -0.764\n",
            "step 4960 | loss_D 0.8587 | loss_G 1.4192 | D(real) +2.033 | D(fake) -0.093\n",
            "step 4970 | loss_D 0.7973 | loss_G 1.6236 | D(real) +1.342 | D(fake) -0.489\n",
            "step 4980 | loss_D 1.1006 | loss_G 1.0538 | D(real) +0.867 | D(fake) -0.227\n",
            "step 4990 | loss_D 1.2870 | loss_G 1.2238 | D(real) +0.019 | D(fake) -0.371\n",
            "step 5000 | loss_D 1.5506 | loss_G 1.2357 | D(real) -0.405 | D(fake) -0.345\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_005000.pt\n",
            "step 5010 | loss_D 1.1917 | loss_G 0.7663 | D(real) +0.593 | D(fake) -0.049\n",
            "step 5020 | loss_D 1.3353 | loss_G 1.0191 | D(real) -0.091 | D(fake) -0.377\n",
            "step 5030 | loss_D 0.8163 | loss_G 1.2001 | D(real) +0.942 | D(fake) -0.701\n",
            "step 5040 | loss_D 1.5432 | loss_G 0.7772 | D(real) -0.480 | D(fake) -0.348\n",
            "step 5050 | loss_D 0.9549 | loss_G 1.2353 | D(real) +0.439 | D(fake) -0.653\n",
            "step 5060 | loss_D 1.6301 | loss_G 0.8862 | D(real) -0.397 | D(fake) -0.147\n",
            "step 5070 | loss_D 0.8744 | loss_G 1.2586 | D(real) +1.762 | D(fake) -0.839\n",
            "step 5080 | loss_D 1.0407 | loss_G 0.9603 | D(real) +1.172 | D(fake) +0.051\n",
            "step 5090 | loss_D 0.8955 | loss_G 1.1901 | D(real) +0.980 | D(fake) -0.273\n",
            "step 5100 | loss_D 0.9516 | loss_G 0.9941 | D(real) +0.453 | D(fake) -1.114\n",
            "step 5110 | loss_D 1.1243 | loss_G 1.0482 | D(real) +0.202 | D(fake) -0.494\n",
            "step 5120 | loss_D 1.4127 | loss_G 0.7348 | D(real) -0.072 | D(fake) -0.251\n",
            "step 5130 | loss_D 0.8542 | loss_G 1.1509 | D(real) +1.030 | D(fake) -0.537\n",
            "step 5140 | loss_D 0.9498 | loss_G 1.0971 | D(real) +1.106 | D(fake) -0.131\n",
            "step 5150 | loss_D 1.3857 | loss_G 1.3507 | D(real) +0.059 | D(fake) -0.038\n",
            "step 5160 | loss_D 1.8696 | loss_G 0.7836 | D(real) -0.770 | D(fake) -0.147\n",
            "step 5170 | loss_D 1.6925 | loss_G 1.0356 | D(real) -0.725 | D(fake) -0.468\n",
            "step 5180 | loss_D 0.8795 | loss_G 1.3182 | D(real) +1.073 | D(fake) -0.365\n",
            "step 5190 | loss_D 0.7702 | loss_G 1.2489 | D(real) +1.672 | D(fake) -0.214\n",
            "step 5200 | loss_D 0.7672 | loss_G 1.2559 | D(real) +1.272 | D(fake) -0.486\n",
            "step 5210 | loss_D 1.3740 | loss_G 0.9185 | D(real) +0.230 | D(fake) -0.222\n",
            "step 5220 | loss_D 0.9374 | loss_G 1.1264 | D(real) +1.067 | D(fake) -0.196\n",
            "step 5230 | loss_D 0.9697 | loss_G 1.0174 | D(real) +0.743 | D(fake) -0.347\n",
            "step 5240 | loss_D 0.9985 | loss_G 1.3188 | D(real) +0.896 | D(fake) -0.548\n",
            "step 5250 | loss_D 0.9689 | loss_G 1.3023 | D(real) +1.328 | D(fake) -0.273\n",
            "step 5260 | loss_D 0.5916 | loss_G 1.4606 | D(real) +1.703 | D(fake) -0.775\n",
            "step 5270 | loss_D 1.4465 | loss_G 1.4141 | D(real) -0.446 | D(fake) -0.709\n",
            "step 5280 | loss_D 1.1502 | loss_G 1.9302 | D(real) +0.287 | D(fake) -0.590\n",
            "step 5290 | loss_D 1.1486 | loss_G 1.1770 | D(real) +1.050 | D(fake) +0.171\n",
            "step 5300 | loss_D 1.0827 | loss_G 1.0041 | D(real) +0.280 | D(fake) -0.446\n",
            "step 5310 | loss_D 1.0561 | loss_G 1.0369 | D(real) +0.649 | D(fake) -0.142\n",
            "step 5320 | loss_D 1.4131 | loss_G 1.0526 | D(real) -0.163 | D(fake) -0.132\n",
            "step 5330 | loss_D 1.1437 | loss_G 1.0182 | D(real) +0.252 | D(fake) -0.289\n",
            "step 5340 | loss_D 1.1432 | loss_G 1.0293 | D(real) +0.313 | D(fake) -0.344\n",
            "step 5350 | loss_D 1.1982 | loss_G 1.1200 | D(real) +0.211 | D(fake) -0.335\n",
            "step 5360 | loss_D 1.0409 | loss_G 1.0419 | D(real) +0.662 | D(fake) -0.489\n",
            "step 5370 | loss_D 0.8675 | loss_G 1.2652 | D(real) +1.192 | D(fake) -0.560\n",
            "step 5380 | loss_D 1.2987 | loss_G 1.4257 | D(real) +0.520 | D(fake) -0.844\n",
            "step 5390 | loss_D 0.8661 | loss_G 1.5329 | D(real) +0.599 | D(fake) -0.672\n",
            "step 5400 | loss_D 0.9201 | loss_G 1.0955 | D(real) +1.420 | D(fake) -0.100\n",
            "step 5410 | loss_D 0.8896 | loss_G 1.1284 | D(real) +1.127 | D(fake) -0.673\n",
            "step 5420 | loss_D 1.2743 | loss_G 1.1663 | D(real) +0.150 | D(fake) -0.268\n",
            "step 5430 | loss_D 0.8383 | loss_G 1.3913 | D(real) +0.998 | D(fake) -0.442\n",
            "step 5440 | loss_D 1.1674 | loss_G 1.0104 | D(real) +0.241 | D(fake) -0.437\n",
            "step 5450 | loss_D 1.1158 | loss_G 0.8694 | D(real) +0.495 | D(fake) -0.203\n",
            "step 5460 | loss_D 0.9066 | loss_G 1.5510 | D(real) +0.503 | D(fake) -0.944\n",
            "step 5470 | loss_D 0.9340 | loss_G 1.7911 | D(real) +0.841 | D(fake) -0.711\n",
            "step 5480 | loss_D 1.0413 | loss_G 1.2745 | D(real) +0.902 | D(fake) -0.359\n",
            "step 5490 | loss_D 1.1865 | loss_G 0.7279 | D(real) +0.542 | D(fake) +0.018\n",
            "step 5500 | loss_D 0.9646 | loss_G 0.9367 | D(real) +0.529 | D(fake) -0.513\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_005500.pt\n",
            "step 5510 | loss_D 0.9594 | loss_G 1.0885 | D(real) +1.247 | D(fake) -0.418\n",
            "step 5520 | loss_D 0.9953 | loss_G 1.1067 | D(real) +0.674 | D(fake) -0.434\n",
            "step 5530 | loss_D 1.3217 | loss_G 0.7787 | D(real) +0.364 | D(fake) +0.078\n",
            "step 5540 | loss_D 1.3190 | loss_G 1.0458 | D(real) +0.523 | D(fake) -0.036\n",
            "step 5550 | loss_D 0.9028 | loss_G 1.0991 | D(real) +0.616 | D(fake) -0.560\n",
            "step 5560 | loss_D 0.8572 | loss_G 1.1599 | D(real) +0.729 | D(fake) -0.680\n",
            "step 5570 | loss_D 1.6414 | loss_G 1.1072 | D(real) -0.867 | D(fake) -0.777\n",
            "step 5580 | loss_D 0.9325 | loss_G 1.4995 | D(real) +0.547 | D(fake) -0.589\n",
            "step 5590 | loss_D 1.0900 | loss_G 1.0666 | D(real) +0.190 | D(fake) -0.528\n",
            "step 5600 | loss_D 1.2220 | loss_G 1.2308 | D(real) +0.043 | D(fake) -0.542\n",
            "step 5610 | loss_D 0.8787 | loss_G 1.2043 | D(real) +0.756 | D(fake) -0.709\n",
            "step 5620 | loss_D 1.6199 | loss_G 0.8580 | D(real) -0.204 | D(fake) -0.336\n",
            "step 5630 | loss_D 1.3020 | loss_G 0.9150 | D(real) +0.296 | D(fake) -0.244\n",
            "step 5640 | loss_D 0.7388 | loss_G 1.4615 | D(real) +2.518 | D(fake) -0.270\n",
            "step 5650 | loss_D 1.2584 | loss_G 1.4765 | D(real) +0.897 | D(fake) -0.310\n",
            "step 5660 | loss_D 0.9946 | loss_G 1.1940 | D(real) +0.814 | D(fake) -0.380\n",
            "step 5670 | loss_D 0.7731 | loss_G 1.4474 | D(real) +1.082 | D(fake) -0.730\n",
            "step 5680 | loss_D 1.0603 | loss_G 1.4539 | D(real) +0.249 | D(fake) -0.841\n",
            "step 5690 | loss_D 1.0139 | loss_G 0.8166 | D(real) +0.610 | D(fake) -0.377\n",
            "step 5700 | loss_D 0.9720 | loss_G 0.9349 | D(real) +2.320 | D(fake) +0.116\n",
            "step 5710 | loss_D 1.0146 | loss_G 1.1139 | D(real) +0.180 | D(fake) -0.937\n",
            "step 5720 | loss_D 1.6068 | loss_G 0.9114 | D(real) -0.426 | D(fake) -0.223\n",
            "step 5730 | loss_D 0.7503 | loss_G 1.1097 | D(real) +1.450 | D(fake) -0.558\n",
            "step 5740 | loss_D 0.8371 | loss_G 1.7277 | D(real) +1.213 | D(fake) -0.284\n",
            "step 5750 | loss_D 1.1937 | loss_G 1.3907 | D(real) -0.288 | D(fake) -1.200\n",
            "step 5760 | loss_D 1.9247 | loss_G 1.0194 | D(real) -0.650 | D(fake) -0.007\n",
            "step 5770 | loss_D 1.0943 | loss_G 0.9367 | D(real) +0.470 | D(fake) -0.202\n",
            "step 5780 | loss_D 1.1691 | loss_G 1.3896 | D(real) +0.862 | D(fake) -0.240\n",
            "step 5790 | loss_D 0.7971 | loss_G 1.4394 | D(real) +1.443 | D(fake) -0.875\n",
            "step 5800 | loss_D 1.2367 | loss_G 0.9308 | D(real) +0.787 | D(fake) +0.189\n",
            "step 5810 | loss_D 0.8731 | loss_G 1.1709 | D(real) +0.478 | D(fake) -0.840\n",
            "step 5820 | loss_D 1.0377 | loss_G 1.2097 | D(real) +0.667 | D(fake) -0.238\n",
            "step 5830 | loss_D 0.7627 | loss_G 1.8017 | D(real) +0.974 | D(fake) -1.004\n",
            "step 5840 | loss_D 1.1135 | loss_G 0.7828 | D(real) +0.439 | D(fake) -0.491\n",
            "step 5850 | loss_D 1.2787 | loss_G 1.4981 | D(real) +0.456 | D(fake) -0.007\n",
            "step 5860 | loss_D 1.0627 | loss_G 1.0706 | D(real) +0.825 | D(fake) -0.306\n",
            "step 5870 | loss_D 1.2182 | loss_G 0.8720 | D(real) -0.137 | D(fake) -0.616\n",
            "step 5880 | loss_D 0.6731 | loss_G 1.2194 | D(real) +1.552 | D(fake) -0.786\n",
            "step 5890 | loss_D 1.1076 | loss_G 1.0750 | D(real) +1.018 | D(fake) +0.111\n",
            "step 5900 | loss_D 1.2152 | loss_G 1.3100 | D(real) -0.120 | D(fake) -0.702\n",
            "step 5910 | loss_D 1.0909 | loss_G 1.4093 | D(real) +0.475 | D(fake) -0.540\n",
            "step 5920 | loss_D 0.7422 | loss_G 1.2783 | D(real) +1.185 | D(fake) -0.583\n",
            "step 5930 | loss_D 0.5654 | loss_G 1.4476 | D(real) +2.168 | D(fake) -0.793\n",
            "step 5940 | loss_D 1.2935 | loss_G 1.1969 | D(real) -0.287 | D(fake) -0.777\n",
            "step 5950 | loss_D 0.8250 | loss_G 1.3011 | D(real) +0.767 | D(fake) -0.778\n",
            "step 5960 | loss_D 1.0147 | loss_G 1.5246 | D(real) +0.941 | D(fake) -0.727\n",
            "step 5970 | loss_D 0.6969 | loss_G 1.7238 | D(real) +0.762 | D(fake) -1.091\n",
            "step 5980 | loss_D 1.6048 | loss_G 1.1499 | D(real) -0.012 | D(fake) +0.217\n",
            "step 5990 | loss_D 0.7274 | loss_G 1.5012 | D(real) +1.268 | D(fake) -0.586\n",
            "step 6000 | loss_D 1.1435 | loss_G 1.2818 | D(real) +0.108 | D(fake) -0.608\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_006000.pt\n",
            "step 6010 | loss_D 0.6904 | loss_G 1.3141 | D(real) +1.113 | D(fake) -0.999\n",
            "step 6020 | loss_D 1.0756 | loss_G 1.0332 | D(real) +0.235 | D(fake) -0.554\n",
            "step 6030 | loss_D 0.9623 | loss_G 1.5587 | D(real) +1.647 | D(fake) +0.120\n",
            "step 6040 | loss_D 0.5797 | loss_G 1.6581 | D(real) +1.799 | D(fake) -0.678\n",
            "step 6050 | loss_D 0.8449 | loss_G 1.2338 | D(real) +1.209 | D(fake) -0.363\n",
            "step 6060 | loss_D 1.5046 | loss_G 1.5850 | D(real) +0.413 | D(fake) +0.323\n",
            "step 6070 | loss_D 0.9732 | loss_G 1.5206 | D(real) +0.589 | D(fake) -0.642\n",
            "step 6080 | loss_D 1.0877 | loss_G 0.8881 | D(real) +1.374 | D(fake) -0.133\n",
            "step 6090 | loss_D 1.1598 | loss_G 1.3519 | D(real) +0.472 | D(fake) -0.467\n",
            "step 6100 | loss_D 0.9646 | loss_G 1.4810 | D(real) +0.480 | D(fake) -0.532\n",
            "step 6110 | loss_D 0.9324 | loss_G 0.8729 | D(real) +0.214 | D(fake) -0.996\n",
            "step 6120 | loss_D 1.7873 | loss_G 0.6635 | D(real) -0.234 | D(fake) +0.247\n",
            "step 6130 | loss_D 0.9614 | loss_G 1.0951 | D(real) +1.743 | D(fake) -0.188\n",
            "step 6140 | loss_D 1.1952 | loss_G 1.0349 | D(real) +0.614 | D(fake) -0.209\n",
            "step 6150 | loss_D 1.3720 | loss_G 1.0597 | D(real) -0.220 | D(fake) -0.430\n",
            "step 6160 | loss_D 0.8337 | loss_G 1.0750 | D(real) +1.527 | D(fake) -0.233\n",
            "step 6170 | loss_D 0.9832 | loss_G 1.0621 | D(real) +0.576 | D(fake) -0.649\n",
            "step 6180 | loss_D 0.9621 | loss_G 1.7730 | D(real) +0.935 | D(fake) -0.410\n",
            "step 6190 | loss_D 1.4139 | loss_G 1.5737 | D(real) +0.400 | D(fake) +0.053\n",
            "step 6200 | loss_D 1.2107 | loss_G 1.1065 | D(real) +0.760 | D(fake) -0.364\n",
            "step 6210 | loss_D 0.7611 | loss_G 1.4910 | D(real) +0.755 | D(fake) -0.837\n",
            "step 6220 | loss_D 1.2307 | loss_G 1.2998 | D(real) +0.009 | D(fake) -0.704\n",
            "step 6230 | loss_D 1.1103 | loss_G 1.1945 | D(real) +0.252 | D(fake) -0.674\n",
            "step 6240 | loss_D 1.1370 | loss_G 0.8628 | D(real) +0.352 | D(fake) -0.381\n",
            "step 6250 | loss_D 0.8542 | loss_G 1.2854 | D(real) +0.777 | D(fake) -0.620\n",
            "step 6260 | loss_D 0.5665 | loss_G 1.4439 | D(real) +1.460 | D(fake) -0.871\n",
            "step 6270 | loss_D 0.6646 | loss_G 1.6606 | D(real) +1.795 | D(fake) -0.581\n",
            "step 6280 | loss_D 1.0768 | loss_G 1.2263 | D(real) +0.301 | D(fake) -0.406\n",
            "step 6290 | loss_D 1.3661 | loss_G 0.9033 | D(real) +0.053 | D(fake) -0.231\n",
            "step 6300 | loss_D 0.8769 | loss_G 1.8805 | D(real) +0.916 | D(fake) -0.510\n",
            "step 6310 | loss_D 0.7023 | loss_G 1.7083 | D(real) +2.156 | D(fake) -0.637\n",
            "step 6320 | loss_D 1.7107 | loss_G 0.9768 | D(real) -0.135 | D(fake) +0.212\n",
            "step 6330 | loss_D 1.0300 | loss_G 1.0543 | D(real) +0.496 | D(fake) -0.634\n",
            "step 6340 | loss_D 1.1501 | loss_G 1.1444 | D(real) +1.114 | D(fake) +0.098\n",
            "step 6350 | loss_D 1.0949 | loss_G 0.9009 | D(real) +0.036 | D(fake) -0.897\n",
            "step 6360 | loss_D 1.2095 | loss_G 1.6417 | D(real) +0.138 | D(fake) -0.954\n",
            "step 6370 | loss_D 0.8352 | loss_G 1.2767 | D(real) +0.633 | D(fake) -0.752\n",
            "step 6380 | loss_D 0.7923 | loss_G 1.2973 | D(real) +0.904 | D(fake) -0.856\n",
            "step 6390 | loss_D 0.9769 | loss_G 1.2742 | D(real) +0.717 | D(fake) -0.425\n",
            "step 6400 | loss_D 0.9151 | loss_G 1.1330 | D(real) +0.810 | D(fake) -0.509\n",
            "step 6410 | loss_D 0.8612 | loss_G 1.1500 | D(real) +0.920 | D(fake) -0.472\n",
            "step 6420 | loss_D 0.9854 | loss_G 0.9561 | D(real) +0.583 | D(fake) -0.458\n",
            "step 6430 | loss_D 0.9035 | loss_G 1.3221 | D(real) +1.127 | D(fake) -0.880\n",
            "step 6440 | loss_D 0.7221 | loss_G 1.1825 | D(real) +2.188 | D(fake) -0.364\n",
            "step 6450 | loss_D 0.8505 | loss_G 1.2384 | D(real) +0.781 | D(fake) -0.586\n",
            "step 6460 | loss_D 1.0348 | loss_G 1.5651 | D(real) +0.096 | D(fake) -0.837\n",
            "step 6470 | loss_D 1.4962 | loss_G 2.1168 | D(real) -0.350 | D(fake) -0.726\n",
            "step 6480 | loss_D 1.4552 | loss_G 1.1021 | D(real) +0.768 | D(fake) +0.486\n",
            "step 6490 | loss_D 1.1972 | loss_G 1.1412 | D(real) +0.821 | D(fake) +0.083\n",
            "step 6500 | loss_D 1.2358 | loss_G 1.2838 | D(real) +1.585 | D(fake) +0.390\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_006500.pt\n",
            "step 6510 | loss_D 0.7102 | loss_G 1.5500 | D(real) +1.242 | D(fake) -0.771\n",
            "step 6520 | loss_D 1.0023 | loss_G 1.1406 | D(real) +0.700 | D(fake) -0.249\n",
            "step 6530 | loss_D 0.8870 | loss_G 0.9333 | D(real) +1.178 | D(fake) -0.321\n",
            "step 6540 | loss_D 0.7596 | loss_G 1.4801 | D(real) +1.114 | D(fake) -0.577\n",
            "step 6550 | loss_D 1.1347 | loss_G 1.0433 | D(real) -0.105 | D(fake) -1.034\n",
            "step 6560 | loss_D 1.0308 | loss_G 1.4718 | D(real) +0.601 | D(fake) -0.431\n",
            "step 6570 | loss_D 1.0660 | loss_G 1.1959 | D(real) +0.569 | D(fake) -0.326\n",
            "step 6580 | loss_D 1.3007 | loss_G 1.4959 | D(real) +0.650 | D(fake) -0.091\n",
            "step 6590 | loss_D 0.5359 | loss_G 1.6029 | D(real) +1.771 | D(fake) -1.223\n",
            "step 6600 | loss_D 1.1885 | loss_G 1.0671 | D(real) -0.012 | D(fake) -0.714\n",
            "step 6610 | loss_D 1.3507 | loss_G 1.1995 | D(real) -0.169 | D(fake) -0.461\n",
            "step 6620 | loss_D 1.0528 | loss_G 1.7255 | D(real) +1.192 | D(fake) -0.432\n",
            "step 6630 | loss_D 1.9840 | loss_G 1.3714 | D(real) -0.154 | D(fake) +0.187\n",
            "step 6640 | loss_D 0.7561 | loss_G 1.4885 | D(real) +1.397 | D(fake) -0.531\n",
            "step 6650 | loss_D 0.8871 | loss_G 1.2265 | D(real) +2.861 | D(fake) -0.230\n",
            "step 6660 | loss_D 1.3694 | loss_G 1.1608 | D(real) +0.583 | D(fake) +0.371\n",
            "step 6670 | loss_D 0.8791 | loss_G 0.7764 | D(real) +0.842 | D(fake) -0.404\n",
            "step 6680 | loss_D 0.9643 | loss_G 1.0555 | D(real) +0.623 | D(fake) -0.537\n",
            "step 6690 | loss_D 0.8526 | loss_G 1.0036 | D(real) +1.902 | D(fake) -0.138\n",
            "step 6700 | loss_D 1.0991 | loss_G 1.4742 | D(real) +0.392 | D(fake) -0.673\n",
            "step 6710 | loss_D 1.1440 | loss_G 0.8304 | D(real) +0.390 | D(fake) -0.416\n",
            "step 6720 | loss_D 1.1491 | loss_G 1.7206 | D(real) +0.816 | D(fake) -0.253\n",
            "step 6730 | loss_D 1.0271 | loss_G 1.5132 | D(real) +0.659 | D(fake) -0.624\n",
            "step 6740 | loss_D 0.7772 | loss_G 1.3753 | D(real) +1.216 | D(fake) -0.594\n",
            "step 6750 | loss_D 0.9023 | loss_G 1.6803 | D(real) +0.975 | D(fake) -0.335\n",
            "step 6760 | loss_D 0.9042 | loss_G 1.2217 | D(real) +1.278 | D(fake) -0.176\n",
            "step 6770 | loss_D 0.6698 | loss_G 1.5020 | D(real) +1.815 | D(fake) -1.077\n",
            "step 6780 | loss_D 0.6842 | loss_G 1.5076 | D(real) +1.145 | D(fake) -0.750\n",
            "step 6790 | loss_D 1.1315 | loss_G 1.0483 | D(real) +0.880 | D(fake) -0.348\n",
            "step 6800 | loss_D 0.9660 | loss_G 1.5855 | D(real) +0.508 | D(fake) -1.309\n",
            "step 6810 | loss_D 1.3607 | loss_G 1.4860 | D(real) +0.814 | D(fake) -0.090\n",
            "step 6820 | loss_D 0.8574 | loss_G 1.3189 | D(real) +0.668 | D(fake) -0.795\n",
            "step 6830 | loss_D 1.4798 | loss_G 0.9958 | D(real) -0.102 | D(fake) -0.442\n",
            "step 6840 | loss_D 1.3409 | loss_G 1.1079 | D(real) +0.562 | D(fake) +0.180\n",
            "step 6850 | loss_D 1.2002 | loss_G 1.1915 | D(real) +0.456 | D(fake) -0.416\n",
            "step 6860 | loss_D 1.1388 | loss_G 0.8551 | D(real) +1.721 | D(fake) +0.299\n",
            "step 6870 | loss_D 0.9010 | loss_G 0.9688 | D(real) +0.560 | D(fake) -1.014\n",
            "step 6880 | loss_D 1.8727 | loss_G 1.0849 | D(real) +0.079 | D(fake) +0.646\n",
            "step 6890 | loss_D 0.9747 | loss_G 1.0232 | D(real) +1.258 | D(fake) -0.522\n",
            "step 6900 | loss_D 1.2098 | loss_G 1.3839 | D(real) +0.247 | D(fake) -0.267\n",
            "step 6910 | loss_D 1.0941 | loss_G 1.2839 | D(real) +0.697 | D(fake) -0.333\n",
            "step 6920 | loss_D 0.7496 | loss_G 1.4824 | D(real) +1.280 | D(fake) -0.554\n",
            "step 6930 | loss_D 0.5507 | loss_G 1.2120 | D(real) +2.699 | D(fake) -0.675\n",
            "step 6940 | loss_D 1.0043 | loss_G 1.3288 | D(real) +1.380 | D(fake) -0.625\n",
            "step 6950 | loss_D 1.2897 | loss_G 1.3357 | D(real) -0.074 | D(fake) -0.690\n",
            "step 6960 | loss_D 0.7093 | loss_G 1.9604 | D(real) +1.506 | D(fake) -0.565\n",
            "step 6970 | loss_D 1.5464 | loss_G 1.0102 | D(real) +0.026 | D(fake) -0.225\n",
            "step 6980 | loss_D 1.2991 | loss_G 0.9471 | D(real) +0.675 | D(fake) -0.152\n",
            "step 6990 | loss_D 1.2314 | loss_G 0.9771 | D(real) -0.128 | D(fake) -0.652\n",
            "step 7000 | loss_D 0.8904 | loss_G 1.3503 | D(real) +1.651 | D(fake) -0.251\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_007000.pt\n",
            "step 7010 | loss_D 0.8518 | loss_G 1.4918 | D(real) +0.521 | D(fake) -1.251\n",
            "step 7020 | loss_D 0.5161 | loss_G 1.8827 | D(real) +1.842 | D(fake) -1.058\n",
            "step 7030 | loss_D 1.0953 | loss_G 0.8903 | D(real) +1.197 | D(fake) -0.158\n",
            "step 7040 | loss_D 0.8985 | loss_G 1.2310 | D(real) +0.461 | D(fake) -0.985\n",
            "step 7050 | loss_D 1.0015 | loss_G 1.2964 | D(real) +0.235 | D(fake) -0.771\n",
            "step 7060 | loss_D 1.5423 | loss_G 0.7896 | D(real) -0.402 | D(fake) -0.188\n",
            "step 7070 | loss_D 0.7100 | loss_G 1.1888 | D(real) +0.850 | D(fake) -1.229\n",
            "step 7080 | loss_D 0.9335 | loss_G 1.6505 | D(real) +0.654 | D(fake) -0.993\n",
            "step 7090 | loss_D 1.3690 | loss_G 1.2312 | D(real) -0.016 | D(fake) -0.244\n",
            "step 7100 | loss_D 1.1189 | loss_G 1.0695 | D(real) +0.809 | D(fake) -0.275\n",
            "step 7110 | loss_D 0.9817 | loss_G 1.3012 | D(real) +2.090 | D(fake) +0.219\n",
            "step 7120 | loss_D 1.1045 | loss_G 1.2378 | D(real) +0.673 | D(fake) -0.094\n",
            "step 7130 | loss_D 1.1305 | loss_G 0.8537 | D(real) +0.300 | D(fake) -0.387\n",
            "step 7140 | loss_D 1.0909 | loss_G 1.0391 | D(real) +0.218 | D(fake) -0.457\n",
            "step 7150 | loss_D 0.7720 | loss_G 1.3168 | D(real) +1.823 | D(fake) -0.324\n",
            "step 7160 | loss_D 0.6144 | loss_G 1.6835 | D(real) +1.535 | D(fake) -0.771\n",
            "step 7170 | loss_D 1.0634 | loss_G 1.3431 | D(real) +0.764 | D(fake) -0.276\n",
            "step 7180 | loss_D 1.3467 | loss_G 1.1224 | D(real) -0.072 | D(fake) -0.400\n",
            "step 7190 | loss_D 0.8614 | loss_G 1.2861 | D(real) +1.629 | D(fake) -0.358\n",
            "step 7200 | loss_D 1.0862 | loss_G 1.2154 | D(real) -0.031 | D(fake) -0.973\n",
            "step 7210 | loss_D 0.7428 | loss_G 1.1322 | D(real) +1.283 | D(fake) -0.536\n",
            "step 7220 | loss_D 1.2477 | loss_G 0.7914 | D(real) -0.067 | D(fake) -0.661\n",
            "step 7230 | loss_D 1.0273 | loss_G 1.2919 | D(real) +0.233 | D(fake) -1.123\n",
            "step 7240 | loss_D 0.7123 | loss_G 1.5570 | D(real) +1.656 | D(fake) -0.473\n",
            "step 7250 | loss_D 1.2539 | loss_G 1.4130 | D(real) +0.872 | D(fake) -0.036\n",
            "step 7260 | loss_D 0.8587 | loss_G 1.7430 | D(real) +0.123 | D(fake) -1.588\n",
            "step 7270 | loss_D 0.7618 | loss_G 1.3142 | D(real) +1.485 | D(fake) -0.409\n",
            "step 7280 | loss_D 1.0013 | loss_G 1.2001 | D(real) +1.846 | D(fake) +0.084\n",
            "step 7290 | loss_D 0.8296 | loss_G 1.2228 | D(real) +0.884 | D(fake) -0.629\n",
            "step 7300 | loss_D 0.8640 | loss_G 1.2544 | D(real) +1.921 | D(fake) -0.024\n",
            "step 7310 | loss_D 1.2979 | loss_G 1.0016 | D(real) -0.028 | D(fake) -0.318\n",
            "step 7320 | loss_D 0.9198 | loss_G 1.3879 | D(real) +0.928 | D(fake) -0.607\n",
            "step 7330 | loss_D 0.9793 | loss_G 0.8523 | D(real) +1.003 | D(fake) -0.464\n",
            "step 7340 | loss_D 0.5388 | loss_G 2.0316 | D(real) +1.294 | D(fake) -1.324\n",
            "step 7350 | loss_D 1.6341 | loss_G 1.2102 | D(real) +0.227 | D(fake) +0.486\n",
            "step 7360 | loss_D 0.8815 | loss_G 0.6841 | D(real) +1.099 | D(fake) -0.433\n",
            "step 7370 | loss_D 1.3045 | loss_G 1.0659 | D(real) +0.304 | D(fake) -0.188\n",
            "step 7380 | loss_D 1.0055 | loss_G 1.1728 | D(real) +0.323 | D(fake) -0.593\n",
            "step 7390 | loss_D 1.0486 | loss_G 1.2673 | D(real) +0.361 | D(fake) -0.771\n",
            "step 7400 | loss_D 0.6858 | loss_G 1.1772 | D(real) +1.228 | D(fake) -0.689\n",
            "step 7410 | loss_D 0.9696 | loss_G 0.8823 | D(real) +1.034 | D(fake) -0.268\n",
            "step 7420 | loss_D 1.2142 | loss_G 1.0190 | D(real) -0.084 | D(fake) -0.550\n",
            "step 7430 | loss_D 1.1197 | loss_G 0.8356 | D(real) +0.839 | D(fake) +0.052\n",
            "step 7440 | loss_D 0.9431 | loss_G 1.1870 | D(real) +0.907 | D(fake) -0.477\n",
            "step 7450 | loss_D 1.0232 | loss_G 1.1805 | D(real) +0.480 | D(fake) -0.830\n",
            "step 7460 | loss_D 0.9351 | loss_G 1.2883 | D(real) +1.015 | D(fake) -0.391\n",
            "step 7470 | loss_D 1.2608 | loss_G 1.1494 | D(real) +0.914 | D(fake) +0.330\n",
            "step 7480 | loss_D 0.6707 | loss_G 1.6357 | D(real) +1.166 | D(fake) -0.957\n",
            "step 7490 | loss_D 0.6911 | loss_G 1.9142 | D(real) +1.642 | D(fake) -1.203\n",
            "step 7500 | loss_D 1.4657 | loss_G 0.8061 | D(real) +0.445 | D(fake) +0.089\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_007500.pt\n",
            "step 7510 | loss_D 0.8465 | loss_G 1.7158 | D(real) +1.359 | D(fake) -0.201\n",
            "step 7520 | loss_D 1.0897 | loss_G 1.2155 | D(real) +0.141 | D(fake) -0.622\n",
            "step 7530 | loss_D 0.9547 | loss_G 0.9023 | D(real) +1.134 | D(fake) -0.113\n",
            "step 7540 | loss_D 0.8684 | loss_G 1.0868 | D(real) +1.264 | D(fake) -0.177\n",
            "step 7550 | loss_D 1.0893 | loss_G 1.2350 | D(real) +1.443 | D(fake) -0.332\n",
            "step 7560 | loss_D 0.9144 | loss_G 1.4418 | D(real) +0.949 | D(fake) -0.339\n",
            "step 7570 | loss_D 0.5321 | loss_G 1.2268 | D(real) +2.643 | D(fake) -0.585\n",
            "step 7580 | loss_D 1.0406 | loss_G 1.0453 | D(real) +0.637 | D(fake) -0.956\n",
            "step 7590 | loss_D 0.8377 | loss_G 1.4308 | D(real) +0.918 | D(fake) -0.749\n",
            "step 7600 | loss_D 0.9790 | loss_G 0.9821 | D(real) +0.662 | D(fake) -0.534\n",
            "step 7610 | loss_D 0.5647 | loss_G 1.7519 | D(real) +1.671 | D(fake) -0.859\n",
            "step 7620 | loss_D 1.0238 | loss_G 1.3077 | D(real) +0.768 | D(fake) -0.315\n",
            "step 7630 | loss_D 1.0712 | loss_G 0.9803 | D(real) +0.594 | D(fake) -0.240\n",
            "step 7640 | loss_D 0.7442 | loss_G 1.6793 | D(real) +1.096 | D(fake) -0.779\n",
            "step 7650 | loss_D 1.1211 | loss_G 0.9932 | D(real) +0.231 | D(fake) -0.466\n",
            "step 7660 | loss_D 0.6386 | loss_G 1.4110 | D(real) +1.216 | D(fake) -0.970\n",
            "step 7670 | loss_D 0.9736 | loss_G 1.3554 | D(real) +0.621 | D(fake) -0.559\n",
            "step 7680 | loss_D 0.6701 | loss_G 1.4874 | D(real) +0.862 | D(fake) -1.498\n",
            "step 7690 | loss_D 0.9944 | loss_G 1.2649 | D(real) +1.248 | D(fake) +0.009\n",
            "step 7700 | loss_D 1.3731 | loss_G 1.0872 | D(real) +0.085 | D(fake) -0.054\n",
            "step 7710 | loss_D 0.9727 | loss_G 2.2576 | D(real) +0.149 | D(fake) -1.166\n",
            "step 7720 | loss_D 1.2561 | loss_G 0.8662 | D(real) +1.078 | D(fake) +0.337\n",
            "step 7730 | loss_D 0.8080 | loss_G 1.2101 | D(real) +1.330 | D(fake) -0.372\n",
            "step 7740 | loss_D 1.1717 | loss_G 1.0228 | D(real) +0.219 | D(fake) -0.308\n",
            "step 7750 | loss_D 1.0302 | loss_G 1.2003 | D(real) +0.641 | D(fake) -0.434\n",
            "step 7760 | loss_D 1.0247 | loss_G 0.9523 | D(real) +1.618 | D(fake) +0.035\n",
            "step 7770 | loss_D 0.8797 | loss_G 1.4851 | D(real) +0.935 | D(fake) -1.046\n",
            "step 7780 | loss_D 1.2540 | loss_G 0.9254 | D(real) -0.126 | D(fake) -0.636\n",
            "step 7790 | loss_D 0.8758 | loss_G 1.0802 | D(real) +1.392 | D(fake) -0.308\n",
            "step 7800 | loss_D 1.2365 | loss_G 0.8001 | D(real) +1.085 | D(fake) +0.402\n",
            "step 7810 | loss_D 0.6099 | loss_G 1.4273 | D(real) +2.904 | D(fake) -1.118\n",
            "step 7820 | loss_D 0.8869 | loss_G 1.5714 | D(real) +0.707 | D(fake) -0.609\n",
            "step 7830 | loss_D 1.2046 | loss_G 1.1622 | D(real) +0.573 | D(fake) +0.036\n",
            "step 7840 | loss_D 0.9531 | loss_G 1.1799 | D(real) +0.540 | D(fake) -0.609\n",
            "step 7850 | loss_D 0.8890 | loss_G 1.3261 | D(real) +1.251 | D(fake) -0.266\n",
            "step 7860 | loss_D 0.8521 | loss_G 1.0620 | D(real) +0.882 | D(fake) -0.701\n",
            "step 7870 | loss_D 0.9815 | loss_G 0.9032 | D(real) +0.921 | D(fake) -0.340\n",
            "step 7880 | loss_D 0.7033 | loss_G 1.2904 | D(real) +1.209 | D(fake) -1.138\n",
            "step 7890 | loss_D 1.2754 | loss_G 0.9436 | D(real) +0.194 | D(fake) -0.105\n",
            "step 7900 | loss_D 1.0125 | loss_G 1.2911 | D(real) +2.400 | D(fake) +0.352\n",
            "step 7910 | loss_D 0.8008 | loss_G 1.2435 | D(real) +1.498 | D(fake) -0.286\n",
            "step 7920 | loss_D 0.8715 | loss_G 1.3159 | D(real) +1.624 | D(fake) -0.113\n",
            "step 7930 | loss_D 1.4956 | loss_G 1.1452 | D(real) -0.228 | D(fake) -0.476\n",
            "step 7940 | loss_D 1.0777 | loss_G 1.0171 | D(real) +0.207 | D(fake) -0.507\n",
            "step 7950 | loss_D 0.9269 | loss_G 1.7463 | D(real) +0.579 | D(fake) -0.657\n",
            "step 7960 | loss_D 1.3424 | loss_G 0.9567 | D(real) -0.078 | D(fake) -0.317\n",
            "step 7970 | loss_D 0.7529 | loss_G 1.4692 | D(real) +0.904 | D(fake) -1.024\n",
            "step 7980 | loss_D 1.3885 | loss_G 1.1060 | D(real) -0.008 | D(fake) -0.054\n",
            "step 7990 | loss_D 1.0591 | loss_G 0.8190 | D(real) +1.222 | D(fake) -0.056\n",
            "step 8000 | loss_D 1.1916 | loss_G 0.8976 | D(real) -0.215 | D(fake) -0.836\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_008000.pt\n",
            "step 8010 | loss_D 1.5193 | loss_G 1.0654 | D(real) -0.245 | D(fake) -0.050\n",
            "step 8020 | loss_D 0.7694 | loss_G 1.0335 | D(real) +1.533 | D(fake) -0.502\n",
            "step 8030 | loss_D 1.0090 | loss_G 1.3416 | D(real) +0.081 | D(fake) -0.888\n",
            "step 8040 | loss_D 1.3337 | loss_G 0.9751 | D(real) +0.032 | D(fake) -0.168\n",
            "step 8050 | loss_D 0.7795 | loss_G 1.7882 | D(real) +1.982 | D(fake) -0.686\n",
            "step 8060 | loss_D 1.3089 | loss_G 1.0053 | D(real) +0.123 | D(fake) -0.595\n",
            "step 8070 | loss_D 1.0874 | loss_G 0.8178 | D(real) +0.790 | D(fake) -0.053\n",
            "step 8080 | loss_D 0.8183 | loss_G 1.0896 | D(real) +0.707 | D(fake) -1.190\n",
            "step 8090 | loss_D 0.8844 | loss_G 1.3100 | D(real) +0.318 | D(fake) -0.983\n",
            "step 8100 | loss_D 1.1786 | loss_G 0.7963 | D(real) +0.080 | D(fake) -0.632\n",
            "step 8110 | loss_D 1.2044 | loss_G 1.3943 | D(real) +0.008 | D(fake) -0.605\n",
            "step 8120 | loss_D 0.7034 | loss_G 1.3538 | D(real) +1.031 | D(fake) -1.230\n",
            "step 8130 | loss_D 0.8815 | loss_G 1.2108 | D(real) +0.396 | D(fake) -0.951\n",
            "step 8140 | loss_D 1.4858 | loss_G 1.0157 | D(real) -0.250 | D(fake) -1.012\n",
            "step 8150 | loss_D 1.0992 | loss_G 1.3474 | D(real) +0.828 | D(fake) -0.145\n",
            "step 8160 | loss_D 1.1279 | loss_G 1.5081 | D(real) -0.166 | D(fake) -1.655\n",
            "step 8170 | loss_D 0.7805 | loss_G 1.0803 | D(real) +1.216 | D(fake) -0.766\n",
            "step 8180 | loss_D 0.8049 | loss_G 0.9549 | D(real) +1.215 | D(fake) -0.476\n",
            "step 8190 | loss_D 0.9224 | loss_G 1.0813 | D(real) +1.626 | D(fake) -0.367\n",
            "step 8200 | loss_D 0.7076 | loss_G 1.1615 | D(real) +2.045 | D(fake) -0.497\n",
            "step 8210 | loss_D 1.2745 | loss_G 1.2061 | D(real) -0.225 | D(fake) -1.321\n",
            "step 8220 | loss_D 1.1535 | loss_G 1.1480 | D(real) +0.346 | D(fake) -0.243\n",
            "step 8230 | loss_D 0.5659 | loss_G 2.1030 | D(real) +0.980 | D(fake) -2.000\n",
            "step 8240 | loss_D 1.1642 | loss_G 0.8461 | D(real) +0.686 | D(fake) -0.062\n",
            "step 8250 | loss_D 1.1661 | loss_G 0.9089 | D(real) +0.279 | D(fake) -0.323\n",
            "step 8260 | loss_D 0.9228 | loss_G 1.2204 | D(real) +0.670 | D(fake) -0.583\n",
            "step 8270 | loss_D 1.4663 | loss_G 0.7706 | D(real) -0.642 | D(fake) -0.793\n",
            "step 8280 | loss_D 0.7143 | loss_G 1.0084 | D(real) +0.808 | D(fake) -1.013\n",
            "step 8290 | loss_D 0.8681 | loss_G 1.3750 | D(real) +1.397 | D(fake) -0.366\n",
            "step 8300 | loss_D 1.2097 | loss_G 1.0814 | D(real) +0.018 | D(fake) -0.495\n",
            "step 8310 | loss_D 0.8503 | loss_G 1.3278 | D(real) +1.001 | D(fake) -1.146\n",
            "step 8320 | loss_D 0.6184 | loss_G 1.3316 | D(real) +1.432 | D(fake) -0.749\n",
            "step 8330 | loss_D 0.8207 | loss_G 1.0693 | D(real) +2.045 | D(fake) -0.159\n",
            "step 8340 | loss_D 0.7684 | loss_G 1.7700 | D(real) +1.069 | D(fake) -0.679\n",
            "step 8350 | loss_D 1.0568 | loss_G 1.4393 | D(real) +0.401 | D(fake) -0.451\n",
            "step 8360 | loss_D 1.1775 | loss_G 1.1849 | D(real) -0.128 | D(fake) -0.831\n",
            "step 8370 | loss_D 1.0462 | loss_G 1.2242 | D(real) +0.676 | D(fake) -0.406\n",
            "step 8380 | loss_D 1.2885 | loss_G 1.3592 | D(real) -0.117 | D(fake) -0.533\n",
            "step 8390 | loss_D 1.0156 | loss_G 1.3670 | D(real) +1.293 | D(fake) +0.005\n",
            "step 8400 | loss_D 1.4587 | loss_G 0.8685 | D(real) -0.008 | D(fake) -0.197\n",
            "step 8410 | loss_D 0.9591 | loss_G 0.7657 | D(real) +0.587 | D(fake) -0.526\n",
            "step 8420 | loss_D 1.0377 | loss_G 1.3346 | D(real) +0.474 | D(fake) -0.617\n",
            "step 8430 | loss_D 0.7238 | loss_G 0.7548 | D(real) +1.803 | D(fake) -0.429\n",
            "step 8440 | loss_D 1.2006 | loss_G 1.4683 | D(real) +0.430 | D(fake) -0.256\n",
            "step 8450 | loss_D 1.1859 | loss_G 0.9224 | D(real) +1.305 | D(fake) +0.159\n",
            "step 8460 | loss_D 0.8317 | loss_G 1.2279 | D(real) +0.935 | D(fake) -0.802\n",
            "step 8470 | loss_D 1.3186 | loss_G 1.0833 | D(real) -0.005 | D(fake) -0.501\n",
            "step 8480 | loss_D 1.3284 | loss_G 1.0042 | D(real) -0.188 | D(fake) -0.406\n",
            "step 8490 | loss_D 0.4401 | loss_G 1.4694 | D(real) +2.531 | D(fake) -0.908\n",
            "step 8500 | loss_D 1.2700 | loss_G 1.1565 | D(real) +0.703 | D(fake) +0.089\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_008500.pt\n",
            "step 8510 | loss_D 1.0938 | loss_G 1.3656 | D(real) +0.271 | D(fake) -0.499\n",
            "step 8520 | loss_D 1.2832 | loss_G 0.9349 | D(real) -0.334 | D(fake) -0.861\n",
            "step 8530 | loss_D 1.1646 | loss_G 1.0407 | D(real) +0.489 | D(fake) -0.511\n",
            "step 8540 | loss_D 1.2337 | loss_G 1.5556 | D(real) -0.302 | D(fake) -0.978\n",
            "step 8550 | loss_D 0.9322 | loss_G 0.9305 | D(real) +1.300 | D(fake) -0.169\n",
            "step 8560 | loss_D 1.0480 | loss_G 1.0122 | D(real) +1.142 | D(fake) +0.026\n",
            "step 8570 | loss_D 0.7360 | loss_G 1.2800 | D(real) +1.081 | D(fake) -0.834\n",
            "step 8580 | loss_D 1.5655 | loss_G 1.0008 | D(real) -0.759 | D(fake) -0.870\n",
            "step 8590 | loss_D 1.1523 | loss_G 0.7552 | D(real) +0.196 | D(fake) -0.703\n",
            "step 8600 | loss_D 1.0635 | loss_G 0.8576 | D(real) +0.185 | D(fake) -0.637\n",
            "step 8610 | loss_D 1.2081 | loss_G 1.2864 | D(real) +0.596 | D(fake) +0.015\n",
            "step 8620 | loss_D 1.5442 | loss_G 0.9357 | D(real) -0.688 | D(fake) -0.743\n",
            "step 8630 | loss_D 0.7466 | loss_G 1.2489 | D(real) +1.556 | D(fake) -0.654\n",
            "step 8640 | loss_D 1.1436 | loss_G 1.4098 | D(real) +0.734 | D(fake) -0.554\n",
            "step 8650 | loss_D 0.4619 | loss_G 2.3441 | D(real) +2.766 | D(fake) -1.013\n",
            "step 8660 | loss_D 0.8727 | loss_G 1.4322 | D(real) +1.200 | D(fake) -0.273\n",
            "step 8670 | loss_D 0.8764 | loss_G 1.0778 | D(real) +0.775 | D(fake) -0.556\n",
            "step 8680 | loss_D 1.5625 | loss_G 0.8885 | D(real) +0.023 | D(fake) +0.021\n",
            "step 8690 | loss_D 1.4588 | loss_G 0.6224 | D(real) -0.165 | D(fake) -0.244\n",
            "step 8700 | loss_D 0.9858 | loss_G 1.4273 | D(real) +0.812 | D(fake) -0.204\n",
            "step 8710 | loss_D 1.5762 | loss_G 0.6717 | D(real) -0.706 | D(fake) -0.567\n",
            "step 8720 | loss_D 1.3783 | loss_G 0.9259 | D(real) -0.365 | D(fake) -0.938\n",
            "step 8730 | loss_D 1.0670 | loss_G 1.1521 | D(real) +0.401 | D(fake) -0.909\n",
            "step 8740 | loss_D 0.8020 | loss_G 1.0089 | D(real) +0.702 | D(fake) -0.932\n",
            "step 8750 | loss_D 1.2236 | loss_G 1.1412 | D(real) -0.464 | D(fake) -1.281\n",
            "step 8760 | loss_D 0.6605 | loss_G 1.9185 | D(real) +1.374 | D(fake) -0.867\n",
            "step 8770 | loss_D 1.3923 | loss_G 1.0341 | D(real) +0.165 | D(fake) +0.095\n",
            "step 8780 | loss_D 0.5702 | loss_G 1.8260 | D(real) +1.411 | D(fake) -1.170\n",
            "step 8790 | loss_D 1.1854 | loss_G 1.2546 | D(real) +0.451 | D(fake) -0.527\n",
            "step 8800 | loss_D 0.6000 | loss_G 1.9081 | D(real) +2.027 | D(fake) -0.536\n",
            "step 8810 | loss_D 1.1211 | loss_G 0.9915 | D(real) +0.186 | D(fake) -0.936\n",
            "step 8820 | loss_D 1.2344 | loss_G 1.2025 | D(real) -0.083 | D(fake) -0.641\n",
            "step 8830 | loss_D 0.8904 | loss_G 1.4532 | D(real) +0.995 | D(fake) -0.908\n",
            "step 8840 | loss_D 0.6206 | loss_G 0.9182 | D(real) +1.840 | D(fake) -0.616\n",
            "step 8850 | loss_D 1.0290 | loss_G 0.9755 | D(real) +0.491 | D(fake) -0.498\n",
            "step 8860 | loss_D 0.9794 | loss_G 1.5424 | D(real) +0.808 | D(fake) -0.601\n",
            "step 8870 | loss_D 0.4693 | loss_G 1.4971 | D(real) +2.662 | D(fake) -0.768\n",
            "step 8880 | loss_D 1.0707 | loss_G 1.8777 | D(real) +0.951 | D(fake) -0.204\n",
            "step 8890 | loss_D 0.9199 | loss_G 1.2616 | D(real) +0.419 | D(fake) -0.935\n",
            "step 8900 | loss_D 1.5173 | loss_G 1.1467 | D(real) -0.454 | D(fake) -0.494\n",
            "step 8910 | loss_D 0.9020 | loss_G 0.8428 | D(real) +0.470 | D(fake) -0.720\n",
            "step 8920 | loss_D 1.2731 | loss_G 0.8340 | D(real) +0.010 | D(fake) -0.469\n",
            "step 8930 | loss_D 1.0799 | loss_G 1.1207 | D(real) +0.285 | D(fake) -0.587\n",
            "step 8940 | loss_D 1.2622 | loss_G 0.8373 | D(real) +0.223 | D(fake) -0.155\n",
            "step 8950 | loss_D 1.1892 | loss_G 1.3165 | D(real) +0.223 | D(fake) -0.573\n",
            "step 8960 | loss_D 1.1554 | loss_G 1.3510 | D(real) +0.300 | D(fake) -0.273\n",
            "step 8970 | loss_D 1.7848 | loss_G 0.7218 | D(real) -0.993 | D(fake) -1.020\n",
            "step 8980 | loss_D 1.0275 | loss_G 1.2672 | D(real) +0.749 | D(fake) -0.598\n",
            "step 8990 | loss_D 1.3514 | loss_G 0.8525 | D(real) -0.253 | D(fake) -0.603\n",
            "step 9000 | loss_D 1.0239 | loss_G 1.0082 | D(real) +0.119 | D(fake) -0.787\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_009000.pt\n",
            "step 9010 | loss_D 0.8021 | loss_G 1.3378 | D(real) +1.687 | D(fake) -0.439\n",
            "step 9020 | loss_D 1.0799 | loss_G 1.0322 | D(real) +0.183 | D(fake) -0.757\n",
            "step 9030 | loss_D 1.0326 | loss_G 0.9823 | D(real) +1.266 | D(fake) -0.199\n",
            "step 9040 | loss_D 1.0477 | loss_G 0.6727 | D(real) +0.446 | D(fake) -0.581\n",
            "step 9050 | loss_D 0.4655 | loss_G 1.8565 | D(real) +1.690 | D(fake) -1.287\n",
            "step 9060 | loss_D 0.4929 | loss_G 1.9863 | D(real) +1.728 | D(fake) -1.188\n",
            "step 9070 | loss_D 1.2708 | loss_G 1.4930 | D(real) -0.296 | D(fake) -1.316\n",
            "step 9080 | loss_D 0.9990 | loss_G 0.9376 | D(real) +0.797 | D(fake) -0.262\n",
            "step 9090 | loss_D 1.0507 | loss_G 1.3931 | D(real) +0.282 | D(fake) -0.590\n",
            "step 9100 | loss_D 0.9245 | loss_G 0.6692 | D(real) +0.365 | D(fake) -0.757\n",
            "step 9110 | loss_D 1.0889 | loss_G 0.8106 | D(real) +0.056 | D(fake) -0.829\n",
            "step 9120 | loss_D 0.6739 | loss_G 1.2031 | D(real) +1.538 | D(fake) -0.629\n",
            "step 9130 | loss_D 1.3017 | loss_G 0.9972 | D(real) +0.219 | D(fake) -0.139\n",
            "step 9140 | loss_D 1.1295 | loss_G 1.2089 | D(real) -0.093 | D(fake) -1.558\n",
            "step 9150 | loss_D 1.1998 | loss_G 1.0674 | D(real) -0.027 | D(fake) -0.512\n",
            "step 9160 | loss_D 1.1469 | loss_G 0.8059 | D(real) -0.033 | D(fake) -0.631\n",
            "step 9170 | loss_D 1.4626 | loss_G 0.8345 | D(real) -0.211 | D(fake) -0.243\n",
            "step 9180 | loss_D 1.0187 | loss_G 1.0983 | D(real) +0.313 | D(fake) -0.722\n",
            "step 9190 | loss_D 0.9487 | loss_G 1.0025 | D(real) +0.637 | D(fake) -0.555\n",
            "step 9200 | loss_D 0.7627 | loss_G 0.9073 | D(real) +1.841 | D(fake) -0.580\n",
            "step 9210 | loss_D 1.0468 | loss_G 1.2543 | D(real) +1.307 | D(fake) -0.788\n",
            "step 9220 | loss_D 0.7980 | loss_G 0.9574 | D(real) +1.717 | D(fake) -0.450\n",
            "step 9230 | loss_D 1.3322 | loss_G 1.2683 | D(real) -0.353 | D(fake) -0.677\n",
            "step 9240 | loss_D 1.1647 | loss_G 2.0895 | D(real) +0.678 | D(fake) -0.319\n",
            "step 9250 | loss_D 0.7736 | loss_G 1.8712 | D(real) +0.994 | D(fake) -1.241\n",
            "step 9260 | loss_D 0.6752 | loss_G 1.7571 | D(real) +1.660 | D(fake) -0.466\n",
            "step 9270 | loss_D 1.3367 | loss_G 1.1392 | D(real) -0.424 | D(fake) -0.953\n",
            "step 9280 | loss_D 1.0094 | loss_G 0.7963 | D(real) +0.801 | D(fake) -0.266\n",
            "step 9290 | loss_D 0.8897 | loss_G 0.9383 | D(real) +0.256 | D(fake) -1.116\n",
            "step 9300 | loss_D 0.9191 | loss_G 1.0075 | D(real) +0.925 | D(fake) -0.424\n",
            "step 9310 | loss_D 1.0824 | loss_G 1.2682 | D(real) +1.295 | D(fake) +0.092\n",
            "step 9320 | loss_D 1.0937 | loss_G 0.9796 | D(real) +1.025 | D(fake) +0.143\n",
            "step 9330 | loss_D 1.0095 | loss_G 0.9326 | D(real) +0.453 | D(fake) -0.514\n",
            "step 9340 | loss_D 1.3488 | loss_G 1.4548 | D(real) -0.104 | D(fake) -0.342\n",
            "step 9350 | loss_D 1.4131 | loss_G 1.3221 | D(real) -0.255 | D(fake) -0.866\n",
            "step 9360 | loss_D 0.7549 | loss_G 1.1900 | D(real) +0.974 | D(fake) -0.741\n",
            "step 9370 | loss_D 1.1445 | loss_G 0.7259 | D(real) +0.771 | D(fake) -0.092\n",
            "step 9380 | loss_D 0.8913 | loss_G 0.8675 | D(real) +0.911 | D(fake) -0.515\n",
            "step 9390 | loss_D 0.8171 | loss_G 1.2194 | D(real) +1.165 | D(fake) -0.732\n",
            "step 9400 | loss_D 0.7600 | loss_G 0.9758 | D(real) +1.121 | D(fake) -0.606\n",
            "step 9410 | loss_D 1.2242 | loss_G 0.9415 | D(real) +0.052 | D(fake) -0.513\n",
            "step 9420 | loss_D 1.0133 | loss_G 1.4933 | D(real) +0.758 | D(fake) -0.319\n",
            "step 9430 | loss_D 1.4286 | loss_G 1.3903 | D(real) +1.361 | D(fake) +0.474\n",
            "step 9440 | loss_D 0.7255 | loss_G 1.3883 | D(real) +0.665 | D(fake) -1.134\n",
            "step 9450 | loss_D 0.9400 | loss_G 0.8592 | D(real) +1.681 | D(fake) +0.002\n",
            "step 9460 | loss_D 1.0044 | loss_G 1.2932 | D(real) +0.777 | D(fake) -0.349\n",
            "step 9470 | loss_D 0.7521 | loss_G 1.0857 | D(real) +0.995 | D(fake) -0.734\n",
            "step 9480 | loss_D 1.0641 | loss_G 1.2302 | D(real) +0.488 | D(fake) -0.508\n",
            "step 9490 | loss_D 1.2692 | loss_G 0.9426 | D(real) +0.008 | D(fake) -0.544\n",
            "step 9500 | loss_D 0.7243 | loss_G 1.8081 | D(real) +1.157 | D(fake) -0.948\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_009500.pt\n",
            "step 9510 | loss_D 1.8601 | loss_G 1.1448 | D(real) -0.544 | D(fake) -0.274\n",
            "step 9520 | loss_D 1.0363 | loss_G 1.2049 | D(real) +0.904 | D(fake) -0.380\n",
            "step 9530 | loss_D 0.8232 | loss_G 0.9775 | D(real) +0.380 | D(fake) -1.395\n",
            "step 9540 | loss_D 1.2436 | loss_G 0.7431 | D(real) +2.199 | D(fake) +0.605\n",
            "step 9550 | loss_D 0.8507 | loss_G 1.1180 | D(real) +0.395 | D(fake) -1.077\n",
            "step 9560 | loss_D 0.9253 | loss_G 1.1718 | D(real) +0.750 | D(fake) -0.472\n",
            "step 9570 | loss_D 0.9419 | loss_G 1.4258 | D(real) +1.420 | D(fake) -0.479\n",
            "step 9580 | loss_D 1.3579 | loss_G 1.2101 | D(real) +0.216 | D(fake) -0.244\n",
            "step 9590 | loss_D 0.6818 | loss_G 1.0719 | D(real) +1.273 | D(fake) -0.828\n",
            "step 9600 | loss_D 1.1996 | loss_G 0.8125 | D(real) +0.589 | D(fake) +0.019\n",
            "step 9610 | loss_D 1.0609 | loss_G 1.2304 | D(real) +0.516 | D(fake) -0.450\n",
            "step 9620 | loss_D 1.2587 | loss_G 1.1129 | D(real) +0.433 | D(fake) +0.018\n",
            "step 9630 | loss_D 0.7748 | loss_G 1.8891 | D(real) +1.180 | D(fake) -0.905\n",
            "step 9640 | loss_D 0.6008 | loss_G 1.6984 | D(real) +1.278 | D(fake) -1.031\n",
            "step 9650 | loss_D 1.2899 | loss_G 0.9620 | D(real) +0.202 | D(fake) -0.434\n",
            "step 9660 | loss_D 0.8743 | loss_G 1.0750 | D(real) +1.330 | D(fake) -0.253\n",
            "step 9670 | loss_D 1.1294 | loss_G 0.8026 | D(real) +0.433 | D(fake) -0.229\n",
            "step 9680 | loss_D 0.9425 | loss_G 0.6292 | D(real) +0.286 | D(fake) -0.803\n",
            "step 9690 | loss_D 0.9268 | loss_G 1.3199 | D(real) +0.497 | D(fake) -0.645\n",
            "step 9700 | loss_D 0.7526 | loss_G 1.2325 | D(real) +0.603 | D(fake) -1.096\n",
            "step 9710 | loss_D 1.0721 | loss_G 0.9808 | D(real) -0.061 | D(fake) -1.107\n",
            "step 9720 | loss_D 1.2123 | loss_G 0.8848 | D(real) +0.238 | D(fake) -0.434\n",
            "step 9730 | loss_D 0.9607 | loss_G 1.3838 | D(real) +0.272 | D(fake) -1.276\n",
            "step 9740 | loss_D 1.1424 | loss_G 0.5864 | D(real) -0.088 | D(fake) -1.035\n",
            "step 9750 | loss_D 0.9245 | loss_G 1.1463 | D(real) +0.738 | D(fake) -0.532\n",
            "step 9760 | loss_D 0.7321 | loss_G 1.3067 | D(real) +0.589 | D(fake) -1.318\n",
            "step 9770 | loss_D 0.9701 | loss_G 1.4017 | D(real) +1.079 | D(fake) -0.157\n",
            "step 9780 | loss_D 0.9100 | loss_G 0.9270 | D(real) +1.101 | D(fake) -0.484\n",
            "step 9790 | loss_D 1.3544 | loss_G 1.1901 | D(real) -0.294 | D(fake) -0.492\n",
            "step 9800 | loss_D 0.8890 | loss_G 1.4975 | D(real) +1.471 | D(fake) -0.628\n",
            "step 9810 | loss_D 1.0130 | loss_G 0.9129 | D(real) +0.591 | D(fake) -0.552\n",
            "step 9820 | loss_D 0.7789 | loss_G 1.2407 | D(real) +0.745 | D(fake) -1.119\n",
            "step 9830 | loss_D 0.9214 | loss_G 1.2624 | D(real) +0.739 | D(fake) -0.583\n",
            "step 9840 | loss_D 1.1772 | loss_G 2.1279 | D(real) +1.449 | D(fake) -0.271\n",
            "step 9850 | loss_D 1.5024 | loss_G 1.0569 | D(real) +0.293 | D(fake) -0.027\n",
            "step 9860 | loss_D 1.1264 | loss_G 0.8729 | D(real) +0.736 | D(fake) -0.035\n",
            "step 9870 | loss_D 1.5189 | loss_G 0.8541 | D(real) -0.495 | D(fake) -0.387\n",
            "step 9880 | loss_D 0.8519 | loss_G 1.0110 | D(real) +1.121 | D(fake) -0.554\n",
            "step 9890 | loss_D 1.1745 | loss_G 0.8217 | D(real) +0.009 | D(fake) -0.593\n",
            "step 9900 | loss_D 1.0140 | loss_G 1.1799 | D(real) +0.557 | D(fake) -0.571\n",
            "step 9910 | loss_D 1.1415 | loss_G 1.1476 | D(real) +0.713 | D(fake) -0.132\n",
            "step 9920 | loss_D 1.1686 | loss_G 1.3285 | D(real) +0.683 | D(fake) -0.160\n",
            "step 9930 | loss_D 1.1120 | loss_G 1.0205 | D(real) +0.126 | D(fake) -0.612\n",
            "step 9940 | loss_D 0.8036 | loss_G 0.9280 | D(real) +0.700 | D(fake) -0.987\n",
            "step 9950 | loss_D 1.2978 | loss_G 0.9027 | D(real) +0.394 | D(fake) -0.389\n",
            "step 9960 | loss_D 0.9396 | loss_G 1.0422 | D(real) +0.604 | D(fake) -0.473\n",
            "step 9970 | loss_D 0.8966 | loss_G 1.1751 | D(real) +0.817 | D(fake) -0.490\n",
            "step 9980 | loss_D 1.0229 | loss_G 1.1719 | D(real) +0.578 | D(fake) -0.307\n",
            "step 9990 | loss_D 0.8386 | loss_G 1.1764 | D(real) +2.131 | D(fake) -0.412\n",
            "step 10000 | loss_D 1.0524 | loss_G 1.1145 | D(real) +0.174 | D(fake) -1.021\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_010000.pt\n",
            "step 10010 | loss_D 1.5499 | loss_G 0.9899 | D(real) -0.646 | D(fake) -0.572\n",
            "step 10020 | loss_D 0.8905 | loss_G 1.0475 | D(real) +1.783 | D(fake) -0.348\n",
            "step 10030 | loss_D 0.8396 | loss_G 1.3374 | D(real) +1.132 | D(fake) -0.552\n",
            "step 10040 | loss_D 1.3041 | loss_G 0.5975 | D(real) +0.183 | D(fake) -0.106\n",
            "step 10050 | loss_D 0.8981 | loss_G 0.8590 | D(real) +1.139 | D(fake) -0.292\n",
            "step 10060 | loss_D 1.1172 | loss_G 1.1104 | D(real) +0.285 | D(fake) -0.507\n",
            "step 10070 | loss_D 0.7542 | loss_G 1.4783 | D(real) +1.213 | D(fake) -0.629\n",
            "step 10080 | loss_D 0.6852 | loss_G 2.3585 | D(real) +0.979 | D(fake) -1.071\n",
            "step 10090 | loss_D 1.1821 | loss_G 1.3619 | D(real) +0.156 | D(fake) -0.309\n",
            "step 10100 | loss_D 1.1454 | loss_G 1.3130 | D(real) +1.227 | D(fake) -0.218\n",
            "step 10110 | loss_D 0.9128 | loss_G 1.4639 | D(real) +0.670 | D(fake) -0.744\n",
            "step 10120 | loss_D 0.9634 | loss_G 1.3480 | D(real) +2.264 | D(fake) -0.011\n",
            "step 10130 | loss_D 0.6959 | loss_G 1.3198 | D(real) +2.201 | D(fake) -0.649\n",
            "step 10140 | loss_D 0.8296 | loss_G 1.1414 | D(real) +0.728 | D(fake) -0.694\n",
            "step 10150 | loss_D 0.8521 | loss_G 0.9067 | D(real) +1.160 | D(fake) -0.548\n",
            "step 10160 | loss_D 1.2647 | loss_G 0.8320 | D(real) -0.080 | D(fake) -0.401\n",
            "step 10170 | loss_D 0.8270 | loss_G 1.1170 | D(real) +0.485 | D(fake) -0.986\n",
            "step 10180 | loss_D 1.2674 | loss_G 1.2899 | D(real) -0.320 | D(fake) -0.934\n",
            "step 10190 | loss_D 0.7006 | loss_G 1.1585 | D(real) +0.969 | D(fake) -1.151\n",
            "step 10200 | loss_D 1.4250 | loss_G 1.2786 | D(real) -0.455 | D(fake) -0.553\n",
            "step 10210 | loss_D 0.8960 | loss_G 1.1289 | D(real) +0.626 | D(fake) -0.828\n",
            "step 10220 | loss_D 0.7850 | loss_G 0.9896 | D(real) +1.147 | D(fake) -0.558\n",
            "step 10230 | loss_D 0.7894 | loss_G 1.3766 | D(real) +1.807 | D(fake) -0.542\n",
            "step 10240 | loss_D 0.8125 | loss_G 1.1696 | D(real) +1.428 | D(fake) -0.901\n",
            "step 10250 | loss_D 0.7009 | loss_G 1.2653 | D(real) +1.120 | D(fake) -0.736\n",
            "step 10260 | loss_D 0.8410 | loss_G 0.9708 | D(real) +0.569 | D(fake) -1.001\n",
            "step 10270 | loss_D 0.9942 | loss_G 1.3369 | D(real) +1.806 | D(fake) -0.420\n",
            "step 10280 | loss_D 1.2912 | loss_G 1.2401 | D(real) +1.507 | D(fake) -0.089\n",
            "step 10290 | loss_D 1.0605 | loss_G 1.1273 | D(real) +0.233 | D(fake) -0.544\n",
            "step 10300 | loss_D 1.1205 | loss_G 1.2169 | D(real) +0.627 | D(fake) -0.693\n",
            "step 10310 | loss_D 1.2685 | loss_G 0.7716 | D(real) -0.288 | D(fake) -0.670\n",
            "step 10320 | loss_D 0.5207 | loss_G 1.4992 | D(real) +1.723 | D(fake) -1.021\n",
            "step 10330 | loss_D 0.9692 | loss_G 1.3867 | D(real) +0.461 | D(fake) -1.103\n",
            "step 10340 | loss_D 0.9044 | loss_G 1.3081 | D(real) +0.942 | D(fake) -0.750\n",
            "step 10350 | loss_D 0.8934 | loss_G 1.3013 | D(real) +1.469 | D(fake) -0.183\n",
            "step 10360 | loss_D 0.9050 | loss_G 1.1249 | D(real) +0.959 | D(fake) -0.984\n",
            "step 10370 | loss_D 1.6636 | loss_G 1.8527 | D(real) -0.809 | D(fake) -1.441\n",
            "step 10380 | loss_D 1.1113 | loss_G 1.1736 | D(real) +1.324 | D(fake) +0.048\n",
            "step 10390 | loss_D 1.5502 | loss_G 0.7823 | D(real) -0.578 | D(fake) -1.350\n",
            "step 10400 | loss_D 0.8529 | loss_G 1.3068 | D(real) +2.744 | D(fake) -0.358\n",
            "step 10410 | loss_D 1.5637 | loss_G 1.0222 | D(real) -0.162 | D(fake) -0.432\n",
            "step 10420 | loss_D 1.3029 | loss_G 0.7963 | D(real) -0.070 | D(fake) -0.289\n",
            "step 10430 | loss_D 1.3262 | loss_G 0.8857 | D(real) -0.053 | D(fake) -0.413\n",
            "step 10440 | loss_D 0.9474 | loss_G 1.0128 | D(real) +0.465 | D(fake) -0.549\n",
            "step 10450 | loss_D 1.3180 | loss_G 0.8052 | D(real) +0.340 | D(fake) +0.035\n",
            "step 10460 | loss_D 0.5163 | loss_G 1.5430 | D(real) +1.577 | D(fake) -1.121\n",
            "step 10470 | loss_D 0.9126 | loss_G 1.0467 | D(real) +1.646 | D(fake) -0.341\n",
            "step 10480 | loss_D 0.7198 | loss_G 1.1536 | D(real) +1.223 | D(fake) -0.745\n",
            "step 10490 | loss_D 0.8374 | loss_G 1.5057 | D(real) +0.657 | D(fake) -1.125\n",
            "step 10500 | loss_D 1.2487 | loss_G 1.0730 | D(real) +0.710 | D(fake) -0.039\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_010500.pt\n",
            "step 10510 | loss_D 1.5763 | loss_G 0.9230 | D(real) +0.026 | D(fake) +0.148\n",
            "step 10520 | loss_D 0.5940 | loss_G 1.1300 | D(real) +1.936 | D(fake) -0.820\n",
            "step 10530 | loss_D 0.7265 | loss_G 1.7458 | D(real) +0.828 | D(fake) -0.908\n",
            "step 10540 | loss_D 1.0209 | loss_G 1.2552 | D(real) +1.153 | D(fake) -0.002\n",
            "step 10550 | loss_D 1.0886 | loss_G 0.6952 | D(real) +0.072 | D(fake) -0.854\n",
            "step 10560 | loss_D 1.0441 | loss_G 1.1046 | D(real) +1.000 | D(fake) -0.051\n",
            "step 10570 | loss_D 1.1730 | loss_G 0.7335 | D(real) +0.637 | D(fake) -0.171\n",
            "step 10580 | loss_D 0.8396 | loss_G 1.1494 | D(real) +1.034 | D(fake) -0.688\n",
            "step 10590 | loss_D 0.9758 | loss_G 1.1535 | D(real) +0.458 | D(fake) -0.931\n",
            "step 10600 | loss_D 0.6266 | loss_G 1.4476 | D(real) +0.735 | D(fake) -1.476\n",
            "step 10610 | loss_D 1.1658 | loss_G 1.0578 | D(real) +0.213 | D(fake) -0.656\n",
            "step 10620 | loss_D 1.1340 | loss_G 1.0432 | D(real) +0.751 | D(fake) -0.236\n",
            "step 10630 | loss_D 0.7759 | loss_G 0.9147 | D(real) +1.069 | D(fake) -0.802\n",
            "step 10640 | loss_D 1.1151 | loss_G 0.9469 | D(real) +0.087 | D(fake) -0.799\n",
            "step 10650 | loss_D 1.0797 | loss_G 0.9780 | D(real) +0.172 | D(fake) -0.543\n",
            "step 10660 | loss_D 0.7913 | loss_G 1.3685 | D(real) +1.369 | D(fake) -1.104\n",
            "step 10670 | loss_D 0.9835 | loss_G 0.8314 | D(real) +0.220 | D(fake) -0.804\n",
            "step 10680 | loss_D 1.0243 | loss_G 1.4700 | D(real) -0.003 | D(fake) -1.167\n",
            "step 10690 | loss_D 1.0237 | loss_G 1.4485 | D(real) +0.646 | D(fake) -0.357\n",
            "step 10700 | loss_D 0.9201 | loss_G 1.3691 | D(real) +0.704 | D(fake) -0.558\n",
            "step 10710 | loss_D 1.2783 | loss_G 1.1482 | D(real) +0.566 | D(fake) -0.062\n",
            "step 10720 | loss_D 0.6380 | loss_G 1.2766 | D(real) +1.302 | D(fake) -0.804\n",
            "step 10730 | loss_D 1.4519 | loss_G 0.7350 | D(real) -0.483 | D(fake) -0.711\n",
            "step 10740 | loss_D 0.9284 | loss_G 0.9145 | D(real) +0.375 | D(fake) -0.735\n",
            "step 10750 | loss_D 0.8948 | loss_G 1.3326 | D(real) +1.117 | D(fake) -0.370\n",
            "step 10760 | loss_D 0.9286 | loss_G 0.8883 | D(real) +2.324 | D(fake) +0.088\n",
            "step 10770 | loss_D 0.8053 | loss_G 1.1308 | D(real) +0.353 | D(fake) -1.491\n",
            "step 10780 | loss_D 0.8883 | loss_G 1.0967 | D(real) +0.935 | D(fake) -0.351\n",
            "step 10790 | loss_D 1.0749 | loss_G 1.8761 | D(real) +1.743 | D(fake) +0.217\n",
            "step 10800 | loss_D 0.8756 | loss_G 1.4180 | D(real) +1.729 | D(fake) -0.456\n",
            "step 10810 | loss_D 0.9037 | loss_G 1.0618 | D(real) +0.910 | D(fake) -0.342\n",
            "step 10820 | loss_D 0.9134 | loss_G 1.0352 | D(real) +1.209 | D(fake) -0.490\n",
            "step 10830 | loss_D 0.8993 | loss_G 1.3474 | D(real) +0.480 | D(fake) -0.883\n",
            "step 10840 | loss_D 0.9881 | loss_G 1.2358 | D(real) +0.764 | D(fake) -0.401\n",
            "step 10850 | loss_D 1.4912 | loss_G 0.7615 | D(real) -0.517 | D(fake) -0.508\n",
            "step 10860 | loss_D 1.0218 | loss_G 1.0887 | D(real) +0.635 | D(fake) -0.383\n",
            "step 10870 | loss_D 1.1151 | loss_G 1.1505 | D(real) +0.158 | D(fake) -1.198\n",
            "step 10880 | loss_D 0.6809 | loss_G 1.5424 | D(real) +1.177 | D(fake) -1.379\n",
            "step 10890 | loss_D 0.9303 | loss_G 1.2909 | D(real) +0.598 | D(fake) -1.035\n",
            "step 10900 | loss_D 0.8537 | loss_G 1.2204 | D(real) +1.476 | D(fake) -0.150\n",
            "step 10910 | loss_D 1.0604 | loss_G 0.9697 | D(real) +0.489 | D(fake) -0.792\n",
            "step 10920 | loss_D 1.0950 | loss_G 1.0061 | D(real) +0.335 | D(fake) -0.476\n",
            "step 10930 | loss_D 0.9881 | loss_G 1.3874 | D(real) +0.397 | D(fake) -0.674\n",
            "step 10940 | loss_D 0.8688 | loss_G 1.6216 | D(real) +1.650 | D(fake) -0.580\n",
            "step 10950 | loss_D 1.0586 | loss_G 0.5709 | D(real) +0.619 | D(fake) -0.666\n",
            "step 10960 | loss_D 1.0072 | loss_G 0.9331 | D(real) +0.570 | D(fake) -1.202\n",
            "step 10970 | loss_D 1.1833 | loss_G 0.8420 | D(real) +0.740 | D(fake) +0.036\n",
            "step 10980 | loss_D 0.7873 | loss_G 1.4544 | D(real) +1.041 | D(fake) -0.943\n",
            "step 10990 | loss_D 0.9647 | loss_G 1.0732 | D(real) +0.734 | D(fake) -0.461\n",
            "step 11000 | loss_D 1.3358 | loss_G 0.8432 | D(real) -0.208 | D(fake) -0.547\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011000.pt\n",
            "step 11010 | loss_D 0.9088 | loss_G 1.1787 | D(real) +1.317 | D(fake) -0.391\n",
            "step 11020 | loss_D 1.4373 | loss_G 1.3759 | D(real) -0.112 | D(fake) -0.082\n",
            "step 11030 | loss_D 0.9313 | loss_G 0.9848 | D(real) +1.261 | D(fake) -0.127\n",
            "step 11040 | loss_D 0.7160 | loss_G 1.5758 | D(real) +1.866 | D(fake) -0.414\n",
            "step 11050 | loss_D 0.7877 | loss_G 1.0467 | D(real) +1.231 | D(fake) -0.535\n",
            "step 11060 | loss_D 0.4701 | loss_G 2.1158 | D(real) +1.406 | D(fake) -1.492\n",
            "step 11070 | loss_D 0.9509 | loss_G 1.1491 | D(real) +0.491 | D(fake) -0.722\n",
            "step 11080 | loss_D 0.9009 | loss_G 1.3354 | D(real) +0.703 | D(fake) -0.518\n",
            "step 11090 | loss_D 1.0801 | loss_G 1.1825 | D(real) +0.374 | D(fake) -0.486\n",
            "step 11100 | loss_D 1.0565 | loss_G 0.9922 | D(real) +0.923 | D(fake) -0.405\n",
            "step 11110 | loss_D 0.8331 | loss_G 1.4825 | D(real) +2.811 | D(fake) +0.036\n",
            "step 11120 | loss_D 0.9708 | loss_G 1.5050 | D(real) +0.750 | D(fake) -0.391\n",
            "step 11130 | loss_D 1.0082 | loss_G 1.2684 | D(real) +0.522 | D(fake) -0.379\n",
            "step 11140 | loss_D 1.2091 | loss_G 0.8988 | D(real) +0.575 | D(fake) -0.126\n",
            "step 11150 | loss_D 0.7916 | loss_G 1.5270 | D(real) +1.079 | D(fake) -0.556\n",
            "step 11160 | loss_D 1.1063 | loss_G 1.2294 | D(real) +1.247 | D(fake) -0.088\n",
            "step 11170 | loss_D 0.8891 | loss_G 1.2719 | D(real) +0.641 | D(fake) -0.649\n",
            "step 11180 | loss_D 1.1693 | loss_G 0.9786 | D(real) +0.093 | D(fake) -0.495\n",
            "step 11190 | loss_D 1.0247 | loss_G 1.0998 | D(real) +1.190 | D(fake) -0.326\n",
            "step 11200 | loss_D 1.1506 | loss_G 0.9866 | D(real) +0.514 | D(fake) -0.189\n",
            "step 11210 | loss_D 1.2512 | loss_G 1.1169 | D(real) +0.506 | D(fake) +0.071\n",
            "step 11220 | loss_D 1.0362 | loss_G 1.2306 | D(real) +0.407 | D(fake) -0.584\n",
            "step 11230 | loss_D 0.5340 | loss_G 1.7797 | D(real) +1.559 | D(fake) -0.984\n",
            "step 11240 | loss_D 1.5993 | loss_G 1.5946 | D(real) +0.449 | D(fake) +0.469\n",
            "step 11250 | loss_D 1.0603 | loss_G 1.2037 | D(real) +0.298 | D(fake) -0.655\n",
            "step 11260 | loss_D 0.9941 | loss_G 1.3998 | D(real) +0.697 | D(fake) -0.257\n",
            "step 11270 | loss_D 0.9355 | loss_G 1.0835 | D(real) +0.308 | D(fake) -0.922\n",
            "step 11280 | loss_D 1.0130 | loss_G 1.1416 | D(real) +0.535 | D(fake) -0.417\n",
            "step 11290 | loss_D 1.5065 | loss_G 0.6172 | D(real) -0.113 | D(fake) -0.004\n",
            "step 11300 | loss_D 0.7690 | loss_G 1.3138 | D(real) +0.981 | D(fake) -0.972\n",
            "step 11310 | loss_D 0.6848 | loss_G 1.2515 | D(real) +1.920 | D(fake) -0.408\n",
            "step 11320 | loss_D 0.7960 | loss_G 1.5322 | D(real) +1.617 | D(fake) -0.405\n",
            "step 11330 | loss_D 0.8185 | loss_G 1.0993 | D(real) +1.292 | D(fake) -0.393\n",
            "step 11340 | loss_D 1.4352 | loss_G 1.3422 | D(real) +0.151 | D(fake) -0.063\n",
            "step 11350 | loss_D 0.7167 | loss_G 1.5463 | D(real) +0.943 | D(fake) -0.874\n",
            "step 11360 | loss_D 1.0976 | loss_G 1.0609 | D(real) +0.260 | D(fake) -0.457\n",
            "step 11370 | loss_D 1.0839 | loss_G 1.4973 | D(real) +1.482 | D(fake) +0.051\n",
            "step 11380 | loss_D 1.0451 | loss_G 1.1416 | D(real) +0.295 | D(fake) -0.668\n",
            "step 11390 | loss_D 0.6595 | loss_G 1.8153 | D(real) +1.543 | D(fake) -0.693\n",
            "step 11400 | loss_D 0.8703 | loss_G 1.3810 | D(real) +0.565 | D(fake) -1.044\n",
            "step 11410 | loss_D 1.1042 | loss_G 1.2739 | D(real) +0.007 | D(fake) -0.782\n",
            "step 11420 | loss_D 1.1725 | loss_G 1.3635 | D(real) +0.837 | D(fake) +0.094\n",
            "step 11430 | loss_D 0.8840 | loss_G 0.9261 | D(real) +0.523 | D(fake) -0.695\n",
            "step 11440 | loss_D 0.9500 | loss_G 1.1383 | D(real) +0.819 | D(fake) -0.405\n",
            "step 11450 | loss_D 1.3272 | loss_G 0.8950 | D(real) +0.191 | D(fake) -0.210\n",
            "step 11460 | loss_D 1.2374 | loss_G 0.8961 | D(real) +0.872 | D(fake) -0.023\n",
            "step 11470 | loss_D 0.8820 | loss_G 1.7637 | D(real) +0.849 | D(fake) -0.552\n",
            "step 11480 | loss_D 1.0961 | loss_G 1.2472 | D(real) +0.646 | D(fake) -0.331\n",
            "step 11490 | loss_D 0.9250 | loss_G 1.5636 | D(real) +0.606 | D(fake) -1.241\n",
            "step 11500 | loss_D 0.9476 | loss_G 0.9033 | D(real) +1.475 | D(fake) +0.050\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\n",
            "step 11510 | loss_D 0.5822 | loss_G 1.5324 | D(real) +2.006 | D(fake) -0.647\n",
            "step 11520 | loss_D 1.5743 | loss_G 0.8225 | D(real) +0.029 | D(fake) +0.114\n",
            "step 11530 | loss_D 0.9461 | loss_G 1.0334 | D(real) +1.099 | D(fake) -0.165\n",
            "step 11540 | loss_D 0.9821 | loss_G 1.1304 | D(real) +1.151 | D(fake) -0.080\n",
            "step 11550 | loss_D 1.0866 | loss_G 0.9872 | D(real) +0.038 | D(fake) -0.916\n",
            "step 11560 | loss_D 1.0052 | loss_G 1.3534 | D(real) -0.028 | D(fake) -1.281\n",
            "step 11570 | loss_D 0.7092 | loss_G 0.8707 | D(real) +0.916 | D(fake) -1.049\n",
            "step 11580 | loss_D 1.0734 | loss_G 1.0904 | D(real) +0.162 | D(fake) -0.743\n",
            "step 11590 | loss_D 1.1935 | loss_G 0.6849 | D(real) -0.078 | D(fake) -0.883\n",
            "step 11600 | loss_D 0.8303 | loss_G 1.0669 | D(real) +0.721 | D(fake) -0.753\n",
            "step 11610 | loss_D 1.1787 | loss_G 1.0106 | D(real) +0.663 | D(fake) -0.656\n",
            "step 11620 | loss_D 1.0252 | loss_G 1.0685 | D(real) +0.255 | D(fake) -0.659\n",
            "step 11630 | loss_D 0.7002 | loss_G 0.7377 | D(real) +0.980 | D(fake) -1.361\n",
            "step 11640 | loss_D 0.9099 | loss_G 1.2683 | D(real) +0.381 | D(fake) -0.767\n",
            "step 11650 | loss_D 0.9013 | loss_G 1.7095 | D(real) +1.102 | D(fake) -0.547\n",
            "step 11660 | loss_D 0.9979 | loss_G 1.1327 | D(real) +0.388 | D(fake) -0.740\n",
            "step 11670 | loss_D 1.1802 | loss_G 1.4890 | D(real) -0.235 | D(fake) -0.905\n",
            "step 11680 | loss_D 1.3935 | loss_G 1.0494 | D(real) -0.177 | D(fake) -0.538\n",
            "step 11690 | loss_D 1.4220 | loss_G 1.1582 | D(real) -0.343 | D(fake) -0.374\n",
            "step 11700 | loss_D 0.8825 | loss_G 0.6854 | D(real) +0.707 | D(fake) -0.559\n",
            "step 11710 | loss_D 0.9951 | loss_G 0.8703 | D(real) +1.363 | D(fake) -0.003\n",
            "step 11720 | loss_D 1.2532 | loss_G 0.9086 | D(real) -0.385 | D(fake) -0.917\n",
            "step 11730 | loss_D 1.2762 | loss_G 0.8143 | D(real) +0.207 | D(fake) -0.557\n",
            "step 11740 | loss_D 0.5888 | loss_G 1.6127 | D(real) +1.060 | D(fake) -1.336\n",
            "step 11750 | loss_D 1.0290 | loss_G 0.6407 | D(real) +0.182 | D(fake) -0.829\n",
            "step 11760 | loss_D 0.8854 | loss_G 1.1877 | D(real) +0.659 | D(fake) -0.644\n",
            "step 11770 | loss_D 1.1157 | loss_G 1.2266 | D(real) +0.016 | D(fake) -1.039\n",
            "step 11780 | loss_D 1.5316 | loss_G 1.2024 | D(real) -0.446 | D(fake) -0.558\n",
            "step 11790 | loss_D 0.5619 | loss_G 1.3250 | D(real) +2.029 | D(fake) -0.728\n",
            "step 11800 | loss_D 0.8415 | loss_G 1.0235 | D(real) +0.987 | D(fake) -0.639\n",
            "step 11810 | loss_D 0.9912 | loss_G 1.2247 | D(real) +1.034 | D(fake) -0.230\n",
            "step 11820 | loss_D 0.8900 | loss_G 0.7676 | D(real) +1.350 | D(fake) -0.202\n",
            "step 11830 | loss_D 0.8704 | loss_G 1.3096 | D(real) +0.874 | D(fake) -0.646\n",
            "step 11840 | loss_D 1.2559 | loss_G 0.8915 | D(real) +0.687 | D(fake) -0.045\n",
            "step 11850 | loss_D 0.6734 | loss_G 1.2539 | D(real) +1.001 | D(fake) -0.981\n",
            "step 11860 | loss_D 0.9883 | loss_G 0.7329 | D(real) +0.305 | D(fake) -0.742\n",
            "step 11870 | loss_D 1.0847 | loss_G 0.9148 | D(real) +0.029 | D(fake) -0.823\n",
            "step 11880 | loss_D 1.1495 | loss_G 0.8572 | D(real) -0.019 | D(fake) -0.764\n",
            "step 11890 | loss_D 1.2206 | loss_G 1.0591 | D(real) -0.166 | D(fake) -0.665\n",
            "step 11900 | loss_D 1.3876 | loss_G 1.1009 | D(real) +0.093 | D(fake) +0.072\n",
            "step 11910 | loss_D 0.8159 | loss_G 1.0956 | D(real) +1.087 | D(fake) -0.552\n",
            "step 11920 | loss_D 1.5831 | loss_G 1.2545 | D(real) +0.583 | D(fake) +0.414\n",
            "step 11930 | loss_D 1.0350 | loss_G 0.9991 | D(real) +1.170 | D(fake) -0.252\n",
            "step 11940 | loss_D 1.2145 | loss_G 1.2866 | D(real) -0.364 | D(fake) -1.269\n",
            "step 11950 | loss_D 1.1114 | loss_G 1.1692 | D(real) +0.444 | D(fake) -0.182\n",
            "step 11960 | loss_D 1.2996 | loss_G 0.8227 | D(real) +0.319 | D(fake) +0.105\n",
            "step 11970 | loss_D 0.9366 | loss_G 1.2292 | D(real) +0.611 | D(fake) -0.491\n",
            "step 11980 | loss_D 1.1893 | loss_G 1.4127 | D(real) +0.573 | D(fake) +0.050\n",
            "step 11990 | loss_D 0.9937 | loss_G 1.3253 | D(real) +1.167 | D(fake) -0.130\n"
          ]
        }
      ],
      "source": [
        "resume_from_ckpt(\n",
        "    ckpt_path=\"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_128_12000_iters/gan_step_002500.pt\",\n",
        "    total_iters=12000,\n",
        "    RUN_DIR=\"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters\",\n",
        "    SAMPLE_EVERY=500,\n",
        "    CHKPT_EVERY=500,\n",
        "    dl=dl, G=G, D=D,\n",
        "    opt_G=opt_G, opt_D=opt_D,\n",
        "    criterion=criterion,\n",
        "    save_samples=save_samples,\n",
        "    DEVICE=DEVICE,\n",
        "    Z_DIM=Z_DIM,\n",
        "    use_amp=use_amp,\n",
        "    scaler_D=scaler_D,\n",
        "    scaler_G=scaler_G\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m8VObUFUCZqy",
      "metadata": {
        "id": "m8VObUFUCZqy"
      },
      "source": [
        "# Implement RL Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I8Ti4ZTQCdz3",
      "metadata": {
        "id": "I8Ti4ZTQCdz3"
      },
      "source": [
        "### Load weights from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HQtPf4JoC2K9",
      "metadata": {
        "id": "HQtPf4JoC2K9"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dOET8jiDJaO",
      "metadata": {
        "id": "3dOET8jiDJaO"
      },
      "outputs": [],
      "source": [
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)\n",
        "D = models.Discriminator_64(img_channels=3, base=64).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pjhi61VbCm1n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjhi61VbCm1n",
        "outputId": "6500eb93-4e4d-4406-e4b5-422807563ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded checkpoint step: 11500\n"
          ]
        }
      ],
      "source": [
        "ckpt_path = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\"\n",
        "ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
        "\n",
        "G.load_state_dict(ckpt[\"G\"])\n",
        "D.load_state_dict(ckpt[\"D\"])\n",
        "\n",
        "G.eval()\n",
        "D.eval()\n",
        "\n",
        "print(\"Loaded checkpoint step:\", ckpt.get(\"step\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CKip372aG5-f",
      "metadata": {
        "id": "CKip372aG5-f"
      },
      "outputs": [],
      "source": [
        "# Freezing weights\n",
        "for p in G.parameters(): p.requires_grad_(False)\n",
        "for p in D.parameters(): p.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XZfG5p43IBDt",
      "metadata": {
        "id": "XZfG5p43IBDt"
      },
      "source": [
        "### Latent Bank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-EwLZa9nHT9g",
      "metadata": {
        "id": "-EwLZa9nHT9g"
      },
      "outputs": [],
      "source": [
        "K = 512\n",
        "Z_DIM = 128\n",
        "\n",
        "Z_bank = torch.randn(K, Z_DIM, device=DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "khYFmTt-IFvr",
      "metadata": {
        "id": "khYFmTt-IFvr"
      },
      "source": [
        "### Reward Function Using Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t6Rgcm7xILjv",
      "metadata": {
        "id": "t6Rgcm7xILjv"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def reward_from_latent(z_batch):\n",
        "\n",
        "    fake = G(z_batch)\n",
        "    logits = D(fake)\n",
        "    r = torch.sigmoid(logits)\n",
        "    return r"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pBxWXdVqLvUG",
      "metadata": {
        "id": "pBxWXdVqLvUG"
      },
      "source": [
        "### Tabular Q-Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LJ_V2iBNLz-J",
      "metadata": {
        "id": "LJ_V2iBNLz-J"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kev0_oVQLxmq",
      "metadata": {
        "id": "Kev0_oVQLxmq"
      },
      "outputs": [],
      "source": [
        "Q = torch.zeros(K, device=DEVICE)\n",
        "\n",
        "def epsilon_by_step(t, eps_start=0.2, eps_end=0.05, decay_steps=5000):\n",
        "    if t >= decay_steps:\n",
        "        return eps_end\n",
        "    return eps_end + (eps_start - eps_end) * (1 - t / decay_steps)\n",
        "\n",
        "def sample_action(Q, eps):\n",
        "    if torch.rand(()) < eps:\n",
        "        return torch.randint(0, K, (1,), device=Q.device).item()\n",
        "    return torch.argmax(Q).item()\n",
        "\n",
        "def update_Q(Q, a, r, alpha=0.1):\n",
        "\n",
        "    Q[a] = (1 - alpha) * Q[a] + alpha * r"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FSBnQOGHMNCE",
      "metadata": {
        "id": "FSBnQOGHMNCE"
      },
      "source": [
        "## Train RL Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ZFseoWaMOu4",
      "metadata": {
        "id": "0ZFseoWaMOu4"
      },
      "outputs": [],
      "source": [
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LOuzUnzwMQzN",
      "metadata": {
        "id": "LOuzUnzwMQzN"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def run_rl_latent_selection(\n",
        "    steps=10000,\n",
        "    batch_size=16,\n",
        "    alpha=0.1,\n",
        "    print_every=50,\n",
        "):\n",
        "    rewards_ma = deque(maxlen=200)\n",
        "    action_hist = torch.zeros(K, device=DEVICE)\n",
        "\n",
        "    for t in range(steps):\n",
        "        eps = epsilon_by_step(t)\n",
        "\n",
        "        a = sample_action(Q, eps)\n",
        "        action_hist[a] += 1\n",
        "\n",
        "        # evaluate chosen latent\n",
        "        z = Z_bank[a].unsqueeze(0).repeat(batch_size, 1)  # [B, Z_DIM]\n",
        "        r = reward_from_latent(z).mean().item()\n",
        "\n",
        "        update_Q(Q, a, r, alpha=alpha)\n",
        "        rewards_ma.append(r)\n",
        "\n",
        "        if (t % print_every) == 0:\n",
        "            # policy entropy estimate from action histogram\n",
        "            p = (action_hist / action_hist.sum()).clamp_min(1e-12)\n",
        "            entropy = float(-(p * p.log()).sum().item())\n",
        "\n",
        "            print(f\"t={t:05d} | eps={eps:.3f} | r={r:.3f} | r_ma={sum(rewards_ma)/len(rewards_ma):.3f} | H={entropy:.2f}\")\n",
        "\n",
        "    return Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rbrq6CVRMVu7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbrq6CVRMVu7",
        "outputId": "c32d52cd-c854-4b18-e616-f839fe8311b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=00000 | eps=0.200 | r=0.475 | r_ma=0.475 | H=0.00\n",
            "t=00050 | eps=0.199 | r=0.475 | r_ma=0.462 | H=0.48\n",
            "t=00100 | eps=0.197 | r=0.475 | r_ma=0.455 | H=0.88\n",
            "t=00150 | eps=0.196 | r=0.475 | r_ma=0.451 | H=0.94\n",
            "t=00200 | eps=0.194 | r=0.475 | r_ma=0.454 | H=0.83\n",
            "t=00250 | eps=0.193 | r=0.475 | r_ma=0.450 | H=0.89\n",
            "t=00300 | eps=0.191 | r=0.475 | r_ma=0.454 | H=0.92\n",
            "t=00350 | eps=0.190 | r=0.475 | r_ma=0.456 | H=0.95\n",
            "t=00400 | eps=0.188 | r=0.475 | r_ma=0.457 | H=0.98\n",
            "t=00450 | eps=0.187 | r=0.475 | r_ma=0.460 | H=1.05\n",
            "t=00500 | eps=0.185 | r=0.475 | r_ma=0.460 | H=1.06\n",
            "t=00550 | eps=0.184 | r=0.475 | r_ma=0.458 | H=1.18\n",
            "t=00600 | eps=0.182 | r=0.475 | r_ma=0.452 | H=1.20\n",
            "t=00650 | eps=0.180 | r=0.475 | r_ma=0.454 | H=1.19\n",
            "t=00700 | eps=0.179 | r=0.475 | r_ma=0.455 | H=1.15\n",
            "t=00750 | eps=0.177 | r=0.338 | r_ma=0.453 | H=1.23\n",
            "t=00800 | eps=0.176 | r=0.475 | r_ma=0.455 | H=1.24\n",
            "t=00850 | eps=0.175 | r=0.475 | r_ma=0.453 | H=1.26\n",
            "t=00900 | eps=0.173 | r=0.475 | r_ma=0.446 | H=1.30\n",
            "t=00950 | eps=0.172 | r=0.475 | r_ma=0.451 | H=1.29\n",
            "t=01000 | eps=0.170 | r=0.299 | r_ma=0.449 | H=1.30\n",
            "t=01050 | eps=0.169 | r=0.475 | r_ma=0.454 | H=1.27\n",
            "t=01100 | eps=0.167 | r=0.257 | r_ma=0.455 | H=1.28\n",
            "t=01150 | eps=0.166 | r=0.398 | r_ma=0.455 | H=1.29\n",
            "t=01200 | eps=0.164 | r=0.431 | r_ma=0.455 | H=1.32\n",
            "t=01250 | eps=0.163 | r=0.281 | r_ma=0.449 | H=1.34\n",
            "t=01300 | eps=0.161 | r=0.351 | r_ma=0.450 | H=1.36\n",
            "t=01350 | eps=0.160 | r=0.475 | r_ma=0.449 | H=1.36\n",
            "t=01400 | eps=0.158 | r=0.475 | r_ma=0.453 | H=1.35\n",
            "t=01450 | eps=0.157 | r=0.475 | r_ma=0.456 | H=1.34\n",
            "t=01500 | eps=0.155 | r=0.245 | r_ma=0.453 | H=1.36\n",
            "t=01550 | eps=0.154 | r=0.475 | r_ma=0.455 | H=1.34\n",
            "t=01600 | eps=0.152 | r=0.475 | r_ma=0.455 | H=1.34\n",
            "t=01650 | eps=0.151 | r=0.475 | r_ma=0.455 | H=1.33\n",
            "t=01700 | eps=0.149 | r=0.475 | r_ma=0.462 | H=1.31\n",
            "t=01750 | eps=0.148 | r=0.475 | r_ma=0.456 | H=1.32\n",
            "t=01800 | eps=0.146 | r=0.475 | r_ma=0.459 | H=1.31\n",
            "t=01850 | eps=0.145 | r=0.475 | r_ma=0.456 | H=1.31\n",
            "t=01900 | eps=0.143 | r=0.475 | r_ma=0.454 | H=1.30\n",
            "t=01950 | eps=0.142 | r=0.475 | r_ma=0.453 | H=1.32\n",
            "t=02000 | eps=0.140 | r=0.475 | r_ma=0.453 | H=1.31\n",
            "t=02050 | eps=0.139 | r=0.475 | r_ma=0.457 | H=1.31\n",
            "t=02100 | eps=0.137 | r=0.475 | r_ma=0.458 | H=1.30\n",
            "t=02150 | eps=0.136 | r=0.475 | r_ma=0.464 | H=1.31\n",
            "t=02200 | eps=0.134 | r=0.475 | r_ma=0.464 | H=1.30\n",
            "t=02250 | eps=0.133 | r=0.475 | r_ma=0.460 | H=1.31\n",
            "t=02300 | eps=0.131 | r=0.475 | r_ma=0.458 | H=1.31\n",
            "t=02350 | eps=0.130 | r=0.475 | r_ma=0.459 | H=1.31\n",
            "t=02400 | eps=0.128 | r=0.475 | r_ma=0.458 | H=1.31\n",
            "t=02450 | eps=0.127 | r=0.552 | r_ma=0.465 | H=1.29\n",
            "t=02500 | eps=0.125 | r=0.475 | r_ma=0.465 | H=1.30\n",
            "t=02550 | eps=0.124 | r=0.475 | r_ma=0.462 | H=1.29\n",
            "t=02600 | eps=0.122 | r=0.475 | r_ma=0.463 | H=1.28\n",
            "t=02650 | eps=0.121 | r=0.348 | r_ma=0.458 | H=1.29\n",
            "t=02700 | eps=0.119 | r=0.475 | r_ma=0.453 | H=1.30\n",
            "t=02750 | eps=0.118 | r=0.475 | r_ma=0.451 | H=1.31\n",
            "t=02800 | eps=0.116 | r=0.475 | r_ma=0.449 | H=1.30\n",
            "t=02850 | eps=0.115 | r=0.475 | r_ma=0.448 | H=1.30\n",
            "t=02900 | eps=0.113 | r=0.475 | r_ma=0.455 | H=1.29\n",
            "t=02950 | eps=0.112 | r=0.520 | r_ma=0.458 | H=1.30\n",
            "t=03000 | eps=0.110 | r=0.475 | r_ma=0.460 | H=1.29\n",
            "t=03050 | eps=0.109 | r=0.475 | r_ma=0.463 | H=1.28\n",
            "t=03100 | eps=0.107 | r=0.475 | r_ma=0.463 | H=1.27\n",
            "t=03150 | eps=0.106 | r=0.475 | r_ma=0.466 | H=1.27\n",
            "t=03200 | eps=0.104 | r=0.475 | r_ma=0.464 | H=1.27\n",
            "t=03250 | eps=0.103 | r=0.475 | r_ma=0.462 | H=1.27\n",
            "t=03300 | eps=0.101 | r=0.475 | r_ma=0.464 | H=1.25\n",
            "t=03350 | eps=0.100 | r=0.475 | r_ma=0.463 | H=1.25\n",
            "t=03400 | eps=0.098 | r=0.475 | r_ma=0.466 | H=1.23\n",
            "t=03450 | eps=0.097 | r=0.475 | r_ma=0.468 | H=1.22\n",
            "t=03500 | eps=0.095 | r=0.475 | r_ma=0.466 | H=1.22\n",
            "t=03550 | eps=0.094 | r=0.475 | r_ma=0.464 | H=1.22\n",
            "t=03600 | eps=0.092 | r=0.475 | r_ma=0.465 | H=1.21\n",
            "t=03650 | eps=0.091 | r=0.475 | r_ma=0.464 | H=1.20\n",
            "t=03700 | eps=0.089 | r=0.475 | r_ma=0.461 | H=1.20\n",
            "t=03750 | eps=0.088 | r=0.475 | r_ma=0.463 | H=1.20\n",
            "t=03800 | eps=0.086 | r=0.475 | r_ma=0.462 | H=1.19\n",
            "t=03850 | eps=0.085 | r=0.475 | r_ma=0.462 | H=1.18\n",
            "t=03900 | eps=0.083 | r=0.536 | r_ma=0.465 | H=1.18\n",
            "t=03950 | eps=0.082 | r=0.475 | r_ma=0.468 | H=1.18\n",
            "t=04000 | eps=0.080 | r=0.475 | r_ma=0.468 | H=1.17\n",
            "t=04050 | eps=0.079 | r=0.229 | r_ma=0.468 | H=1.16\n",
            "t=04100 | eps=0.077 | r=0.475 | r_ma=0.466 | H=1.16\n",
            "t=04150 | eps=0.076 | r=0.475 | r_ma=0.465 | H=1.16\n",
            "t=04200 | eps=0.074 | r=0.475 | r_ma=0.464 | H=1.16\n",
            "t=04250 | eps=0.073 | r=0.475 | r_ma=0.464 | H=1.15\n",
            "t=04300 | eps=0.071 | r=0.475 | r_ma=0.467 | H=1.15\n",
            "t=04350 | eps=0.070 | r=0.475 | r_ma=0.467 | H=1.14\n",
            "t=04400 | eps=0.068 | r=0.429 | r_ma=0.469 | H=1.14\n",
            "t=04450 | eps=0.067 | r=0.475 | r_ma=0.469 | H=1.13\n",
            "t=04500 | eps=0.065 | r=0.475 | r_ma=0.469 | H=1.13\n",
            "t=04550 | eps=0.064 | r=0.475 | r_ma=0.467 | H=1.13\n",
            "t=04600 | eps=0.062 | r=0.475 | r_ma=0.464 | H=1.13\n",
            "t=04650 | eps=0.060 | r=0.475 | r_ma=0.465 | H=1.13\n",
            "t=04700 | eps=0.059 | r=0.475 | r_ma=0.466 | H=1.12\n",
            "t=04750 | eps=0.058 | r=0.475 | r_ma=0.468 | H=1.12\n",
            "t=04800 | eps=0.056 | r=0.475 | r_ma=0.469 | H=1.11\n",
            "t=04850 | eps=0.055 | r=0.475 | r_ma=0.469 | H=1.10\n",
            "t=04900 | eps=0.053 | r=0.475 | r_ma=0.469 | H=1.09\n",
            "t=04950 | eps=0.052 | r=0.475 | r_ma=0.471 | H=1.08\n",
            "t=05000 | eps=0.050 | r=0.475 | r_ma=0.472 | H=1.08\n",
            "t=05050 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.08\n",
            "t=05100 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.07\n",
            "t=05150 | eps=0.050 | r=0.475 | r_ma=0.466 | H=1.07\n",
            "t=05200 | eps=0.050 | r=0.475 | r_ma=0.468 | H=1.06\n",
            "t=05250 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.05\n",
            "t=05300 | eps=0.050 | r=0.475 | r_ma=0.468 | H=1.05\n",
            "t=05350 | eps=0.050 | r=0.475 | r_ma=0.471 | H=1.04\n",
            "t=05400 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.04\n",
            "t=05450 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.03\n",
            "t=05500 | eps=0.050 | r=0.475 | r_ma=0.473 | H=1.03\n",
            "t=05550 | eps=0.050 | r=0.475 | r_ma=0.471 | H=1.02\n",
            "t=05600 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.02\n",
            "t=05650 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.01\n",
            "t=05700 | eps=0.050 | r=0.475 | r_ma=0.467 | H=1.01\n",
            "t=05750 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.01\n",
            "t=05800 | eps=0.050 | r=0.475 | r_ma=0.472 | H=1.00\n",
            "t=05850 | eps=0.050 | r=0.475 | r_ma=0.471 | H=1.00\n",
            "t=05900 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.99\n",
            "t=05950 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.99\n",
            "t=06000 | eps=0.050 | r=0.475 | r_ma=0.466 | H=0.99\n",
            "t=06050 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.98\n",
            "t=06100 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.98\n",
            "t=06150 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.98\n",
            "t=06200 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.98\n",
            "t=06250 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.97\n",
            "t=06300 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.97\n",
            "t=06350 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.96\n",
            "t=06400 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.96\n",
            "t=06450 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.96\n",
            "t=06500 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.95\n",
            "t=06550 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.95\n",
            "t=06600 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.95\n",
            "t=06650 | eps=0.050 | r=0.256 | r_ma=0.472 | H=0.94\n",
            "t=06700 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.94\n",
            "t=06750 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.94\n",
            "t=06800 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.94\n",
            "t=06850 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.93\n",
            "t=06900 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.93\n",
            "t=06950 | eps=0.050 | r=0.475 | r_ma=0.466 | H=0.93\n",
            "t=07000 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.93\n",
            "t=07050 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.93\n",
            "t=07100 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.92\n",
            "t=07150 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.92\n",
            "t=07200 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.92\n",
            "t=07250 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.91\n",
            "t=07300 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.91\n",
            "t=07350 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.91\n",
            "t=07400 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.91\n",
            "t=07450 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.90\n",
            "t=07500 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.90\n",
            "t=07550 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.90\n",
            "t=07600 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.90\n",
            "t=07650 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.89\n",
            "t=07700 | eps=0.050 | r=0.475 | r_ma=0.472 | H=0.89\n",
            "t=07750 | eps=0.050 | r=0.475 | r_ma=0.472 | H=0.89\n",
            "t=07800 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.89\n",
            "t=07850 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.88\n",
            "t=07900 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.88\n",
            "t=07950 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.88\n"
          ]
        }
      ],
      "source": [
        "Q = run_rl_latent_selection(steps=8000, batch_size=16, alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WN3alNEOhEZe",
      "metadata": {
        "id": "WN3alNEOhEZe"
      },
      "source": [
        "### Visualize RL-Selected VS Random Latents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EZbpasZNhW2t",
      "metadata": {
        "id": "EZbpasZNhW2t"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid, save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vG27FuoZhLOV",
      "metadata": {
        "id": "vG27FuoZhLOV"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def save_compare_grids(out_dir, n=64, nrow=8):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # RL best latents\n",
        "    top_idx = torch.topk(Q, k=n).indices\n",
        "    z_rl = Z_bank[top_idx]  # [n, Z_DIM]\n",
        "    x_rl = G(z_rl)\n",
        "    grid_rl = make_grid(denorm(x_rl), nrow=nrow)\n",
        "    save_image(grid_rl, os.path.join(out_dir, \"rl_topk.png\"))\n",
        "\n",
        "    # Random latents\n",
        "    z_rand = torch.randn(n, Z_DIM, device=DEVICE)\n",
        "    x_rand = G(z_rand)\n",
        "    grid_rand = make_grid(denorm(x_rand), nrow=nrow)\n",
        "    save_image(grid_rand, os.path.join(out_dir, \"random.png\"))\n",
        "\n",
        "    print(\"Saved grids to:\", out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qltTKelLhQI_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qltTKelLhQI_",
        "outputId": "c0730080-e5c5-4bcb-d24b-f8af90be73e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved grids to: /content/drive/MyDrive/gan-rl-runs/rl_eval_64\n"
          ]
        }
      ],
      "source": [
        "save_compare_grids(\"/content/drive/MyDrive/gan-rl-runs/rl_eval_64\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e44C-AGJzbgi",
      "metadata": {
        "id": "e44C-AGJzbgi"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SzMTD6sPzdxH",
      "metadata": {
        "id": "SzMTD6sPzdxH"
      },
      "source": [
        "## FID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6HLIDHqUzaTi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HLIDHqUzaTi",
        "outputId": "548d4442-0355-4b57-a7a6-7e0202548fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_4EjH7VMzo-a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4EjH7VMzo-a",
        "outputId": "e5231fbe-b5b2-402c-862e-453d56b7f00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CKPT_DIR: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters\n",
            "REAL_DIR: /content/drive/MyDrive/gan-rl-eval/fid_eval_64/real_2000\n",
            "FAKE_ROOT: /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step\n"
          ]
        }
      ],
      "source": [
        "import os, glob, re, math\n",
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters\"\n",
        "FID_ROOT = \"/content/drive/MyDrive/gan-rl-eval/fid_eval_64\"\n",
        "REAL_DIR = os.path.join(FID_ROOT, \"real_2000\")\n",
        "FAKE_ROOT = os.path.join(FID_ROOT, \"fake_by_step\")\n",
        "\n",
        "os.makedirs(REAL_DIR, exist_ok=True)\n",
        "os.makedirs(FAKE_ROOT, exist_ok=True)\n",
        "\n",
        "print(\"CKPT_DIR:\", CKPT_DIR)\n",
        "print(\"REAL_DIR:\", REAL_DIR)\n",
        "print(\"FAKE_ROOT:\", FAKE_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8A6K4aYm0Iq8",
      "metadata": {
        "id": "8A6K4aYm0Iq8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "SfkRvttq00xn",
      "metadata": {
        "id": "SfkRvttq00xn"
      },
      "outputs": [],
      "source": [
        "def load_G_from_ckpt(G, ckpt_path, device=\"cuda\"):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    G.load_state_dict(ckpt[\"G\"])\n",
        "    G.eval()\n",
        "    for p in G.parameters():\n",
        "        p.requires_grad_(False)\n",
        "    step = int(ckpt.get(\"step\", -1))\n",
        "    return step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ne_LSeUC0GR3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_LSeUC0GR3",
        "outputId": "47620b35-563e-4cc2-e71a-ec59cf255420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Real images already exist: 2000\n"
          ]
        }
      ],
      "source": [
        "N_REAL = 2000\n",
        "DEVICE = \"cuda\"\n",
        "\n",
        "def denorm(x):\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def export_real_images(dl, out_dir, n_total=2000):\n",
        "\n",
        "    existing = len(list(Path(out_dir).glob(\"*.png\")))\n",
        "    if existing >= n_total:\n",
        "        print(f\"âœ… Real images already exist: {existing}\")\n",
        "        return\n",
        "\n",
        "    print(\"Exporting real images...\")\n",
        "    count = 0\n",
        "    for batch in dl:\n",
        "        imgs = batch[0]\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        imgs = denorm(imgs)\n",
        "\n",
        "        for i in range(imgs.size(0)):\n",
        "            path = os.path.join(out_dir, f\"real_{count:05d}.png\")\n",
        "            save_image(imgs[i], path)\n",
        "            count += 1\n",
        "            if count >= n_total:\n",
        "                print(f\"âœ… Exported {count} real images to {out_dir}\")\n",
        "                return\n",
        "\n",
        "export_real_images(dl, REAL_DIR, N_REAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z1WCHjAE1GFJ",
      "metadata": {
        "id": "Z1WCHjAE1GFJ"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def compute_fid(real_dir, fake_dir):\n",
        "    cmd = [\"python\", \"-m\", \"pytorch_fid\", real_dir, fake_dir, \"--device\", \"cuda\"]\n",
        "    out = subprocess.check_output(cmd, text=True)\n",
        "    # pytorch-fid prints: \"FID: XX.XXXX\"\n",
        "    m = re.search(r\"FID:\\s*([0-9.]+)\", out)\n",
        "    fid = float(m.group(1)) if m else None\n",
        "    return fid, out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rU1EDNgv1BJR",
      "metadata": {
        "id": "rU1EDNgv1BJR"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "N_FAKE = 2000\n",
        "Z_DIM = 128\n",
        "BATCH = 64\n",
        "\n",
        "@torch.no_grad()\n",
        "def export_fake_images_for_ckpt(G, ckpt_path, out_root, n_total=2000, batch_size=64):\n",
        "    step = load_G_from_ckpt(G, ckpt_path, device=DEVICE)\n",
        "\n",
        "    out_dir = os.path.join(out_root, f\"fake_step_{step:06d}\")\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    existing = len(list(Path(out_dir).glob(\"*.png\")))\n",
        "    if existing >= n_total:\n",
        "        print(f\"âœ… Fake images already exist for step {step}: {existing}\")\n",
        "        return step, out_dir\n",
        "\n",
        "    print(f\"Exporting fake images for step {step} ...\")\n",
        "    count = 0\n",
        "    while count < n_total:\n",
        "        b = min(batch_size, n_total - count)\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        fake = G(z)\n",
        "        fake = denorm(fake)\n",
        "\n",
        "        for i in range(fake.size(0)):\n",
        "            path = os.path.join(out_dir, f\"fake_{count:05d}.png\")\n",
        "            save_image(fake[i], path)\n",
        "            count += 1\n",
        "\n",
        "    print(f\"âœ… Exported {n_total} fake images to {out_dir}\")\n",
        "    return step, out_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sKt8t7YU33ig",
      "metadata": {
        "id": "sKt8t7YU33ig"
      },
      "outputs": [],
      "source": [
        "from src import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZfDBfut43882",
      "metadata": {
        "id": "ZfDBfut43882"
      },
      "outputs": [],
      "source": [
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(\"cuda\")\n",
        "D = models.Discriminator_64(img_channels=3, base=64).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x86rA1741J2T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x86rA1741J2T",
        "outputId": "52944531-90bc-4dc2-e908-52560c985703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoints selected: [3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500]\n",
            "Exporting fake images for step 3000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_003000\n",
            "step=3000 | FID=300.37646800373574\n",
            "Exporting fake images for step 3500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_003500\n",
            "step=3500 | FID=264.46975874077464\n",
            "Exporting fake images for step 4000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_004000\n",
            "step=4000 | FID=199.50375775585388\n",
            "Exporting fake images for step 4500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_004500\n",
            "step=4500 | FID=246.25538491467358\n",
            "Exporting fake images for step 5000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_005000\n",
            "step=5000 | FID=320.64035893390314\n",
            "Exporting fake images for step 5500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_005500\n",
            "step=5500 | FID=212.30712302931818\n",
            "Exporting fake images for step 6000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_006000\n",
            "step=6000 | FID=315.9072017608338\n",
            "Exporting fake images for step 6500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_006500\n",
            "step=6500 | FID=195.45032060911055\n",
            "Exporting fake images for step 7000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_007000\n",
            "step=7000 | FID=252.2338826105988\n",
            "Exporting fake images for step 7500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_007500\n",
            "step=7500 | FID=381.61469646101324\n",
            "Exporting fake images for step 8000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_008000\n",
            "step=8000 | FID=166.7767328366765\n",
            "Exporting fake images for step 8500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_008500\n",
            "step=8500 | FID=226.88216744126385\n",
            "Exporting fake images for step 9000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_009000\n",
            "step=9000 | FID=193.93763080714297\n",
            "Exporting fake images for step 9500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_009500\n",
            "step=9500 | FID=201.36661070359546\n",
            "Exporting fake images for step 10000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_010000\n",
            "step=10000 | FID=157.44017393310372\n",
            "Exporting fake images for step 10500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_010500\n",
            "step=10500 | FID=164.68553381632395\n",
            "Exporting fake images for step 11000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_011000\n",
            "step=11000 | FID=161.9504731099006\n",
            "Exporting fake images for step 11500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_011500\n",
            "step=11500 | FID=180.92448833949132\n",
            "âœ… Saved: /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fid_results.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2669,\n        \"min\": 3000,\n        \"max\": 11500,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          3000,\n          3500,\n          7000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64.45061017467438,\n        \"min\": 157.44017393310372,\n        \"max\": 381.61469646101324,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          300.37646800373574,\n          264.46975874077464,\n          252.2338826105988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>fid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3000</td>\n",
              "      <td>300.376468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3500</td>\n",
              "      <td>264.469759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4000</td>\n",
              "      <td>199.503758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4500</td>\n",
              "      <td>246.255385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>320.640359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5500</td>\n",
              "      <td>212.307123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6000</td>\n",
              "      <td>315.907202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6500</td>\n",
              "      <td>195.450321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7000</td>\n",
              "      <td>252.233883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7500</td>\n",
              "      <td>381.614696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8000</td>\n",
              "      <td>166.776733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>8500</td>\n",
              "      <td>226.882167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9000</td>\n",
              "      <td>193.937631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>9500</td>\n",
              "      <td>201.366611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10000</td>\n",
              "      <td>157.440174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10500</td>\n",
              "      <td>164.685534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11000</td>\n",
              "      <td>161.950473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>11500</td>\n",
              "      <td>180.924488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7aec50bb-3c8a-47e6-9944-350b382d2dca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aec50bb-3c8a-47e6-9944-350b382d2dca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7aec50bb-3c8a-47e6-9944-350b382d2dca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ba3164d6-8540-41ff-b386-b742d488f233\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba3164d6-8540-41ff-b386-b742d488f233 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     step         fid\n",
              "0    3000  300.376468\n",
              "1    3500  264.469759\n",
              "2    4000  199.503758\n",
              "3    4500  246.255385\n",
              "4    5000  320.640359\n",
              "5    5500  212.307123\n",
              "6    6000  315.907202\n",
              "7    6500  195.450321\n",
              "8    7000  252.233883\n",
              "9    7500  381.614696\n",
              "10   8000  166.776733\n",
              "11   8500  226.882167\n",
              "12   9000  193.937631\n",
              "13   9500  201.366611\n",
              "14  10000  157.440174\n",
              "15  10500  164.685534\n",
              "16  11000  161.950473\n",
              "17  11500  180.924488"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "EVAL_EVERY = 500  # evaluate at steps multiple of 500\n",
        "\n",
        "\n",
        "ckpts = sorted(glob.glob(os.path.join(CKPT_DIR, \"gan_step_*.pt\")))\n",
        "\n",
        "def step_from_name(p):\n",
        "    m = re.search(r\"gan_step_(\\d+)\\.pt\", os.path.basename(p))\n",
        "    return int(m.group(1)) if m else -1\n",
        "\n",
        "ckpts = [(step_from_name(p), p) for p in ckpts]\n",
        "ckpts = [(s, p) for (s, p) in ckpts if s >= 0 and (s % EVAL_EVERY == 0)]\n",
        "ckpts = sorted(ckpts, key=lambda x: x[0])\n",
        "\n",
        "\n",
        "print(\"Checkpoints selected:\", [s for s,_ in ckpts])\n",
        "\n",
        "results = []\n",
        "for s, p in ckpts:\n",
        "    step, fake_dir = export_fake_images_for_ckpt(G, p, FAKE_ROOT, n_total=N_FAKE, batch_size=BATCH)\n",
        "    fid, _ = compute_fid(REAL_DIR, fake_dir)\n",
        "    print(f\"step={step} | FID={fid}\")\n",
        "    results.append({\"step\": step, \"fid\": fid})\n",
        "\n",
        "df = pd.DataFrame(results).sort_values(\"step\")\n",
        "csv_path = os.path.join(FID_ROOT, \"fid_results.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"âœ… Saved:\", csv_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TLk0ZfAJ1MMm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "TLk0ZfAJ1MMm",
        "outputId": "7933fb5d-d482-455c-9e4e-374341ab3e6d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df[\"step\"], df[\"fid\"])\n",
        "plt.xlabel(\"Training step\")\n",
        "plt.ylabel(\"FID\")\n",
        "plt.title(\"FID vs Training Step (64x64, N=2000)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LslH2sIzVWbN",
      "metadata": {
        "id": "LslH2sIzVWbN"
      },
      "source": [
        "## LPIPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ZtE85piVbTr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZtE85piVbTr",
        "outputId": "95511def-910a-4952-ea66-032a86f0f4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (0.24.0+cpu)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (2025.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.2.1->lpips) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.3)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install lpips\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_7IZy8oLBQwN",
      "metadata": {
        "id": "_7IZy8oLBQwN"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JUivb-GUVfNQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUivb-GUVfNQ",
        "outputId": "539f6736-d85f-4c47-835b-153ed2c3200f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded step: 11500\n"
          ]
        }
      ],
      "source": [
        "CKPT_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\"\n",
        "\n",
        "\n",
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "G.load_state_dict(ckpt[\"G\"])\n",
        "G.eval()\n",
        "for p in G.parameters(): p.requires_grad_(False)\n",
        "\n",
        "print(\"Loaded step:\", ckpt.get(\"step\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "twmnKzHxWVHp",
      "metadata": {
        "id": "twmnKzHxWVHp"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3B8_4kKiWZXR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B8_4kKiWZXR",
        "outputId": "45b85a5e-49d0-44e5-d246-04b64c0d0df3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating fake pool: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fake_pool: torch.Size([200, 3, 64, 64]) -0.9999791383743286 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "Z_DIM = 128\n",
        "M = 200          # pool size\n",
        "GEN_BS = 64      # generation batch size\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_pool(G, m=200, bs=64):\n",
        "    imgs = []\n",
        "    n_batches = math.ceil(m / bs)\n",
        "    for _ in tqdm(range(n_batches), desc=\"Generating fake pool\"):\n",
        "        b = min(bs, m - len(imgs))\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        x = G(z)  # [-1,1], shape [b,3,64,64]\n",
        "        imgs.append(x.detach().cpu())\n",
        "    return torch.cat(imgs, dim=0)[:m]\n",
        "\n",
        "fake_pool = generate_pool(G, M, GEN_BS)\n",
        "print(\"fake_pool:\", fake_pool.shape, fake_pool.min().item(), fake_pool.max().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JuaBfE7ZXYH5",
      "metadata": {
        "id": "JuaBfE7ZXYH5"
      },
      "outputs": [],
      "source": [
        "import lpips\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mPeT3NQpXbpK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPeT3NQpXbpK",
        "outputId": "5830039e-98cb-43fe-bbe4-1d7df15355f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing LPIPS: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 37.48it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(     i    j     lpips\n",
              " 0  144   80  0.051936\n",
              " 1  161  184  0.057893\n",
              " 2   94   32  0.064466\n",
              " 3   27    9  0.078389\n",
              " 4  173   36  0.079051,\n",
              "       i    j     lpips\n",
              " 95  163  134  0.288987\n",
              " 96  163  170  0.290612\n",
              " 97   43   85  0.330486\n",
              " 98   67  120  0.346448\n",
              " 99   32    5  0.350479)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lpips_fn = lpips.LPIPS(net='alex').to(DEVICE)\n",
        "lpips_fn.eval()\n",
        "\n",
        "NUM_PAIRS = 100\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_lpips_pairs(fake_pool, num_pairs=100):\n",
        "    M = fake_pool.size(0)\n",
        "    pairs = []\n",
        "    scores = []\n",
        "\n",
        "    for _ in tqdm(range(num_pairs), desc=\"Computing LPIPS\"):\n",
        "        i, j = random.sample(range(M), 2)\n",
        "        x1 = fake_pool[i].unsqueeze(0).to(DEVICE)  # [1,3,64,64] in [-1,1]\n",
        "        x2 = fake_pool[j].unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        d = lpips_fn(x1, x2)  # [1,1,1,1] or [1]\n",
        "        d_val = float(d.view(-1).item())\n",
        "\n",
        "        pairs.append((i, j))\n",
        "        scores.append(d_val)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"i\": [p[0] for p in pairs],\n",
        "        \"j\": [p[1] for p in pairs],\n",
        "        \"lpips\": scores\n",
        "    }).sort_values(\"lpips\").reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "df_lpips = compute_lpips_pairs(fake_pool, NUM_PAIRS)\n",
        "df_lpips.head(), df_lpips.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b-ZAHQ1qXzxM",
      "metadata": {
        "id": "b-ZAHQ1qXzxM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision.utils import make_grid, save_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mZIFQolNXudX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZIFQolNXudX",
        "outputId": "8f4cf455-4ff1-4305-a381-da9586cc9123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved pairs + CSV to: /content/drive/MyDrive/gan-rl-runs/12000_iters/lpips_eval_step_11500\n",
            "CSV: /content/drive/MyDrive/gan-rl-runs/12000_iters/lpips_eval_step_11500/lpips_pairs.csv\n"
          ]
        }
      ],
      "source": [
        "OUT_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/lpips_eval_step_11500\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def denorm(x):\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_pair(fake_pool, i, j, fname):\n",
        "    x1 = denorm(fake_pool[i])\n",
        "    x2 = denorm(fake_pool[j])\n",
        "    grid = make_grid(torch.stack([x1, x2], dim=0), nrow=2)\n",
        "    save_image(grid, os.path.join(OUT_DIR, fname))\n",
        "\n",
        "low3 = df_lpips.iloc[:3]\n",
        "high3 = df_lpips.iloc[-3:]\n",
        "\n",
        "for k, row in enumerate(low3.itertuples(index=False), 1):\n",
        "    save_pair(fake_pool, row.i, row.j, f\"low_lpips_{k}_val_{row.lpips:.4f}.png\")\n",
        "\n",
        "for k, row in enumerate(high3.itertuples(index=False), 1):\n",
        "    save_pair(fake_pool, row.i, row.j, f\"high_lpips_{k}_val_{row.lpips:.4f}.png\")\n",
        "\n",
        "csv_path = os.path.join(OUT_DIR, \"lpips_pairs.csv\")\n",
        "df_lpips.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"Saved pairs + CSV to:\", OUT_DIR)\n",
        "print(\"CSV:\", csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DERtMIM7X3jn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DERtMIM7X3jn",
        "outputId": "44fbc99f-2f63-4347-ce66-72f807e84f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LPIPS summary over 100 pairs\n",
            "mean: 0.17383772969245911\n",
            "std : 0.06392530398543005\n",
            "min : 0.05193610489368439\n",
            "max : 0.3504791259765625\n",
            "\n",
            "Lowest 3 pairs:\n",
            "     i    j     lpips\n",
            "0  144   80  0.051936\n",
            "1  161  184  0.057893\n",
            "2   94   32  0.064466\n",
            "\n",
            "Highest 3 pairs:\n",
            "     i    j     lpips\n",
            "97  43   85  0.330486\n",
            "98  67  120  0.346448\n",
            "99  32    5  0.350479\n"
          ]
        }
      ],
      "source": [
        "print(\"LPIPS summary over\", NUM_PAIRS, \"pairs\")\n",
        "print(\"mean:\", df_lpips[\"lpips\"].mean())\n",
        "print(\"std :\", df_lpips[\"lpips\"].std())\n",
        "print(\"min :\", df_lpips[\"lpips\"].min())\n",
        "print(\"max :\", df_lpips[\"lpips\"].max())\n",
        "\n",
        "print(\"\\nLowest 3 pairs:\")\n",
        "print(low3)\n",
        "\n",
        "print(\"\\nHighest 3 pairs:\")\n",
        "print(high3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IZYmKk_saVRW",
      "metadata": {
        "id": "IZYmKk_saVRW"
      },
      "source": [
        "## Discriminator Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oqV0HmqmaYlu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqV0HmqmaYlu",
        "outputId": "dd58b54f-26be-4b56-af24-68c0bb269543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded step: 11500\n"
          ]
        }
      ],
      "source": [
        "CKPT_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\"\n",
        "\n",
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)\n",
        "D = models.Discriminator_64(img_channels=3, base=64).to(DEVICE)\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "G.load_state_dict(ckpt[\"G\"])\n",
        "D.load_state_dict(ckpt[\"D\"])\n",
        "\n",
        "G.eval(); D.eval()\n",
        "for p in G.parameters(): p.requires_grad_(False)\n",
        "for p in D.parameters(): p.requires_grad_(False)\n",
        "\n",
        "print(\"Loaded step:\", ckpt.get(\"step\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gJJbhZ11awPR",
      "metadata": {
        "id": "gJJbhZ11awPR"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z6KhLrKXavsp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6KhLrKXavsp",
        "outputId": "1e0a8660-795d-4a06-b8e1-f1d2471a0761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[1899,  101],\n",
              "        [ 770, 1230]]),\n",
              " {'TP': 1230,\n",
              "  'TN': 1899,\n",
              "  'FP': 101,\n",
              "  'FN': 770,\n",
              "  'acc': 0.78225,\n",
              "  'real_prob_mean': 0.5590644478797913,\n",
              "  'fake_prob_mean': 0.3534086048603058})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "Z_DIM = 128\n",
        "N_EVAL = 2000\n",
        "BATCH = 64\n",
        "THRESH = 0.5  # sigmoid threshold\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_batch_imgs(batch):\n",
        "\n",
        "    return batch[0]\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_discriminator_confusion(dl, G, D, n_eval=2000, batch_size=64, thresh=0.5):\n",
        "    TP=TN=FP=FN=0\n",
        "    real_probs_all = []\n",
        "    fake_probs_all = []\n",
        "\n",
        "    # --- Real pass ---\n",
        "    seen = 0\n",
        "    data_iter = iter(dl)\n",
        "    while seen < n_eval:\n",
        "        batch = next(data_iter)\n",
        "        real = get_batch_imgs(batch).to(DEVICE, non_blocking=True)\n",
        "        b = min(real.size(0), n_eval - seen)\n",
        "        real = real[:b]\n",
        "        seen += b\n",
        "\n",
        "        logits = D(real)               # [b]\n",
        "        probs  = torch.sigmoid(logits) # [b]\n",
        "        real_probs_all.append(probs.detach().cpu())\n",
        "\n",
        "        pred_real = (probs >= thresh).cpu().numpy()\n",
        "\n",
        "        TP += int(pred_real.sum())\n",
        "        FN += int((~pred_real).sum())\n",
        "\n",
        "    # --- Fake pass ---\n",
        "    seen = 0\n",
        "    while seen < n_eval:\n",
        "        b = min(batch_size, n_eval - seen)\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        fake = G(z)\n",
        "        seen += b\n",
        "\n",
        "        logits = D(fake)\n",
        "        probs  = torch.sigmoid(logits)\n",
        "        fake_probs_all.append(probs.detach().cpu())\n",
        "\n",
        "        pred_real = (probs >= thresh).cpu().numpy()\n",
        "\n",
        "\n",
        "        FP += int(pred_real.sum())\n",
        "        TN += int((~pred_real).sum())\n",
        "\n",
        "    real_probs_all = torch.cat(real_probs_all).numpy()\n",
        "    fake_probs_all = torch.cat(fake_probs_all).numpy()\n",
        "\n",
        "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "    cm = np.array([[TN, FP],\n",
        "                   [FN, TP]])\n",
        "\n",
        "    stats = {\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"acc\": acc,\n",
        "        \"real_prob_mean\": float(real_probs_all.mean()),\n",
        "        \"fake_prob_mean\": float(fake_probs_all.mean()),\n",
        "    }\n",
        "    return cm, stats, real_probs_all, fake_probs_all\n",
        "\n",
        "cm, stats, real_probs, fake_probs = eval_discriminator_confusion(dl, G, D, n_eval=N_EVAL, batch_size=BATCH, thresh=THRESH)\n",
        "cm, stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QsJLUt66a3Cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "QsJLUt66a3Cc",
        "outputId": "2b7065cd-b87c-4c97-bdae-691bc3f9b57e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stats: {'TP': 1230, 'TN': 1899, 'FP': 101, 'FN': 770, 'acc': 0.78225, 'real_prob_mean': 0.5590644478797913, 'fake_prob_mean': 0.3534086048603058}\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrix plot\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation=\"nearest\")\n",
        "plt.title(\"Confusion Matrix (D at step 11500)\")\n",
        "plt.xticks([0,1], [\"Pred Fake\", \"Pred Real\"])\n",
        "plt.yticks([0,1], [\"True Fake\", \"True Real\"])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, str(cm[i,j]), ha=\"center\", va=\"center\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Probability histograms\n",
        "plt.figure()\n",
        "plt.hist(real_probs, bins=30, alpha=0.7, label=\"Real (sigmoid(D))\")\n",
        "plt.hist(fake_probs, bins=30, alpha=0.7, label=\"Fake (sigmoid(D))\")\n",
        "plt.title(\"Discriminator Output Probabilities\")\n",
        "plt.xlabel(\"sigmoid(D(x))\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Stats:\", stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5_rqEb30cKGY",
      "metadata": {
        "id": "5_rqEb30cKGY"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jhrc2LXDcHu2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhrc2LXDcHu2",
        "outputId": "f08d42be-e7f2-4ae0-f909-c60ce5854e43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved TP -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_11500/TP_examples.png\n",
            "Saved TN -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_11500/TN_examples.png\n",
            "Saved FP -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_11500/FP_examples.png\n",
            "Saved FN -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_11500/FN_examples.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_11500\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def denorm(x): return (x*0.5 + 0.5).clamp(0,1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_examples(dl, G, D, thresh=0.5, max_each=8):\n",
        "    examples = {\"TP\": [], \"TN\": [], \"FP\": [], \"FN\": []}\n",
        "\n",
        "    # collect from real\n",
        "    for batch in dl:\n",
        "        real = get_batch_imgs(batch).to(DEVICE, non_blocking=True)\n",
        "        probs = torch.sigmoid(D(real))\n",
        "        pred_real = probs >= thresh\n",
        "        for i in range(real.size(0)):\n",
        "            if pred_real[i] and len(examples[\"TP\"]) < max_each:\n",
        "                examples[\"TP\"].append(real[i].cpu())\n",
        "            if (not pred_real[i]) and len(examples[\"FN\"]) < max_each:\n",
        "                examples[\"FN\"].append(real[i].cpu())\n",
        "        if len(examples[\"TP\"])>=max_each and len(examples[\"FN\"])>=max_each:\n",
        "            break\n",
        "\n",
        "    # collect from fake\n",
        "    while len(examples[\"TN\"]) < max_each or len(examples[\"FP\"]) < max_each:\n",
        "        b = 64\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        fake = G(z)\n",
        "        probs = torch.sigmoid(D(fake))\n",
        "        pred_real = probs >= thresh\n",
        "        for i in range(fake.size(0)):\n",
        "            if (not pred_real[i]) and len(examples[\"TN\"]) < max_each:\n",
        "                examples[\"TN\"].append(fake[i].cpu())\n",
        "            if pred_real[i] and len(examples[\"FP\"]) < max_each:\n",
        "                examples[\"FP\"].append(fake[i].cpu())\n",
        "\n",
        "    return examples\n",
        "\n",
        "ex = collect_examples(dl, G, D, THRESH, max_each=8)\n",
        "\n",
        "for k, imgs in ex.items():\n",
        "    if len(imgs) == 0:\n",
        "        continue\n",
        "    grid = torch.stack(imgs, dim=0)\n",
        "    save_image(denorm(grid), os.path.join(OUT_DIR, f\"{k}_examples.png\"), nrow=4)\n",
        "    print(\"Saved\", k, \"->\", os.path.join(OUT_DIR, f\"{k}_examples.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aEMt0wUwcvZW",
      "metadata": {
        "id": "aEMt0wUwcvZW"
      },
      "source": [
        "## Training Stability Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9uX4qmSBfQli",
      "metadata": {
        "id": "9uX4qmSBfQli"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yKkiGGZHctKb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKkiGGZHctKb",
        "outputId": "51a735f5-30fc-4dea-8875-3dff190abaf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   step  loss_D  loss_G\n",
            "0  2510  1.2668  0.7779\n",
            "1  2520  0.8847  1.1308\n",
            "2  2530  0.8540  1.2237\n",
            "3  2540  1.2627  1.0067\n",
            "4  2550  1.3379  0.7821 \n",
            "...\n",
            "       step  loss_D  loss_G\n",
            "944  11950  1.1114  1.1692\n",
            "945  11960  1.2996  0.8227\n",
            "946  11970  0.9366  1.2292\n",
            "947  11980  1.1893  1.4127\n",
            "948  11990  0.9937  1.3253\n",
            "Parsed points: 949\n"
          ]
        }
      ],
      "source": [
        "LOG_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/gan_train.log\"\n",
        "OUT_PREFIX = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/gan_losses\"\n",
        "\n",
        "step_pat = re.compile(\n",
        "    r\"step\\s+(\\d+)\\s+\\|\\s+loss_D\\s+([0-9]*\\.?[0-9]+)\\s+\\|\\s+loss_G\\s+([0-9]*\\.?[0-9]+)\"\n",
        ")\n",
        "\n",
        "rows = []\n",
        "with open(LOG_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        m = step_pat.search(line)\n",
        "        if m:\n",
        "            step = int(m.group(1))\n",
        "            loss_d = float(m.group(2))\n",
        "            loss_g = float(m.group(3))\n",
        "            rows.append((step, loss_d, loss_g))\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"step\", \"loss_D\", \"loss_G\"]).sort_values(\"step\").drop_duplicates(\"step\")\n",
        "print(df.head(), \"\\n...\\n\", df.tail())\n",
        "print(\"Parsed points:\", len(df))\n",
        "\n",
        "# Loss_D plot\n",
        "plt.figure()\n",
        "plt.plot(df[\"step\"], df[\"loss_D\"])\n",
        "plt.xlabel(\"Training step\")\n",
        "plt.ylabel(\"Discriminator loss\")\n",
        "plt.title(\"GAN training: Discriminator loss\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_PREFIX}_lossD.png\", dpi=200)\n",
        "plt.close()\n",
        "\n",
        "# Loss_G plot\n",
        "plt.figure()\n",
        "plt.plot(df[\"step\"], df[\"loss_G\"])\n",
        "plt.xlabel(\"Training step\")\n",
        "plt.ylabel(\"Generator loss\")\n",
        "plt.title(\"GAN training: Generator loss\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_PREFIX}_lossG.png\", dpi=200)\n",
        "plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2RNAOhb7cusk",
      "metadata": {
        "id": "2RNAOhb7cusk"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Fixed Seed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zahy641Qcthk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zahy641Qcthk",
        "outputId": "67984669-587a-4dea-9b85-8407ef9d85d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved reproducibility grids to: /content/drive/MyDrive/gan-rl-runs/12000_iters/repro_eval_step_11500\n"
          ]
        }
      ],
      "source": [
        "\n",
        "OUT_REPRO = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/repro_eval_step_11500\"\n",
        "os.makedirs(OUT_REPRO, exist_ok=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_fixed_seed_grid(G, seed, path, n=64, nrow=8):\n",
        "    torch.manual_seed(seed)\n",
        "    z = torch.randn(n, Z_DIM, device=DEVICE)\n",
        "    x = denorm(G(z))\n",
        "    grid = make_grid(x, nrow=nrow)\n",
        "    save_image(grid, path)\n",
        "\n",
        "save_fixed_seed_grid(G, seed=2025, path=os.path.join(OUT_REPRO, \"fixed_seed_run1.png\"))\n",
        "save_fixed_seed_grid(G, seed=2025, path=os.path.join(OUT_REPRO, \"fixed_seed_run2.png\"))\n",
        "print(\"Saved reproducibility grids to:\", OUT_REPRO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QTPvfLKviQrk",
      "metadata": {
        "id": "QTPvfLKviQrk"
      },
      "source": [
        "## RL Entropy Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wO8BRy6_iYXr",
      "metadata": {
        "id": "wO8BRy6_iYXr"
      },
      "outputs": [],
      "source": [
        "LOG_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/rl_train.log\"\n",
        "OUT_PREFIX = \"/content/drive/MyDrive/gan-rl-runs/12000_iters\"\n",
        "\n",
        "pat = re.compile(\n",
        "    r\"t=(\\d+)\\s*\\|\\s*eps=([0-9]*\\.?[0-9]+)\\s*\\|\\s*r=([0-9]*\\.?[0-9]+)\\s*\\|\\s*r_ma=([0-9]*\\.?[0-9]+)\\s*\\|\\s*H=([0-9]*\\.?[0-9]+)\"\n",
        ")\n",
        "\n",
        "rows = []\n",
        "with open(LOG_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        m = pat.search(line)\n",
        "        if m:\n",
        "            t = int(m.group(1))\n",
        "            eps = float(m.group(2))\n",
        "            r = float(m.group(3))\n",
        "            r_ma = float(m.group(4))\n",
        "            H = float(m.group(5))\n",
        "            rows.append((t, eps, r, r_ma, H))\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"t\", \"eps\", \"r\", \"r_ma\", \"H\"]).sort_values(\"t\").drop_duplicates(\"t\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df[\"t\"], df[\"H\"])\n",
        "plt.xlabel(\"t\")\n",
        "plt.ylabel(\"entropy (H)\")\n",
        "plt.title(\"Policy Entropy\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_PREFIX}_entropy.png\", dpi=200)\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_6E8Bue41JhO",
      "metadata": {
        "id": "_6E8Bue41JhO"
      },
      "source": [
        "# Export 2000 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "NV-CyTU00kJk",
      "metadata": {
        "id": "NV-CyTU00kJk"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def export_fake_images_for_assignment(G, ckpt_path, out_root, n_total=2000, batch_size=64):\n",
        "    step = load_G_from_ckpt(G, ckpt_path, device=DEVICE)\n",
        "\n",
        "    out_dir = out_root\n",
        "\n",
        "    existing = len(list(Path(out_dir).glob(\"*.png\")))\n",
        "    if existing >= n_total:\n",
        "        print(f\"Fake images already exist for step {step}: {existing}\")\n",
        "        return step, out_dir\n",
        "\n",
        "    print(f\"Exporting fake images for step {step} ...\")\n",
        "    count = 0\n",
        "    while count < n_total:\n",
        "        b = min(batch_size, n_total - count)\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        fake = G(z)\n",
        "        fake = denorm(fake)\n",
        "\n",
        "        for i in range(fake.size(0)):\n",
        "            path = os.path.join(out_dir, f\"fake_{count:05d}.png\")\n",
        "            save_image(fake[i], path)\n",
        "            count += 1\n",
        "\n",
        "    print(f\"Exported {n_total} fake images to {out_dir}\")\n",
        "    return step, out_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "IxoH5pCV1Vvx",
      "metadata": {
        "id": "IxoH5pCV1Vvx"
      },
      "outputs": [],
      "source": [
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "lk3r2Stj11HR",
      "metadata": {
        "id": "lk3r2Stj11HR"
      },
      "outputs": [],
      "source": [
        "def denorm(x):\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "CoXRQwvA2CWI",
      "metadata": {
        "id": "CoXRQwvA2CWI"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid, save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "4HXQ2Dzf0AJa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HXQ2Dzf0AJa",
        "outputId": "f734e56f-7f88-4177-fae2-7407099bc0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting fake images for step 11500 ...\n",
            "Exported 2000 fake images to /content/drive/MyDrive/gan-rl-runs/12000_iters/610300056\n"
          ]
        }
      ],
      "source": [
        "### Export 2000 images from checkpoint 2000\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\"\n",
        "out_root = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/610300056\"\n",
        "step, fake_dir = export_fake_images_for_assignment(G, ckpt_path, out_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rY4LRnxX3sJe",
      "metadata": {
        "id": "rY4LRnxX3sJe"
      },
      "source": [
        "## Images can be observed using thi following link:\n",
        "\n",
        "https://drive.google.com/drive/folders/1t-WpnVbOdo0XPRKqAiR9vpJN1hjIxBVV?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gcsQSaIT4hlR",
      "metadata": {
        "id": "gcsQSaIT4hlR"
      },
      "source": [
        "#Loading Weights Locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hYv3Carq4kcp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYv3Carq4kcp",
        "outputId": "6500eb93-4e4d-4406-e4b5-422807563ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded checkpoint step: 11500\n"
          ]
        }
      ],
      "source": [
        "DEVICE = \"cpu\"\n",
        "\n",
        "ckpt_path = \"weights/gan_step_011500.pt\"\n",
        "ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
        "\n",
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)\n",
        "D = models.Discriminator_64(img_channels=3, base=64).to(DEVICE)\n",
        "\n",
        "G.load_state_dict(ckpt[\"G\"])\n",
        "D.load_state_dict(ckpt[\"D\"])\n",
        "\n",
        "G.eval()\n",
        "D.eval()\n",
        "\n",
        "print(\"Loaded checkpoint step:\", ckpt.get(\"step\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fqxJ2iVD46dL",
      "metadata": {
        "id": "fqxJ2iVD46dL"
      },
      "outputs": [],
      "source": [
        "# Freezing weights\n",
        "for p in G.parameters(): p.requires_grad_(False)\n",
        "for p in D.parameters(): p.requires_grad_(False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
