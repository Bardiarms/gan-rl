{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "638cbfaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "638cbfaf",
        "outputId": "3753eca5-d220-44c7-c83b-a1322496b288",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'gan-rl'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 68 (delta 32), reused 52 (delta 18), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (68/68), 384.48 KiB | 10.39 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n",
            "/content/gan-rl\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bardiarms/gan-rl.git\n",
        "%cd gan-rl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5bd6faac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bd6faac",
        "outputId": "bf1c157f-81af-4305-a910-ac87012596b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2862d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2862d9",
        "outputId": "0377e089-c6b8-423e-8bc0-dc6f7541d594",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio tqdm matplotlib pandas pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e33c9c9a",
      "metadata": {
        "id": "e33c9c9a",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/gan-rl-data\"\n",
        "RUN_DIR  = \"/content/drive/MyDrive/gan-rl-runs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6f45a59c",
      "metadata": {
        "id": "6f45a59c"
      },
      "outputs": [],
      "source": [
        "REPO_DIR = \"/content/gan-rl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "68b70e02",
      "metadata": {
        "id": "68b70e02"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e8668c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1e8668c",
        "outputId": "8336096c-8e85-456c-b439-a30c3bb8f799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA_DIR exists: True\n",
            "RUN_DIR: /content/drive/MyDrive/gan-rl-runs\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "print(\"DATA_DIR exists:\", os.path.exists(DATA_DIR))\n",
        "print(\"RUN_DIR:\", RUN_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "23908dec",
      "metadata": {
        "id": "23908dec"
      },
      "outputs": [],
      "source": [
        "# DATA_ROOT = \"/content/cartoonset100k\"\n",
        "DATA_ROOT = \"/content/drive/MyDrive/gan-rl-data/cartoonset100k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346636e5",
      "metadata": {
        "id": "346636e5"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b191e94",
      "metadata": {},
      "source": [
        "### Storing images, corresponding metadata and their directory name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08e470f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c08e470f",
        "outputId": "7a503c80-38d1-4084-9e45-fae556583277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pairs: 100000\n",
            "Missing CSV for PNG: 17\n"
          ]
        }
      ],
      "source": [
        "data_root = Path(DATA_ROOT)\n",
        "\n",
        "pairs, missing_meta, missing_img = [], [], []\n",
        "\n",
        "for d in sorted(data_root.iterdir()):\n",
        "\n",
        "    for png_path in d.glob(\"*.png\"):\n",
        "        csv_path = png_path.with_suffix(\".csv\")\n",
        "        if csv_path.exists():\n",
        "            pairs.append((str(png_path), str(csv_path), int(d.name)))   # If the pair exists, add them to pairs\n",
        "        else:\n",
        "            missing_meta.append(str(png_path))\n",
        "\n",
        "\n",
        "print(\"Total pairs:\", len(pairs))\n",
        "print(\"Missing CSV for PNG:\", len(missing_meta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b087efec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b087efec",
        "outputId": "05dda2b2-f070-4420-bb26-5e6c4619c0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12694632614924764393.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12694632614924764393.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12110888894984629978.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12110888894984629978.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12783151780612292884.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs12783151780612292884.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1182038763634098519.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1182038763634098519.csv', 0)\n",
            "('/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1213446833171185255.png', '/content/drive/MyDrive/gan-rl-data/cartoonset100k/0/cs1213446833171185255.csv', 0)\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(pairs[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "98f1e97e",
      "metadata": {
        "id": "98f1e97e"
      },
      "outputs": [],
      "source": [
        "pairs.sort(key=lambda x: x[0])  # sort by image path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2x3O3KmwFqCH",
      "metadata": {
        "id": "2x3O3KmwFqCH"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3b8387b9",
      "metadata": {
        "id": "3b8387b9"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fce0614",
      "metadata": {
        "id": "1fce0614"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMG_SIZE = 64      # We convert 500*500 pixel images into 64*64.\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4a2e261a",
      "metadata": {
        "id": "4a2e261a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d44da00d",
      "metadata": {
        "id": "d44da00d"
      },
      "outputs": [],
      "source": [
        "# Read metadata and store them in pandas dataframe\n",
        "def read_meta(meta_path: str)-> pd.DataFrame:\n",
        "\n",
        "  df = pd.read_csv(meta_path, header=None, names=[\"attr\", \"value\", \"max\"])\n",
        "  df[\"attr\"] = df[\"attr\"].astype(str)\n",
        "  df[\"value\"] = df[\"value\"].astype(int)\n",
        "  df[\"max\"] = df[\"max\"].astype(int)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb9892b8",
      "metadata": {
        "id": "bb9892b8"
      },
      "outputs": [],
      "source": [
        "# Apply one-hot encoding\n",
        "def encode_onehot(meta_path: str,\n",
        "                  attr_to_num_classes: dict,\n",
        "                  offsets: dict,\n",
        "                  total_dim: int\n",
        "                  )-> torch.Tensor:\n",
        "\n",
        "    df = read_meta(meta_path)\n",
        "    vec = np.zeros((total_dim,), dtype=np.float32)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        attr = row[\"attr\"]\n",
        "        val = int(row[\"value\"])\n",
        "\n",
        "        if attr not in offsets:\n",
        "          continue\n",
        "\n",
        "        n = attr_to_num_classes[attr]\n",
        "        if val < 0 or val >= n:\n",
        "            val = max(0, min(val, n - 1))\n",
        "\n",
        "        vec[offsets[attr] + val] = 1.0\n",
        "\n",
        "    return torch.from_numpy(vec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3ba9243e",
      "metadata": {
        "id": "3ba9243e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7e51057e",
      "metadata": {
        "id": "7e51057e"
      },
      "outputs": [],
      "source": [
        "class CartoonSetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, pairs, img_transform, meta_cache = None):\n",
        "        self.pairs = pairs\n",
        "        self.img_transform = img_transform\n",
        "        self.meta_cache = meta_cache\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, meta_path, folder_id = self.pairs[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = self.img_transform(img)\n",
        "\n",
        "        if self.meta_cache is not None:\n",
        "            meta = self.meta_cache[meta_path]\n",
        "            return img, meta, folder_id\n",
        "\n",
        "        else:\n",
        "            return img, folder_id\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "640141c8",
      "metadata": {
        "id": "640141c8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "720fa385",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720fa385",
        "outputId": "3a8ee880-8f64-47e7-c345-d58848fb8070"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imgs: torch.Size([4, 3, 64, 64]) -1.0 1.0\n",
            "folder_ids: tensor([5, 8, 7, 6])\n"
          ]
        }
      ],
      "source": [
        "ds = CartoonSetDataset(pairs=pairs, img_transform=img_transform)\n",
        "\n",
        "dl = DataLoader(\n",
        "    ds,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=False\n",
        ")\n",
        "imgs, folder_ids = next(iter(dl))\n",
        "print(\"imgs:\", imgs.shape, imgs.min().item(), imgs.max().item())\n",
        "print(\"folder_ids:\", folder_ids[:8])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bc1a408e",
      "metadata": {
        "id": "bc1a408e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from src import models\n",
        "IMG_SIZE = 64\n",
        "Z_DIM = 128\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda\"\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0edd349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0edd349",
        "outputId": "f1ec16c4-4cf9-4624-a406-ea408f9a517a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Real: torch.Size([4, 3, 64, 64]) -0.9607843160629272 1.0\n",
            "Fake: torch.Size([4, 3, 64, 64]) -0.9999998807907104 0.9999997019767761\n",
            "D(real) shape: torch.Size([4]) min/max: -0.09946166723966599 -0.0696922019124031\n",
            "D(fake) shape: torch.Size([4]) min/max: -0.13368116319179535 -0.022538205608725548\n"
          ]
        }
      ],
      "source": [
        "G = models.Generator_64(z_dim=Z_DIM).to(DEVICE)\n",
        "D = models.Discriminator_64().to(DEVICE)\n",
        "\n",
        "imgs, folder_ids = next(iter(dl))  # from your existing DataLoader\n",
        "imgs = imgs.to(DEVICE)\n",
        "\n",
        "z = torch.randn(imgs.size(0), Z_DIM, device=DEVICE)\n",
        "fake = G(z)\n",
        "\n",
        "print(\"Real:\", imgs.shape, imgs.min().item(), imgs.max().item())\n",
        "print(\"Fake:\", fake.shape, fake.min().item(), fake.max().item())\n",
        "\n",
        "d_real = D(imgs)\n",
        "d_fake = D(fake.detach())\n",
        "\n",
        "print(\"D(real) shape:\", d_real.shape, \"min/max:\", d_real.min().item(), d_real.max().item())\n",
        "print(\"D(fake) shape:\", d_fake.shape, \"min/max:\", d_fake.min().item(), d_fake.max().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bbf079a",
      "metadata": {
        "id": "2bbf079a"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "lr_G = 2e-4\n",
        "lr_D = 1e-4\n",
        "beta1, beta2 = 0.5, 0.999\n",
        "\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "\n",
        "use_amp = True\n",
        "scaler_D = torch.amp.GradScaler(device=\"cuda\", enabled=use_amp)\n",
        "scaler_G = torch.amp.GradScaler(device=\"cuda\", enabled=use_amp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb46d0ef",
      "metadata": {
        "id": "eb46d0ef"
      },
      "source": [
        "### Train GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd7ff95",
      "metadata": {
        "id": "afd7ff95"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid, save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecde02e",
      "metadata": {
        "id": "0ecde02e"
      },
      "outputs": [],
      "source": [
        "# Denormalize pixels to [0,255]\n",
        "def denorm(x):\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_samples(G, step, fixed_z, out_dir, nrow=8):\n",
        "    G.eval()\n",
        "    fake = G(fixed_z)\n",
        "    grid = make_grid(denorm(fake), nrow=nrow)\n",
        "    path = os.path.join(out_dir, f\"step_{step:06d}.png\")\n",
        "    save_image(grid, path)\n",
        "    G.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "469ce45f",
      "metadata": {
        "id": "469ce45f"
      },
      "outputs": [],
      "source": [
        "# Add Gaussian Noise to Discriminator's inputs\n",
        "def noise_sigma(step, sigma0=0.10, hold_steps=1500, decay_steps=4000):\n",
        "    if step < hold_steps:\n",
        "        return sigma0\n",
        "    t = (step - hold_steps) / decay_steps\n",
        "    return sigma0 * max(0.0, 1.0 - t)\n",
        "\n",
        "# Noise Helper\n",
        "def add_instance_noise(x, sigma):\n",
        "    if sigma <= 0:\n",
        "        return x\n",
        "    return x + sigma * torch.randn_like(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd86037",
      "metadata": {
        "id": "6dd86037"
      },
      "outputs": [],
      "source": [
        "def train_func(RUN_DIR: str,\n",
        "               iters: int,\n",
        "               SAMPLE_EVERY: int,\n",
        "               CHKPT_EVERY: int\n",
        "               )-> None:\n",
        "\n",
        "    SAMPLES_DIR = os.path.join(RUN_DIR, f\"samples_128_{iters}_iters\")\n",
        "    CHKPT_DIR = os.path.join(RUN_DIR, f\"checkpoints_128_{iters}_iters\")\n",
        "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
        "    os.makedirs(CHKPT_DIR, exist_ok=True)\n",
        "\n",
        "    fixed_z = torch.randn(64, Z_DIM, device=DEVICE)\n",
        "\n",
        "    G.train(); D.train()\n",
        "\n",
        "    step = 0\n",
        "    data_iter = iter(dl)\n",
        "\n",
        "    while step < iters:\n",
        "        try:\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(dl)\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "\n",
        "        real = imgs.to(DEVICE, non_blocking=True)\n",
        "        B = real.size(0)\n",
        "\n",
        "        real_labels = torch.ones(B, device=DEVICE)\n",
        "        fake_labels = torch.zeros(B, device=DEVICE)\n",
        "\n",
        "\n",
        "        # ---Train Discriminator---\n",
        "\n",
        "        opt_D.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        sigma = 0\n",
        "\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "\n",
        "            real_in = add_instance_noise(real, sigma)\n",
        "            fake_in = add_instance_noise(fake.detach(), sigma)\n",
        "\n",
        "            logits_real = D(real_in)\n",
        "            logits_fake = D(fake_in)\n",
        "            loss_D_real = criterion(logits_real, real_labels)\n",
        "            loss_D_fake = criterion(logits_fake, fake_labels)\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "\n",
        "        scaler_D.scale(loss_D).backward()\n",
        "        scaler_D.step(opt_D)\n",
        "        scaler_D.update()\n",
        "\n",
        "\n",
        "        # ---Train Generator---\n",
        "        \n",
        "        opt_G.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "            \n",
        "            logits_fake_for_G = D(fake)\n",
        "            loss_G = criterion(logits_fake_for_G, real_labels)\n",
        "\n",
        "        scaler_G.scale(loss_G).backward()\n",
        "        scaler_G.step(opt_G)\n",
        "        scaler_G.update()\n",
        "\n",
        "        # Logging\n",
        "        if step % 10 == 0:\n",
        "            print(\n",
        "                f\"step {step:04d} | \"\n",
        "                f\"loss_D {loss_D.item():.4f} (r {loss_D_real.item():.4f}, f {loss_D_fake.item():.4f}) | \"\n",
        "                f\"loss_G {loss_G.item():.4f} | \"\n",
        "                f\"D(real) {logits_real.mean().item():+.3f} | D(fake) {logits_fake.mean().item():+.3f}\"\n",
        "            )\n",
        "\n",
        "        # Save samples\n",
        "        if step % SAMPLE_EVERY == 0:\n",
        "            save_samples(G, step, fixed_z, out_dir = SAMPLES_DIR)\n",
        "\n",
        "        # Save checkpoints\n",
        "        if step > 0 and step % CHKPT_EVERY == 0:\n",
        "            ckpt_path = os.path.join(CHKPT_DIR, f\"gan_step_{step:06d}.pt\")\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"step\": step,\n",
        "                    \"G\": G.state_dict(),\n",
        "                    \"D\": D.state_dict(),\n",
        "                    \"opt_G\": opt_G.state_dict(),\n",
        "                    \"opt_D\": opt_D.state_dict(),\n",
        "                    \"scaler_D\": scaler_D.state_dict(),\n",
        "                    \"scaler_G\": scaler_G.state_dict(),\n",
        "                },\n",
        "                ckpt_path,\n",
        "            )\n",
        "\n",
        "        step += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50beb89d",
      "metadata": {
        "id": "50beb89d"
      },
      "outputs": [],
      "source": [
        "train_func(RUN_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters\", iters = 12000, SAMPLE_EVERY = 500, CHKPT_EVERY = 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NMqjHZwaLIMV",
      "metadata": {
        "id": "NMqjHZwaLIMV"
      },
      "source": [
        "## Resume Train From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ivGByHbxLM5q",
      "metadata": {
        "id": "ivGByHbxLM5q"
      },
      "outputs": [],
      "source": [
        "\n",
        "def resume_from_ckpt(\n",
        "    ckpt_path: str,\n",
        "    total_iters: int,\n",
        "    RUN_DIR: str,\n",
        "    SAMPLE_EVERY: int,\n",
        "    CHKPT_EVERY: int,\n",
        "    dl,\n",
        "    G,\n",
        "    D,\n",
        "    opt_G,\n",
        "    opt_D,\n",
        "    criterion,\n",
        "    save_samples,\n",
        "    DEVICE=\"cuda\",\n",
        "    Z_DIM=128,\n",
        "    use_amp=True,\n",
        "    scaler_D=None,\n",
        "    scaler_G=None\n",
        "):\n",
        "    # ---- load ----\n",
        "    ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
        "    G.load_state_dict(ckpt[\"G\"])\n",
        "    D.load_state_dict(ckpt[\"D\"])\n",
        "    opt_G.load_state_dict(ckpt[\"opt_G\"])\n",
        "    opt_D.load_state_dict(ckpt[\"opt_D\"])\n",
        "\n",
        "    start_step = int(ckpt.get(\"step\", 0)) + 1\n",
        "\n",
        "    \n",
        "    if \"scaler_D\" in ckpt and ckpt[\"scaler_D\"] is not None:\n",
        "        try:\n",
        "            scaler_D.load_state_dict(ckpt[\"scaler_D\"])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if \"scaler_G\" in ckpt and ckpt[\"scaler_G\"] is not None:\n",
        "        try:\n",
        "            scaler_G.load_state_dict(ckpt[\"scaler_G\"])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # ---- dirs ----\n",
        "    SAMPLES_DIR = os.path.join(RUN_DIR, f\"samples_64_{total_iters}_iters\")\n",
        "    CKPT_DIR    = os.path.join(RUN_DIR, f\"checkpoints_64_{total_iters}_iters\")\n",
        "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
        "    os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "    print(f\"âœ… Loaded: {ckpt_path}\")\n",
        "    print(f\"â–¶ï¸ Resume: step {start_step} -> {total_iters-1}\")\n",
        "\n",
        "    fixed_z = torch.randn(64, Z_DIM, device=DEVICE)\n",
        "\n",
        "    G.train(); D.train()\n",
        "    step = start_step\n",
        "    data_iter = iter(dl)\n",
        "\n",
        "    while step < total_iters:\n",
        "        try:\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(dl)\n",
        "            imgs, folder_ids = next(data_iter)\n",
        "\n",
        "        real = imgs.to(DEVICE, non_blocking=True)\n",
        "        B = real.size(0)\n",
        "\n",
        "        real_labels = torch.ones(B, device=DEVICE)\n",
        "        fake_labels = torch.zeros(B, device=DEVICE)\n",
        "\n",
        "\n",
        "        # ---Train Discriminator---\n",
        "\n",
        "        opt_D.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        sigma = 0\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "\n",
        "            real_in = add_instance_noise(real, sigma)\n",
        "            fake_in = add_instance_noise(fake.detach(), sigma)\n",
        "\n",
        "            logits_real = D(real_in)\n",
        "            logits_fake = D(fake_in)\n",
        "            loss_D_real = criterion(logits_real, real_labels)\n",
        "            loss_D_fake = criterion(logits_fake, fake_labels)\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "\n",
        "        scaler_D.scale(loss_D).backward()\n",
        "        scaler_D.step(opt_D)\n",
        "        scaler_D.update()\n",
        "\n",
        "\n",
        "        \n",
        "        # ---Train Generator---\n",
        "        \n",
        "        opt_G.zero_grad(set_to_none=True)\n",
        "        z = torch.randn(B, Z_DIM, device=DEVICE)\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "            fake = G(z)\n",
        "            \n",
        "            logits_fake_for_G = D(fake)\n",
        "            loss_G = criterion(logits_fake_for_G, real_labels)\n",
        "\n",
        "        scaler_G.scale(loss_G).backward()\n",
        "        scaler_G.step(opt_G)\n",
        "        scaler_G.update()\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(\n",
        "                f\"step {step:04d} | loss_D {loss_D.item():.4f} | loss_G {loss_G.item():.4f} | \"\n",
        "                f\"D(real) {logits_real.mean().item():+.3f} | D(fake) {logits_fake.mean().item():+.3f}\"\n",
        "            )\n",
        "\n",
        "        if step % SAMPLE_EVERY == 0:\n",
        "            save_samples(G, step, fixed_z, out_dir=SAMPLES_DIR)\n",
        "\n",
        "        if step > 0 and step % CHKPT_EVERY == 0:\n",
        "            out_path = os.path.join(CKPT_DIR, f\"gan_step_{step:06d}.pt\")\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"step\": step,\n",
        "                    \"G\": G.state_dict(),\n",
        "                    \"D\": D.state_dict(),\n",
        "                    \"opt_G\": opt_G.state_dict(),\n",
        "                    \"opt_D\": opt_D.state_dict(),\n",
        "                    \"scaler_D\": scaler_D.state_dict(),\n",
        "                    \"scaler_G\": scaler_G.state_dict(),\n",
        "                },\n",
        "                out_path,\n",
        "            )\n",
        "            print(\"ðŸ’¾ Saved:\", out_path)\n",
        "\n",
        "        step += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iMnL1vOcLl88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMnL1vOcLl88",
        "outputId": "dca795f9-379c-4957-9465-393d43007d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_128_12000_iters/gan_step_002500.pt\n",
            "â–¶ï¸ Resume: step 2501 -> 11999\n",
            "step 2510 | loss_D 1.2668 | loss_G 0.7779 | D(real) +0.051 | D(fake) -0.241\n",
            "step 2520 | loss_D 0.8847 | loss_G 1.1308 | D(real) +1.030 | D(fake) -0.321\n",
            "step 2530 | loss_D 0.8540 | loss_G 1.2237 | D(real) +0.876 | D(fake) -0.459\n",
            "step 2540 | loss_D 1.2627 | loss_G 1.0067 | D(real) -0.065 | D(fake) -0.349\n",
            "step 2550 | loss_D 1.3379 | loss_G 0.7821 | D(real) +0.273 | D(fake) +0.090\n",
            "step 2560 | loss_D 1.4662 | loss_G 0.8350 | D(real) -0.111 | D(fake) +0.026\n",
            "step 2570 | loss_D 1.4360 | loss_G 0.9077 | D(real) -0.210 | D(fake) -0.173\n",
            "step 2580 | loss_D 1.2204 | loss_G 1.0562 | D(real) +0.464 | D(fake) +0.014\n",
            "step 2590 | loss_D 1.4519 | loss_G 0.9529 | D(real) -0.163 | D(fake) -0.081\n",
            "step 2600 | loss_D 1.0611 | loss_G 0.9488 | D(real) +0.577 | D(fake) -0.197\n",
            "step 2610 | loss_D 1.4531 | loss_G 0.8496 | D(real) -0.121 | D(fake) -0.003\n",
            "step 2620 | loss_D 1.5839 | loss_G 0.8463 | D(real) -0.333 | D(fake) -0.019\n",
            "step 2630 | loss_D 1.6198 | loss_G 1.1080 | D(real) +0.156 | D(fake) +0.431\n",
            "step 2640 | loss_D 1.1308 | loss_G 1.0118 | D(real) +0.820 | D(fake) +0.108\n",
            "step 2650 | loss_D 1.4528 | loss_G 1.1306 | D(real) -0.198 | D(fake) -0.123\n",
            "step 2660 | loss_D 1.2787 | loss_G 0.9003 | D(real) -0.123 | D(fake) -0.406\n",
            "step 2670 | loss_D 1.2577 | loss_G 0.7465 | D(real) +0.506 | D(fake) +0.126\n",
            "step 2680 | loss_D 1.3906 | loss_G 0.8725 | D(real) +0.227 | D(fake) +0.153\n",
            "step 2690 | loss_D 1.5941 | loss_G 1.2928 | D(real) -0.837 | D(fake) -0.774\n",
            "step 2700 | loss_D 1.1631 | loss_G 0.8657 | D(real) +0.612 | D(fake) -0.115\n",
            "step 2710 | loss_D 1.3758 | loss_G 0.9802 | D(real) -0.031 | D(fake) -0.058\n",
            "step 2720 | loss_D 1.1337 | loss_G 0.9134 | D(real) +0.488 | D(fake) -0.159\n",
            "step 2730 | loss_D 1.3521 | loss_G 0.8270 | D(real) -0.271 | D(fake) -0.483\n",
            "step 2740 | loss_D 1.3623 | loss_G 0.8053 | D(real) -0.071 | D(fake) -0.156\n",
            "step 2750 | loss_D 1.3172 | loss_G 0.8349 | D(real) +0.295 | D(fake) +0.049\n",
            "step 2760 | loss_D 1.6362 | loss_G 0.9512 | D(real) -0.604 | D(fake) -0.228\n",
            "step 2770 | loss_D 1.1942 | loss_G 0.7666 | D(real) +0.515 | D(fake) -0.013\n",
            "step 2780 | loss_D 1.1767 | loss_G 1.1213 | D(real) -0.022 | D(fake) -0.526\n",
            "step 2790 | loss_D 1.2040 | loss_G 1.1122 | D(real) +0.166 | D(fake) -0.243\n",
            "step 2800 | loss_D 1.4379 | loss_G 1.1143 | D(real) +0.349 | D(fake) +0.242\n",
            "step 2810 | loss_D 1.6051 | loss_G 0.7526 | D(real) -0.231 | D(fake) +0.146\n",
            "step 2820 | loss_D 1.3954 | loss_G 0.8629 | D(real) -0.001 | D(fake) +0.007\n",
            "step 2830 | loss_D 1.4433 | loss_G 0.8204 | D(real) -0.157 | D(fake) -0.065\n",
            "step 2840 | loss_D 1.1698 | loss_G 0.8069 | D(real) +0.211 | D(fake) -0.347\n",
            "step 2850 | loss_D 1.3727 | loss_G 0.8757 | D(real) -0.049 | D(fake) -0.093\n",
            "step 2860 | loss_D 1.1564 | loss_G 0.9008 | D(real) +0.781 | D(fake) +0.030\n",
            "step 2870 | loss_D 1.0242 | loss_G 1.2727 | D(real) +0.584 | D(fake) -0.887\n",
            "step 2880 | loss_D 1.1892 | loss_G 1.1806 | D(real) +0.491 | D(fake) -0.005\n",
            "step 2890 | loss_D 1.0725 | loss_G 0.9267 | D(real) +0.426 | D(fake) -0.274\n",
            "step 2900 | loss_D 1.5126 | loss_G 0.8136 | D(real) -0.187 | D(fake) -0.028\n",
            "step 2910 | loss_D 1.3098 | loss_G 0.6632 | D(real) +0.356 | D(fake) +0.110\n",
            "step 2920 | loss_D 1.3616 | loss_G 0.7783 | D(real) -0.304 | D(fake) -0.459\n",
            "step 2930 | loss_D 1.1724 | loss_G 0.8899 | D(real) +0.123 | D(fake) -0.494\n",
            "step 2940 | loss_D 1.2696 | loss_G 0.9956 | D(real) +0.304 | D(fake) -0.121\n",
            "step 2950 | loss_D 1.2504 | loss_G 0.9938 | D(real) +0.209 | D(fake) -0.263\n",
            "step 2960 | loss_D 1.4728 | loss_G 0.9104 | D(real) -0.230 | D(fake) -0.153\n",
            "step 2970 | loss_D 1.3901 | loss_G 0.8697 | D(real) +0.002 | D(fake) -0.068\n",
            "step 2980 | loss_D 1.1760 | loss_G 0.9487 | D(real) +0.275 | D(fake) -0.251\n",
            "step 2990 | loss_D 1.2730 | loss_G 1.1521 | D(real) +0.214 | D(fake) -0.295\n",
            "step 3000 | loss_D 1.8537 | loss_G 0.6188 | D(real) -0.651 | D(fake) +0.079\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_003000.pt\n",
            "step 3010 | loss_D 1.1203 | loss_G 1.4056 | D(real) +0.603 | D(fake) -0.176\n",
            "step 3020 | loss_D 1.0257 | loss_G 1.1654 | D(real) +0.221 | D(fake) -0.786\n",
            "step 3030 | loss_D 0.9080 | loss_G 1.2105 | D(real) +1.089 | D(fake) -0.306\n",
            "step 3040 | loss_D 1.4879 | loss_G 1.2435 | D(real) +0.153 | D(fake) +0.187\n",
            "step 3050 | loss_D 1.7255 | loss_G 0.8115 | D(real) -0.059 | D(fake) +0.523\n",
            "step 3060 | loss_D 1.3323 | loss_G 1.3100 | D(real) +0.332 | D(fake) -0.075\n",
            "step 3070 | loss_D 1.2100 | loss_G 1.0014 | D(real) +0.294 | D(fake) -0.131\n",
            "step 3080 | loss_D 1.3333 | loss_G 0.8779 | D(real) -0.104 | D(fake) -0.277\n",
            "step 3090 | loss_D 1.2195 | loss_G 0.7966 | D(real) +0.590 | D(fake) +0.083\n",
            "step 3100 | loss_D 1.5502 | loss_G 0.9552 | D(real) -0.362 | D(fake) -0.160\n",
            "step 3110 | loss_D 1.6270 | loss_G 0.8592 | D(real) -0.505 | D(fake) -0.163\n",
            "step 3120 | loss_D 1.0673 | loss_G 0.8207 | D(real) +0.792 | D(fake) -0.023\n",
            "step 3130 | loss_D 1.3423 | loss_G 1.0565 | D(real) -0.183 | D(fake) -0.419\n",
            "step 3140 | loss_D 1.0384 | loss_G 1.3437 | D(real) +0.445 | D(fake) -0.357\n",
            "step 3150 | loss_D 1.3521 | loss_G 0.7964 | D(real) -0.161 | D(fake) -0.273\n",
            "step 3160 | loss_D 1.3414 | loss_G 0.7786 | D(real) +0.207 | D(fake) +0.087\n",
            "step 3170 | loss_D 1.1828 | loss_G 1.0793 | D(real) +0.590 | D(fake) +0.002\n",
            "step 3180 | loss_D 1.2720 | loss_G 1.0231 | D(real) +0.329 | D(fake) +0.015\n",
            "step 3190 | loss_D 1.0450 | loss_G 1.1513 | D(real) +0.874 | D(fake) -0.234\n",
            "step 3200 | loss_D 1.0410 | loss_G 0.6985 | D(real) +0.642 | D(fake) -0.271\n",
            "step 3210 | loss_D 1.6955 | loss_G 0.9953 | D(real) -0.958 | D(fake) -1.144\n",
            "step 3220 | loss_D 1.2660 | loss_G 0.9454 | D(real) -0.042 | D(fake) -0.347\n",
            "step 3230 | loss_D 1.0140 | loss_G 1.2469 | D(real) +0.382 | D(fake) -0.527\n",
            "step 3240 | loss_D 0.8163 | loss_G 1.4215 | D(real) +1.227 | D(fake) -0.404\n",
            "step 3250 | loss_D 1.3251 | loss_G 1.0631 | D(real) -0.036 | D(fake) -0.321\n",
            "step 3260 | loss_D 1.8883 | loss_G 0.7839 | D(real) -0.873 | D(fake) -0.241\n",
            "step 3270 | loss_D 1.2680 | loss_G 1.1338 | D(real) +0.208 | D(fake) -0.220\n",
            "step 3280 | loss_D 1.4751 | loss_G 0.7205 | D(real) +0.440 | D(fake) +0.389\n",
            "step 3290 | loss_D 1.1994 | loss_G 0.9351 | D(real) +0.132 | D(fake) -0.327\n",
            "step 3300 | loss_D 0.9505 | loss_G 1.2113 | D(real) +0.552 | D(fake) -0.673\n",
            "step 3310 | loss_D 1.0039 | loss_G 1.2613 | D(real) +0.562 | D(fake) -0.606\n",
            "step 3320 | loss_D 1.0080 | loss_G 1.1872 | D(real) +0.812 | D(fake) -0.345\n",
            "step 3330 | loss_D 1.1354 | loss_G 0.8068 | D(real) +0.613 | D(fake) -0.005\n",
            "step 3340 | loss_D 1.6253 | loss_G 1.3091 | D(real) -0.957 | D(fake) -1.006\n",
            "step 3350 | loss_D 1.4228 | loss_G 0.7831 | D(real) -0.025 | D(fake) -0.037\n",
            "step 3360 | loss_D 1.4526 | loss_G 0.9832 | D(real) +0.256 | D(fake) -0.042\n",
            "step 3370 | loss_D 1.3955 | loss_G 0.7407 | D(real) -0.133 | D(fake) -0.173\n",
            "step 3380 | loss_D 1.4983 | loss_G 0.9516 | D(real) +0.373 | D(fake) +0.437\n",
            "step 3390 | loss_D 1.4334 | loss_G 0.9407 | D(real) +0.003 | D(fake) +0.039\n",
            "step 3400 | loss_D 1.3927 | loss_G 0.7156 | D(real) +0.046 | D(fake) +0.052\n",
            "step 3410 | loss_D 1.2153 | loss_G 0.8404 | D(real) +0.260 | D(fake) -0.137\n",
            "step 3420 | loss_D 1.1245 | loss_G 0.9412 | D(real) +0.484 | D(fake) -0.134\n",
            "step 3430 | loss_D 1.1435 | loss_G 0.9926 | D(real) +0.287 | D(fake) -0.292\n",
            "step 3440 | loss_D 1.1936 | loss_G 1.3135 | D(real) +0.296 | D(fake) -0.220\n",
            "step 3450 | loss_D 1.5084 | loss_G 1.0557 | D(real) -0.416 | D(fake) -0.270\n",
            "step 3460 | loss_D 1.1608 | loss_G 1.4069 | D(real) +0.153 | D(fake) -0.413\n",
            "step 3470 | loss_D 1.4549 | loss_G 0.9911 | D(real) -0.504 | D(fake) -0.583\n",
            "step 3480 | loss_D 1.4009 | loss_G 0.8766 | D(real) +0.064 | D(fake) -0.455\n",
            "step 3490 | loss_D 1.2366 | loss_G 0.8814 | D(real) -0.068 | D(fake) -0.476\n",
            "step 3500 | loss_D 1.2822 | loss_G 1.1017 | D(real) +0.470 | D(fake) -0.130\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_003500.pt\n",
            "step 3510 | loss_D 0.9890 | loss_G 0.7919 | D(real) +0.462 | D(fake) -0.576\n",
            "step 3520 | loss_D 1.6266 | loss_G 1.0163 | D(real) +0.094 | D(fake) +0.453\n",
            "step 3530 | loss_D 1.0642 | loss_G 0.8534 | D(real) +0.438 | D(fake) -0.335\n",
            "step 3540 | loss_D 0.8632 | loss_G 1.5923 | D(real) +1.812 | D(fake) -0.103\n",
            "step 3550 | loss_D 1.5676 | loss_G 0.7974 | D(real) -0.549 | D(fake) -0.653\n",
            "step 3560 | loss_D 1.1932 | loss_G 0.6348 | D(real) +0.126 | D(fake) -0.317\n",
            "step 3570 | loss_D 1.2559 | loss_G 1.0370 | D(real) +0.115 | D(fake) -0.195\n",
            "step 3580 | loss_D 1.0638 | loss_G 0.8557 | D(real) +0.325 | D(fake) -0.409\n",
            "step 3590 | loss_D 1.1582 | loss_G 0.9860 | D(real) +0.157 | D(fake) -0.646\n",
            "step 3600 | loss_D 1.2120 | loss_G 0.8430 | D(real) +0.607 | D(fake) -0.334\n",
            "step 3610 | loss_D 1.2473 | loss_G 0.9051 | D(real) +0.023 | D(fake) -0.333\n",
            "step 3620 | loss_D 0.9556 | loss_G 1.1118 | D(real) +0.807 | D(fake) -0.382\n",
            "step 3630 | loss_D 1.3202 | loss_G 1.1401 | D(real) +1.191 | D(fake) +0.302\n",
            "step 3640 | loss_D 1.1685 | loss_G 1.0090 | D(real) +0.183 | D(fake) -0.367\n",
            "step 3650 | loss_D 1.1939 | loss_G 0.9612 | D(real) +0.084 | D(fake) -0.477\n",
            "step 3660 | loss_D 1.3467 | loss_G 0.7567 | D(real) +0.094 | D(fake) -0.159\n",
            "step 3670 | loss_D 1.3330 | loss_G 0.6859 | D(real) +0.175 | D(fake) -0.028\n",
            "step 3680 | loss_D 0.9820 | loss_G 0.7733 | D(real) +0.914 | D(fake) -0.172\n",
            "step 3690 | loss_D 1.0556 | loss_G 1.0109 | D(real) +0.592 | D(fake) -0.268\n",
            "step 3700 | loss_D 1.1519 | loss_G 1.0808 | D(real) +0.076 | D(fake) -0.525\n",
            "step 3710 | loss_D 1.2454 | loss_G 0.9688 | D(real) +0.360 | D(fake) -0.152\n",
            "step 3720 | loss_D 1.5768 | loss_G 1.0385 | D(real) -0.630 | D(fake) -0.452\n",
            "step 3730 | loss_D 0.9790 | loss_G 1.4430 | D(real) +0.354 | D(fake) -0.742\n",
            "step 3740 | loss_D 1.2850 | loss_G 0.9292 | D(real) +0.006 | D(fake) -0.267\n",
            "step 3750 | loss_D 1.0622 | loss_G 0.8778 | D(real) +0.385 | D(fake) -0.426\n",
            "step 3760 | loss_D 1.2054 | loss_G 1.1252 | D(real) -0.189 | D(fake) -0.751\n",
            "step 3770 | loss_D 0.9563 | loss_G 1.4446 | D(real) +0.872 | D(fake) -0.310\n",
            "step 3780 | loss_D 0.8279 | loss_G 1.1783 | D(real) +1.466 | D(fake) -0.220\n",
            "step 3790 | loss_D 1.6436 | loss_G 0.8580 | D(real) -0.612 | D(fake) -0.220\n",
            "step 3800 | loss_D 1.1960 | loss_G 0.6078 | D(real) +0.187 | D(fake) -0.290\n",
            "step 3810 | loss_D 1.7445 | loss_G 1.0386 | D(real) -0.678 | D(fake) -0.162\n",
            "step 3820 | loss_D 1.2056 | loss_G 0.9793 | D(real) +0.031 | D(fake) -0.417\n",
            "step 3830 | loss_D 1.2062 | loss_G 0.9801 | D(real) +0.388 | D(fake) -0.021\n",
            "step 3840 | loss_D 1.0339 | loss_G 1.1000 | D(real) +1.211 | D(fake) -0.149\n",
            "step 3850 | loss_D 1.2090 | loss_G 1.0807 | D(real) +0.344 | D(fake) -0.077\n",
            "step 3860 | loss_D 1.1606 | loss_G 1.1132 | D(real) +0.368 | D(fake) -0.198\n",
            "step 3870 | loss_D 0.9875 | loss_G 0.9424 | D(real) +1.331 | D(fake) +0.027\n",
            "step 3880 | loss_D 1.1681 | loss_G 1.1850 | D(real) -0.006 | D(fake) -0.657\n",
            "step 3890 | loss_D 1.0166 | loss_G 1.4110 | D(real) +0.840 | D(fake) -0.168\n",
            "step 3900 | loss_D 1.6486 | loss_G 1.3384 | D(real) +0.019 | D(fake) -0.728\n",
            "step 3910 | loss_D 0.9903 | loss_G 1.2445 | D(real) +0.907 | D(fake) -0.278\n",
            "step 3920 | loss_D 1.0204 | loss_G 0.7594 | D(real) +1.769 | D(fake) +0.261\n",
            "step 3930 | loss_D 1.1420 | loss_G 1.1729 | D(real) +0.932 | D(fake) -0.133\n",
            "step 3940 | loss_D 1.0380 | loss_G 1.0102 | D(real) +0.211 | D(fake) -0.728\n",
            "step 3950 | loss_D 1.5773 | loss_G 0.8998 | D(real) -0.418 | D(fake) -0.142\n",
            "step 3960 | loss_D 1.1387 | loss_G 0.9060 | D(real) +0.584 | D(fake) -0.148\n",
            "step 3970 | loss_D 1.2126 | loss_G 0.9443 | D(real) -0.051 | D(fake) -0.486\n",
            "step 3980 | loss_D 1.1652 | loss_G 0.9858 | D(real) +0.445 | D(fake) -0.121\n",
            "step 3990 | loss_D 1.3591 | loss_G 0.8134 | D(real) +0.146 | D(fake) +0.067\n",
            "step 4000 | loss_D 0.7979 | loss_G 1.1383 | D(real) +1.131 | D(fake) -0.566\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_004000.pt\n",
            "step 4010 | loss_D 1.1682 | loss_G 1.0333 | D(real) +0.560 | D(fake) -0.066\n",
            "step 4020 | loss_D 0.9821 | loss_G 1.2838 | D(real) +0.183 | D(fake) -0.829\n",
            "step 4030 | loss_D 1.0941 | loss_G 1.1289 | D(real) +1.184 | D(fake) +0.089\n",
            "step 4040 | loss_D 1.9589 | loss_G 0.4363 | D(real) -1.354 | D(fake) -0.880\n",
            "step 4050 | loss_D 1.1602 | loss_G 0.7056 | D(real) +0.141 | D(fake) -0.398\n",
            "step 4060 | loss_D 1.5121 | loss_G 0.7676 | D(real) +0.192 | D(fake) +0.244\n",
            "step 4070 | loss_D 1.3933 | loss_G 1.0477 | D(real) -0.296 | D(fake) -0.401\n",
            "step 4080 | loss_D 1.4418 | loss_G 1.0391 | D(real) -0.268 | D(fake) -0.202\n",
            "step 4090 | loss_D 1.0396 | loss_G 0.9774 | D(real) +0.403 | D(fake) -0.403\n",
            "step 4100 | loss_D 0.7466 | loss_G 1.3716 | D(real) +1.992 | D(fake) -0.729\n",
            "step 4110 | loss_D 1.4260 | loss_G 1.0540 | D(real) -0.195 | D(fake) -0.159\n",
            "step 4120 | loss_D 1.1294 | loss_G 1.0978 | D(real) +0.286 | D(fake) -0.528\n",
            "step 4130 | loss_D 1.2297 | loss_G 0.8677 | D(real) +0.354 | D(fake) -0.013\n",
            "step 4140 | loss_D 1.3045 | loss_G 0.9730 | D(real) -0.388 | D(fake) -0.802\n",
            "step 4150 | loss_D 1.3621 | loss_G 0.9854 | D(real) +0.399 | D(fake) +0.136\n",
            "step 4160 | loss_D 0.6467 | loss_G 1.3333 | D(real) +1.173 | D(fake) -0.896\n",
            "step 4170 | loss_D 1.2638 | loss_G 0.8588 | D(real) +0.821 | D(fake) +0.192\n",
            "step 4180 | loss_D 1.4213 | loss_G 1.4518 | D(real) -0.486 | D(fake) -0.745\n",
            "step 4190 | loss_D 0.6811 | loss_G 1.8914 | D(real) +0.947 | D(fake) -1.131\n",
            "step 4200 | loss_D 1.2519 | loss_G 1.0895 | D(real) -0.077 | D(fake) -0.454\n",
            "step 4210 | loss_D 1.1345 | loss_G 1.0436 | D(real) +0.618 | D(fake) -0.073\n",
            "step 4220 | loss_D 0.9316 | loss_G 0.9467 | D(real) +1.847 | D(fake) +0.064\n",
            "step 4230 | loss_D 1.4651 | loss_G 0.7988 | D(real) -0.176 | D(fake) -0.149\n",
            "step 4240 | loss_D 1.2568 | loss_G 0.8377 | D(real) +0.068 | D(fake) -0.208\n",
            "step 4250 | loss_D 0.9825 | loss_G 1.1339 | D(real) +0.371 | D(fake) -0.620\n",
            "step 4260 | loss_D 1.3749 | loss_G 0.9496 | D(real) -0.071 | D(fake) -0.184\n",
            "step 4270 | loss_D 1.1978 | loss_G 0.9196 | D(real) +0.799 | D(fake) +0.033\n",
            "step 4280 | loss_D 1.2781 | loss_G 0.9311 | D(real) +0.173 | D(fake) -0.238\n",
            "step 4290 | loss_D 0.9983 | loss_G 1.1649 | D(real) +0.581 | D(fake) -0.379\n",
            "step 4300 | loss_D 1.0807 | loss_G 1.1347 | D(real) +1.100 | D(fake) -0.387\n",
            "step 4310 | loss_D 1.4834 | loss_G 0.9934 | D(real) +0.191 | D(fake) +0.193\n",
            "step 4320 | loss_D 1.1505 | loss_G 1.0300 | D(real) +0.342 | D(fake) -0.321\n",
            "step 4330 | loss_D 0.9285 | loss_G 0.7805 | D(real) +0.699 | D(fake) -0.417\n",
            "step 4340 | loss_D 0.9797 | loss_G 1.0824 | D(real) +0.627 | D(fake) -0.341\n",
            "step 4350 | loss_D 1.3472 | loss_G 0.9038 | D(real) +1.289 | D(fake) +0.601\n",
            "step 4360 | loss_D 0.7070 | loss_G 1.3954 | D(real) +1.273 | D(fake) -0.649\n",
            "step 4370 | loss_D 1.6468 | loss_G 0.8839 | D(real) -0.520 | D(fake) -0.095\n",
            "step 4380 | loss_D 1.0117 | loss_G 1.0845 | D(real) +0.505 | D(fake) -0.563\n",
            "step 4390 | loss_D 1.5458 | loss_G 0.6869 | D(real) -0.254 | D(fake) +0.014\n",
            "step 4400 | loss_D 0.8320 | loss_G 1.2642 | D(real) +0.968 | D(fake) -0.607\n",
            "step 4410 | loss_D 1.4667 | loss_G 0.7730 | D(real) +0.101 | D(fake) +0.135\n",
            "step 4420 | loss_D 1.2086 | loss_G 0.9113 | D(real) +0.242 | D(fake) -0.458\n",
            "step 4430 | loss_D 0.9975 | loss_G 1.1003 | D(real) +0.742 | D(fake) -0.259\n",
            "step 4440 | loss_D 1.0899 | loss_G 0.8172 | D(real) +0.289 | D(fake) -0.481\n",
            "step 4450 | loss_D 1.0652 | loss_G 0.9624 | D(real) +0.222 | D(fake) -0.551\n",
            "step 4460 | loss_D 0.8594 | loss_G 1.1427 | D(real) +1.604 | D(fake) -0.260\n",
            "step 4470 | loss_D 1.4424 | loss_G 0.6879 | D(real) +1.380 | D(fake) +0.574\n",
            "step 4480 | loss_D 0.8995 | loss_G 1.5099 | D(real) +0.328 | D(fake) -1.058\n",
            "step 4490 | loss_D 1.0419 | loss_G 1.1319 | D(real) +0.646 | D(fake) -0.318\n",
            "step 4500 | loss_D 1.1798 | loss_G 1.2388 | D(real) +0.918 | D(fake) +0.033\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_004500.pt\n",
            "step 4510 | loss_D 0.9379 | loss_G 1.1311 | D(real) +0.500 | D(fake) -0.581\n",
            "step 4520 | loss_D 1.5631 | loss_G 0.6203 | D(real) +0.321 | D(fake) +0.478\n",
            "step 4530 | loss_D 1.0535 | loss_G 1.0802 | D(real) +0.698 | D(fake) -0.187\n",
            "step 4540 | loss_D 1.1581 | loss_G 0.7308 | D(real) +0.294 | D(fake) -0.228\n",
            "step 4550 | loss_D 0.7293 | loss_G 1.0594 | D(real) +0.930 | D(fake) -0.766\n",
            "step 4560 | loss_D 1.1038 | loss_G 1.1133 | D(real) +0.683 | D(fake) -0.209\n",
            "step 4570 | loss_D 0.9449 | loss_G 1.1918 | D(real) +0.807 | D(fake) -0.583\n",
            "step 4580 | loss_D 1.2627 | loss_G 1.1802 | D(real) +0.813 | D(fake) +0.058\n",
            "step 4590 | loss_D 0.9095 | loss_G 1.0938 | D(real) +0.702 | D(fake) -0.517\n",
            "step 4600 | loss_D 1.2078 | loss_G 1.0188 | D(real) +0.020 | D(fake) -0.450\n",
            "step 4610 | loss_D 1.1744 | loss_G 0.8463 | D(real) +0.672 | D(fake) -0.010\n",
            "step 4620 | loss_D 0.7524 | loss_G 1.5813 | D(real) +1.894 | D(fake) -0.279\n",
            "step 4630 | loss_D 1.3386 | loss_G 1.1379 | D(real) +0.424 | D(fake) +0.146\n",
            "step 4640 | loss_D 0.8828 | loss_G 1.2519 | D(real) +0.935 | D(fake) -0.523\n",
            "step 4650 | loss_D 1.4865 | loss_G 0.7278 | D(real) -0.448 | D(fake) -0.581\n",
            "step 4660 | loss_D 0.9556 | loss_G 1.3458 | D(real) +0.084 | D(fake) -1.280\n",
            "step 4670 | loss_D 1.2689 | loss_G 0.9231 | D(real) +0.477 | D(fake) +0.026\n",
            "step 4680 | loss_D 1.4234 | loss_G 1.0852 | D(real) -0.275 | D(fake) -0.338\n",
            "step 4690 | loss_D 1.3851 | loss_G 1.0856 | D(real) -0.180 | D(fake) -0.270\n",
            "step 4700 | loss_D 0.9687 | loss_G 1.0062 | D(real) +0.822 | D(fake) -0.377\n",
            "step 4710 | loss_D 1.1448 | loss_G 1.1144 | D(real) -0.039 | D(fake) -0.755\n",
            "step 4720 | loss_D 1.4922 | loss_G 0.7755 | D(real) -0.283 | D(fake) -0.227\n",
            "step 4730 | loss_D 0.9005 | loss_G 0.7182 | D(real) +1.544 | D(fake) -0.237\n",
            "step 4740 | loss_D 1.4304 | loss_G 1.1612 | D(real) -0.039 | D(fake) -0.295\n",
            "step 4750 | loss_D 1.4213 | loss_G 1.0454 | D(real) -0.357 | D(fake) -0.423\n",
            "step 4760 | loss_D 1.1005 | loss_G 0.9615 | D(real) +0.976 | D(fake) -0.084\n",
            "step 4770 | loss_D 0.9998 | loss_G 1.2447 | D(real) +0.658 | D(fake) -0.609\n",
            "step 4780 | loss_D 1.0686 | loss_G 1.1137 | D(real) +0.740 | D(fake) -0.300\n",
            "step 4790 | loss_D 0.8744 | loss_G 1.2551 | D(real) +2.078 | D(fake) -0.700\n",
            "step 4800 | loss_D 0.9541 | loss_G 1.3426 | D(real) +0.339 | D(fake) -0.738\n",
            "step 4810 | loss_D 1.5721 | loss_G 1.0287 | D(real) -0.271 | D(fake) -0.439\n",
            "step 4820 | loss_D 1.6050 | loss_G 1.0294 | D(real) -1.062 | D(fake) -1.289\n",
            "step 4830 | loss_D 1.0819 | loss_G 1.3819 | D(real) +0.665 | D(fake) -0.086\n",
            "step 4840 | loss_D 1.1533 | loss_G 1.1607 | D(real) +0.203 | D(fake) -0.479\n",
            "step 4850 | loss_D 1.2619 | loss_G 0.8142 | D(real) +0.243 | D(fake) -0.158\n",
            "step 4860 | loss_D 1.5999 | loss_G 0.8459 | D(real) -0.649 | D(fake) -0.409\n",
            "step 4870 | loss_D 1.2541 | loss_G 0.9739 | D(real) +0.526 | D(fake) +0.082\n",
            "step 4880 | loss_D 0.8119 | loss_G 1.1590 | D(real) +0.795 | D(fake) -0.694\n",
            "step 4890 | loss_D 0.6587 | loss_G 1.3654 | D(real) +1.466 | D(fake) -0.857\n",
            "step 4900 | loss_D 0.7718 | loss_G 2.5332 | D(real) +2.215 | D(fake) -0.126\n",
            "step 4910 | loss_D 0.6914 | loss_G 1.4834 | D(real) +0.642 | D(fake) -1.266\n",
            "step 4920 | loss_D 1.3059 | loss_G 0.9800 | D(real) -0.019 | D(fake) -0.401\n",
            "step 4930 | loss_D 0.9012 | loss_G 1.1308 | D(real) +0.563 | D(fake) -0.796\n",
            "step 4940 | loss_D 1.1220 | loss_G 1.0617 | D(real) +1.119 | D(fake) -0.145\n",
            "step 4950 | loss_D 0.7570 | loss_G 1.2541 | D(real) +0.799 | D(fake) -0.764\n",
            "step 4960 | loss_D 0.8587 | loss_G 1.4192 | D(real) +2.033 | D(fake) -0.093\n",
            "step 4970 | loss_D 0.7973 | loss_G 1.6236 | D(real) +1.342 | D(fake) -0.489\n",
            "step 4980 | loss_D 1.1006 | loss_G 1.0538 | D(real) +0.867 | D(fake) -0.227\n",
            "step 4990 | loss_D 1.2870 | loss_G 1.2238 | D(real) +0.019 | D(fake) -0.371\n",
            "step 5000 | loss_D 1.5506 | loss_G 1.2357 | D(real) -0.405 | D(fake) -0.345\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_005000.pt\n",
            "step 5010 | loss_D 1.1917 | loss_G 0.7663 | D(real) +0.593 | D(fake) -0.049\n",
            "step 5020 | loss_D 1.3353 | loss_G 1.0191 | D(real) -0.091 | D(fake) -0.377\n",
            "step 5030 | loss_D 0.8163 | loss_G 1.2001 | D(real) +0.942 | D(fake) -0.701\n",
            "step 5040 | loss_D 1.5432 | loss_G 0.7772 | D(real) -0.480 | D(fake) -0.348\n",
            "step 5050 | loss_D 0.9549 | loss_G 1.2353 | D(real) +0.439 | D(fake) -0.653\n",
            "step 5060 | loss_D 1.6301 | loss_G 0.8862 | D(real) -0.397 | D(fake) -0.147\n",
            "step 5070 | loss_D 0.8744 | loss_G 1.2586 | D(real) +1.762 | D(fake) -0.839\n",
            "step 5080 | loss_D 1.0407 | loss_G 0.9603 | D(real) +1.172 | D(fake) +0.051\n",
            "step 5090 | loss_D 0.8955 | loss_G 1.1901 | D(real) +0.980 | D(fake) -0.273\n",
            "step 5100 | loss_D 0.9516 | loss_G 0.9941 | D(real) +0.453 | D(fake) -1.114\n",
            "step 5110 | loss_D 1.1243 | loss_G 1.0482 | D(real) +0.202 | D(fake) -0.494\n",
            "step 5120 | loss_D 1.4127 | loss_G 0.7348 | D(real) -0.072 | D(fake) -0.251\n",
            "step 5130 | loss_D 0.8542 | loss_G 1.1509 | D(real) +1.030 | D(fake) -0.537\n",
            "step 5140 | loss_D 0.9498 | loss_G 1.0971 | D(real) +1.106 | D(fake) -0.131\n",
            "step 5150 | loss_D 1.3857 | loss_G 1.3507 | D(real) +0.059 | D(fake) -0.038\n",
            "step 5160 | loss_D 1.8696 | loss_G 0.7836 | D(real) -0.770 | D(fake) -0.147\n",
            "step 5170 | loss_D 1.6925 | loss_G 1.0356 | D(real) -0.725 | D(fake) -0.468\n",
            "step 5180 | loss_D 0.8795 | loss_G 1.3182 | D(real) +1.073 | D(fake) -0.365\n",
            "step 5190 | loss_D 0.7702 | loss_G 1.2489 | D(real) +1.672 | D(fake) -0.214\n",
            "step 5200 | loss_D 0.7672 | loss_G 1.2559 | D(real) +1.272 | D(fake) -0.486\n",
            "step 5210 | loss_D 1.3740 | loss_G 0.9185 | D(real) +0.230 | D(fake) -0.222\n",
            "step 5220 | loss_D 0.9374 | loss_G 1.1264 | D(real) +1.067 | D(fake) -0.196\n",
            "step 5230 | loss_D 0.9697 | loss_G 1.0174 | D(real) +0.743 | D(fake) -0.347\n",
            "step 5240 | loss_D 0.9985 | loss_G 1.3188 | D(real) +0.896 | D(fake) -0.548\n",
            "step 5250 | loss_D 0.9689 | loss_G 1.3023 | D(real) +1.328 | D(fake) -0.273\n",
            "step 5260 | loss_D 0.5916 | loss_G 1.4606 | D(real) +1.703 | D(fake) -0.775\n",
            "step 5270 | loss_D 1.4465 | loss_G 1.4141 | D(real) -0.446 | D(fake) -0.709\n",
            "step 5280 | loss_D 1.1502 | loss_G 1.9302 | D(real) +0.287 | D(fake) -0.590\n",
            "step 5290 | loss_D 1.1486 | loss_G 1.1770 | D(real) +1.050 | D(fake) +0.171\n",
            "step 5300 | loss_D 1.0827 | loss_G 1.0041 | D(real) +0.280 | D(fake) -0.446\n",
            "step 5310 | loss_D 1.0561 | loss_G 1.0369 | D(real) +0.649 | D(fake) -0.142\n",
            "step 5320 | loss_D 1.4131 | loss_G 1.0526 | D(real) -0.163 | D(fake) -0.132\n",
            "step 5330 | loss_D 1.1437 | loss_G 1.0182 | D(real) +0.252 | D(fake) -0.289\n",
            "step 5340 | loss_D 1.1432 | loss_G 1.0293 | D(real) +0.313 | D(fake) -0.344\n",
            "step 5350 | loss_D 1.1982 | loss_G 1.1200 | D(real) +0.211 | D(fake) -0.335\n",
            "step 5360 | loss_D 1.0409 | loss_G 1.0419 | D(real) +0.662 | D(fake) -0.489\n",
            "step 5370 | loss_D 0.8675 | loss_G 1.2652 | D(real) +1.192 | D(fake) -0.560\n",
            "step 5380 | loss_D 1.2987 | loss_G 1.4257 | D(real) +0.520 | D(fake) -0.844\n",
            "step 5390 | loss_D 0.8661 | loss_G 1.5329 | D(real) +0.599 | D(fake) -0.672\n",
            "step 5400 | loss_D 0.9201 | loss_G 1.0955 | D(real) +1.420 | D(fake) -0.100\n",
            "step 5410 | loss_D 0.8896 | loss_G 1.1284 | D(real) +1.127 | D(fake) -0.673\n",
            "step 5420 | loss_D 1.2743 | loss_G 1.1663 | D(real) +0.150 | D(fake) -0.268\n",
            "step 5430 | loss_D 0.8383 | loss_G 1.3913 | D(real) +0.998 | D(fake) -0.442\n",
            "step 5440 | loss_D 1.1674 | loss_G 1.0104 | D(real) +0.241 | D(fake) -0.437\n",
            "step 5450 | loss_D 1.1158 | loss_G 0.8694 | D(real) +0.495 | D(fake) -0.203\n",
            "step 5460 | loss_D 0.9066 | loss_G 1.5510 | D(real) +0.503 | D(fake) -0.944\n",
            "step 5470 | loss_D 0.9340 | loss_G 1.7911 | D(real) +0.841 | D(fake) -0.711\n",
            "step 5480 | loss_D 1.0413 | loss_G 1.2745 | D(real) +0.902 | D(fake) -0.359\n",
            "step 5490 | loss_D 1.1865 | loss_G 0.7279 | D(real) +0.542 | D(fake) +0.018\n",
            "step 5500 | loss_D 0.9646 | loss_G 0.9367 | D(real) +0.529 | D(fake) -0.513\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_005500.pt\n",
            "step 5510 | loss_D 0.9594 | loss_G 1.0885 | D(real) +1.247 | D(fake) -0.418\n",
            "step 5520 | loss_D 0.9953 | loss_G 1.1067 | D(real) +0.674 | D(fake) -0.434\n",
            "step 5530 | loss_D 1.3217 | loss_G 0.7787 | D(real) +0.364 | D(fake) +0.078\n",
            "step 5540 | loss_D 1.3190 | loss_G 1.0458 | D(real) +0.523 | D(fake) -0.036\n",
            "step 5550 | loss_D 0.9028 | loss_G 1.0991 | D(real) +0.616 | D(fake) -0.560\n",
            "step 5560 | loss_D 0.8572 | loss_G 1.1599 | D(real) +0.729 | D(fake) -0.680\n",
            "step 5570 | loss_D 1.6414 | loss_G 1.1072 | D(real) -0.867 | D(fake) -0.777\n",
            "step 5580 | loss_D 0.9325 | loss_G 1.4995 | D(real) +0.547 | D(fake) -0.589\n",
            "step 5590 | loss_D 1.0900 | loss_G 1.0666 | D(real) +0.190 | D(fake) -0.528\n",
            "step 5600 | loss_D 1.2220 | loss_G 1.2308 | D(real) +0.043 | D(fake) -0.542\n",
            "step 5610 | loss_D 0.8787 | loss_G 1.2043 | D(real) +0.756 | D(fake) -0.709\n",
            "step 5620 | loss_D 1.6199 | loss_G 0.8580 | D(real) -0.204 | D(fake) -0.336\n",
            "step 5630 | loss_D 1.3020 | loss_G 0.9150 | D(real) +0.296 | D(fake) -0.244\n",
            "step 5640 | loss_D 0.7388 | loss_G 1.4615 | D(real) +2.518 | D(fake) -0.270\n",
            "step 5650 | loss_D 1.2584 | loss_G 1.4765 | D(real) +0.897 | D(fake) -0.310\n",
            "step 5660 | loss_D 0.9946 | loss_G 1.1940 | D(real) +0.814 | D(fake) -0.380\n",
            "step 5670 | loss_D 0.7731 | loss_G 1.4474 | D(real) +1.082 | D(fake) -0.730\n",
            "step 5680 | loss_D 1.0603 | loss_G 1.4539 | D(real) +0.249 | D(fake) -0.841\n",
            "step 5690 | loss_D 1.0139 | loss_G 0.8166 | D(real) +0.610 | D(fake) -0.377\n",
            "step 5700 | loss_D 0.9720 | loss_G 0.9349 | D(real) +2.320 | D(fake) +0.116\n",
            "step 5710 | loss_D 1.0146 | loss_G 1.1139 | D(real) +0.180 | D(fake) -0.937\n",
            "step 5720 | loss_D 1.6068 | loss_G 0.9114 | D(real) -0.426 | D(fake) -0.223\n",
            "step 5730 | loss_D 0.7503 | loss_G 1.1097 | D(real) +1.450 | D(fake) -0.558\n",
            "step 5740 | loss_D 0.8371 | loss_G 1.7277 | D(real) +1.213 | D(fake) -0.284\n",
            "step 5750 | loss_D 1.1937 | loss_G 1.3907 | D(real) -0.288 | D(fake) -1.200\n",
            "step 5760 | loss_D 1.9247 | loss_G 1.0194 | D(real) -0.650 | D(fake) -0.007\n",
            "step 5770 | loss_D 1.0943 | loss_G 0.9367 | D(real) +0.470 | D(fake) -0.202\n",
            "step 5780 | loss_D 1.1691 | loss_G 1.3896 | D(real) +0.862 | D(fake) -0.240\n",
            "step 5790 | loss_D 0.7971 | loss_G 1.4394 | D(real) +1.443 | D(fake) -0.875\n",
            "step 5800 | loss_D 1.2367 | loss_G 0.9308 | D(real) +0.787 | D(fake) +0.189\n",
            "step 5810 | loss_D 0.8731 | loss_G 1.1709 | D(real) +0.478 | D(fake) -0.840\n",
            "step 5820 | loss_D 1.0377 | loss_G 1.2097 | D(real) +0.667 | D(fake) -0.238\n",
            "step 5830 | loss_D 0.7627 | loss_G 1.8017 | D(real) +0.974 | D(fake) -1.004\n",
            "step 5840 | loss_D 1.1135 | loss_G 0.7828 | D(real) +0.439 | D(fake) -0.491\n",
            "step 5850 | loss_D 1.2787 | loss_G 1.4981 | D(real) +0.456 | D(fake) -0.007\n",
            "step 5860 | loss_D 1.0627 | loss_G 1.0706 | D(real) +0.825 | D(fake) -0.306\n",
            "step 5870 | loss_D 1.2182 | loss_G 0.8720 | D(real) -0.137 | D(fake) -0.616\n",
            "step 5880 | loss_D 0.6731 | loss_G 1.2194 | D(real) +1.552 | D(fake) -0.786\n",
            "step 5890 | loss_D 1.1076 | loss_G 1.0750 | D(real) +1.018 | D(fake) +0.111\n",
            "step 5900 | loss_D 1.2152 | loss_G 1.3100 | D(real) -0.120 | D(fake) -0.702\n",
            "step 5910 | loss_D 1.0909 | loss_G 1.4093 | D(real) +0.475 | D(fake) -0.540\n",
            "step 5920 | loss_D 0.7422 | loss_G 1.2783 | D(real) +1.185 | D(fake) -0.583\n",
            "step 5930 | loss_D 0.5654 | loss_G 1.4476 | D(real) +2.168 | D(fake) -0.793\n",
            "step 5940 | loss_D 1.2935 | loss_G 1.1969 | D(real) -0.287 | D(fake) -0.777\n",
            "step 5950 | loss_D 0.8250 | loss_G 1.3011 | D(real) +0.767 | D(fake) -0.778\n",
            "step 5960 | loss_D 1.0147 | loss_G 1.5246 | D(real) +0.941 | D(fake) -0.727\n",
            "step 5970 | loss_D 0.6969 | loss_G 1.7238 | D(real) +0.762 | D(fake) -1.091\n",
            "step 5980 | loss_D 1.6048 | loss_G 1.1499 | D(real) -0.012 | D(fake) +0.217\n",
            "step 5990 | loss_D 0.7274 | loss_G 1.5012 | D(real) +1.268 | D(fake) -0.586\n",
            "step 6000 | loss_D 1.1435 | loss_G 1.2818 | D(real) +0.108 | D(fake) -0.608\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_006000.pt\n",
            "step 6010 | loss_D 0.6904 | loss_G 1.3141 | D(real) +1.113 | D(fake) -0.999\n",
            "step 6020 | loss_D 1.0756 | loss_G 1.0332 | D(real) +0.235 | D(fake) -0.554\n",
            "step 6030 | loss_D 0.9623 | loss_G 1.5587 | D(real) +1.647 | D(fake) +0.120\n",
            "step 6040 | loss_D 0.5797 | loss_G 1.6581 | D(real) +1.799 | D(fake) -0.678\n",
            "step 6050 | loss_D 0.8449 | loss_G 1.2338 | D(real) +1.209 | D(fake) -0.363\n",
            "step 6060 | loss_D 1.5046 | loss_G 1.5850 | D(real) +0.413 | D(fake) +0.323\n",
            "step 6070 | loss_D 0.9732 | loss_G 1.5206 | D(real) +0.589 | D(fake) -0.642\n",
            "step 6080 | loss_D 1.0877 | loss_G 0.8881 | D(real) +1.374 | D(fake) -0.133\n",
            "step 6090 | loss_D 1.1598 | loss_G 1.3519 | D(real) +0.472 | D(fake) -0.467\n",
            "step 6100 | loss_D 0.9646 | loss_G 1.4810 | D(real) +0.480 | D(fake) -0.532\n",
            "step 6110 | loss_D 0.9324 | loss_G 0.8729 | D(real) +0.214 | D(fake) -0.996\n",
            "step 6120 | loss_D 1.7873 | loss_G 0.6635 | D(real) -0.234 | D(fake) +0.247\n",
            "step 6130 | loss_D 0.9614 | loss_G 1.0951 | D(real) +1.743 | D(fake) -0.188\n",
            "step 6140 | loss_D 1.1952 | loss_G 1.0349 | D(real) +0.614 | D(fake) -0.209\n",
            "step 6150 | loss_D 1.3720 | loss_G 1.0597 | D(real) -0.220 | D(fake) -0.430\n",
            "step 6160 | loss_D 0.8337 | loss_G 1.0750 | D(real) +1.527 | D(fake) -0.233\n",
            "step 6170 | loss_D 0.9832 | loss_G 1.0621 | D(real) +0.576 | D(fake) -0.649\n",
            "step 6180 | loss_D 0.9621 | loss_G 1.7730 | D(real) +0.935 | D(fake) -0.410\n",
            "step 6190 | loss_D 1.4139 | loss_G 1.5737 | D(real) +0.400 | D(fake) +0.053\n",
            "step 6200 | loss_D 1.2107 | loss_G 1.1065 | D(real) +0.760 | D(fake) -0.364\n",
            "step 6210 | loss_D 0.7611 | loss_G 1.4910 | D(real) +0.755 | D(fake) -0.837\n",
            "step 6220 | loss_D 1.2307 | loss_G 1.2998 | D(real) +0.009 | D(fake) -0.704\n",
            "step 6230 | loss_D 1.1103 | loss_G 1.1945 | D(real) +0.252 | D(fake) -0.674\n",
            "step 6240 | loss_D 1.1370 | loss_G 0.8628 | D(real) +0.352 | D(fake) -0.381\n",
            "step 6250 | loss_D 0.8542 | loss_G 1.2854 | D(real) +0.777 | D(fake) -0.620\n",
            "step 6260 | loss_D 0.5665 | loss_G 1.4439 | D(real) +1.460 | D(fake) -0.871\n",
            "step 6270 | loss_D 0.6646 | loss_G 1.6606 | D(real) +1.795 | D(fake) -0.581\n",
            "step 6280 | loss_D 1.0768 | loss_G 1.2263 | D(real) +0.301 | D(fake) -0.406\n",
            "step 6290 | loss_D 1.3661 | loss_G 0.9033 | D(real) +0.053 | D(fake) -0.231\n",
            "step 6300 | loss_D 0.8769 | loss_G 1.8805 | D(real) +0.916 | D(fake) -0.510\n",
            "step 6310 | loss_D 0.7023 | loss_G 1.7083 | D(real) +2.156 | D(fake) -0.637\n",
            "step 6320 | loss_D 1.7107 | loss_G 0.9768 | D(real) -0.135 | D(fake) +0.212\n",
            "step 6330 | loss_D 1.0300 | loss_G 1.0543 | D(real) +0.496 | D(fake) -0.634\n",
            "step 6340 | loss_D 1.1501 | loss_G 1.1444 | D(real) +1.114 | D(fake) +0.098\n",
            "step 6350 | loss_D 1.0949 | loss_G 0.9009 | D(real) +0.036 | D(fake) -0.897\n",
            "step 6360 | loss_D 1.2095 | loss_G 1.6417 | D(real) +0.138 | D(fake) -0.954\n",
            "step 6370 | loss_D 0.8352 | loss_G 1.2767 | D(real) +0.633 | D(fake) -0.752\n",
            "step 6380 | loss_D 0.7923 | loss_G 1.2973 | D(real) +0.904 | D(fake) -0.856\n",
            "step 6390 | loss_D 0.9769 | loss_G 1.2742 | D(real) +0.717 | D(fake) -0.425\n",
            "step 6400 | loss_D 0.9151 | loss_G 1.1330 | D(real) +0.810 | D(fake) -0.509\n",
            "step 6410 | loss_D 0.8612 | loss_G 1.1500 | D(real) +0.920 | D(fake) -0.472\n",
            "step 6420 | loss_D 0.9854 | loss_G 0.9561 | D(real) +0.583 | D(fake) -0.458\n",
            "step 6430 | loss_D 0.9035 | loss_G 1.3221 | D(real) +1.127 | D(fake) -0.880\n",
            "step 6440 | loss_D 0.7221 | loss_G 1.1825 | D(real) +2.188 | D(fake) -0.364\n",
            "step 6450 | loss_D 0.8505 | loss_G 1.2384 | D(real) +0.781 | D(fake) -0.586\n",
            "step 6460 | loss_D 1.0348 | loss_G 1.5651 | D(real) +0.096 | D(fake) -0.837\n",
            "step 6470 | loss_D 1.4962 | loss_G 2.1168 | D(real) -0.350 | D(fake) -0.726\n",
            "step 6480 | loss_D 1.4552 | loss_G 1.1021 | D(real) +0.768 | D(fake) +0.486\n",
            "step 6490 | loss_D 1.1972 | loss_G 1.1412 | D(real) +0.821 | D(fake) +0.083\n",
            "step 6500 | loss_D 1.2358 | loss_G 1.2838 | D(real) +1.585 | D(fake) +0.390\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_006500.pt\n",
            "step 6510 | loss_D 0.7102 | loss_G 1.5500 | D(real) +1.242 | D(fake) -0.771\n",
            "step 6520 | loss_D 1.0023 | loss_G 1.1406 | D(real) +0.700 | D(fake) -0.249\n",
            "step 6530 | loss_D 0.8870 | loss_G 0.9333 | D(real) +1.178 | D(fake) -0.321\n",
            "step 6540 | loss_D 0.7596 | loss_G 1.4801 | D(real) +1.114 | D(fake) -0.577\n",
            "step 6550 | loss_D 1.1347 | loss_G 1.0433 | D(real) -0.105 | D(fake) -1.034\n",
            "step 6560 | loss_D 1.0308 | loss_G 1.4718 | D(real) +0.601 | D(fake) -0.431\n",
            "step 6570 | loss_D 1.0660 | loss_G 1.1959 | D(real) +0.569 | D(fake) -0.326\n",
            "step 6580 | loss_D 1.3007 | loss_G 1.4959 | D(real) +0.650 | D(fake) -0.091\n",
            "step 6590 | loss_D 0.5359 | loss_G 1.6029 | D(real) +1.771 | D(fake) -1.223\n",
            "step 6600 | loss_D 1.1885 | loss_G 1.0671 | D(real) -0.012 | D(fake) -0.714\n",
            "step 6610 | loss_D 1.3507 | loss_G 1.1995 | D(real) -0.169 | D(fake) -0.461\n",
            "step 6620 | loss_D 1.0528 | loss_G 1.7255 | D(real) +1.192 | D(fake) -0.432\n",
            "step 6630 | loss_D 1.9840 | loss_G 1.3714 | D(real) -0.154 | D(fake) +0.187\n",
            "step 6640 | loss_D 0.7561 | loss_G 1.4885 | D(real) +1.397 | D(fake) -0.531\n",
            "step 6650 | loss_D 0.8871 | loss_G 1.2265 | D(real) +2.861 | D(fake) -0.230\n",
            "step 6660 | loss_D 1.3694 | loss_G 1.1608 | D(real) +0.583 | D(fake) +0.371\n",
            "step 6670 | loss_D 0.8791 | loss_G 0.7764 | D(real) +0.842 | D(fake) -0.404\n",
            "step 6680 | loss_D 0.9643 | loss_G 1.0555 | D(real) +0.623 | D(fake) -0.537\n",
            "step 6690 | loss_D 0.8526 | loss_G 1.0036 | D(real) +1.902 | D(fake) -0.138\n",
            "step 6700 | loss_D 1.0991 | loss_G 1.4742 | D(real) +0.392 | D(fake) -0.673\n",
            "step 6710 | loss_D 1.1440 | loss_G 0.8304 | D(real) +0.390 | D(fake) -0.416\n",
            "step 6720 | loss_D 1.1491 | loss_G 1.7206 | D(real) +0.816 | D(fake) -0.253\n",
            "step 6730 | loss_D 1.0271 | loss_G 1.5132 | D(real) +0.659 | D(fake) -0.624\n",
            "step 6740 | loss_D 0.7772 | loss_G 1.3753 | D(real) +1.216 | D(fake) -0.594\n",
            "step 6750 | loss_D 0.9023 | loss_G 1.6803 | D(real) +0.975 | D(fake) -0.335\n",
            "step 6760 | loss_D 0.9042 | loss_G 1.2217 | D(real) +1.278 | D(fake) -0.176\n",
            "step 6770 | loss_D 0.6698 | loss_G 1.5020 | D(real) +1.815 | D(fake) -1.077\n",
            "step 6780 | loss_D 0.6842 | loss_G 1.5076 | D(real) +1.145 | D(fake) -0.750\n",
            "step 6790 | loss_D 1.1315 | loss_G 1.0483 | D(real) +0.880 | D(fake) -0.348\n",
            "step 6800 | loss_D 0.9660 | loss_G 1.5855 | D(real) +0.508 | D(fake) -1.309\n",
            "step 6810 | loss_D 1.3607 | loss_G 1.4860 | D(real) +0.814 | D(fake) -0.090\n",
            "step 6820 | loss_D 0.8574 | loss_G 1.3189 | D(real) +0.668 | D(fake) -0.795\n",
            "step 6830 | loss_D 1.4798 | loss_G 0.9958 | D(real) -0.102 | D(fake) -0.442\n",
            "step 6840 | loss_D 1.3409 | loss_G 1.1079 | D(real) +0.562 | D(fake) +0.180\n",
            "step 6850 | loss_D 1.2002 | loss_G 1.1915 | D(real) +0.456 | D(fake) -0.416\n",
            "step 6860 | loss_D 1.1388 | loss_G 0.8551 | D(real) +1.721 | D(fake) +0.299\n",
            "step 6870 | loss_D 0.9010 | loss_G 0.9688 | D(real) +0.560 | D(fake) -1.014\n",
            "step 6880 | loss_D 1.8727 | loss_G 1.0849 | D(real) +0.079 | D(fake) +0.646\n",
            "step 6890 | loss_D 0.9747 | loss_G 1.0232 | D(real) +1.258 | D(fake) -0.522\n",
            "step 6900 | loss_D 1.2098 | loss_G 1.3839 | D(real) +0.247 | D(fake) -0.267\n",
            "step 6910 | loss_D 1.0941 | loss_G 1.2839 | D(real) +0.697 | D(fake) -0.333\n",
            "step 6920 | loss_D 0.7496 | loss_G 1.4824 | D(real) +1.280 | D(fake) -0.554\n",
            "step 6930 | loss_D 0.5507 | loss_G 1.2120 | D(real) +2.699 | D(fake) -0.675\n",
            "step 6940 | loss_D 1.0043 | loss_G 1.3288 | D(real) +1.380 | D(fake) -0.625\n",
            "step 6950 | loss_D 1.2897 | loss_G 1.3357 | D(real) -0.074 | D(fake) -0.690\n",
            "step 6960 | loss_D 0.7093 | loss_G 1.9604 | D(real) +1.506 | D(fake) -0.565\n",
            "step 6970 | loss_D 1.5464 | loss_G 1.0102 | D(real) +0.026 | D(fake) -0.225\n",
            "step 6980 | loss_D 1.2991 | loss_G 0.9471 | D(real) +0.675 | D(fake) -0.152\n",
            "step 6990 | loss_D 1.2314 | loss_G 0.9771 | D(real) -0.128 | D(fake) -0.652\n",
            "step 7000 | loss_D 0.8904 | loss_G 1.3503 | D(real) +1.651 | D(fake) -0.251\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_007000.pt\n",
            "step 7010 | loss_D 0.8518 | loss_G 1.4918 | D(real) +0.521 | D(fake) -1.251\n",
            "step 7020 | loss_D 0.5161 | loss_G 1.8827 | D(real) +1.842 | D(fake) -1.058\n",
            "step 7030 | loss_D 1.0953 | loss_G 0.8903 | D(real) +1.197 | D(fake) -0.158\n",
            "step 7040 | loss_D 0.8985 | loss_G 1.2310 | D(real) +0.461 | D(fake) -0.985\n",
            "step 7050 | loss_D 1.0015 | loss_G 1.2964 | D(real) +0.235 | D(fake) -0.771\n",
            "step 7060 | loss_D 1.5423 | loss_G 0.7896 | D(real) -0.402 | D(fake) -0.188\n",
            "step 7070 | loss_D 0.7100 | loss_G 1.1888 | D(real) +0.850 | D(fake) -1.229\n",
            "step 7080 | loss_D 0.9335 | loss_G 1.6505 | D(real) +0.654 | D(fake) -0.993\n",
            "step 7090 | loss_D 1.3690 | loss_G 1.2312 | D(real) -0.016 | D(fake) -0.244\n",
            "step 7100 | loss_D 1.1189 | loss_G 1.0695 | D(real) +0.809 | D(fake) -0.275\n",
            "step 7110 | loss_D 0.9817 | loss_G 1.3012 | D(real) +2.090 | D(fake) +0.219\n",
            "step 7120 | loss_D 1.1045 | loss_G 1.2378 | D(real) +0.673 | D(fake) -0.094\n",
            "step 7130 | loss_D 1.1305 | loss_G 0.8537 | D(real) +0.300 | D(fake) -0.387\n",
            "step 7140 | loss_D 1.0909 | loss_G 1.0391 | D(real) +0.218 | D(fake) -0.457\n",
            "step 7150 | loss_D 0.7720 | loss_G 1.3168 | D(real) +1.823 | D(fake) -0.324\n",
            "step 7160 | loss_D 0.6144 | loss_G 1.6835 | D(real) +1.535 | D(fake) -0.771\n",
            "step 7170 | loss_D 1.0634 | loss_G 1.3431 | D(real) +0.764 | D(fake) -0.276\n",
            "step 7180 | loss_D 1.3467 | loss_G 1.1224 | D(real) -0.072 | D(fake) -0.400\n",
            "step 7190 | loss_D 0.8614 | loss_G 1.2861 | D(real) +1.629 | D(fake) -0.358\n",
            "step 7200 | loss_D 1.0862 | loss_G 1.2154 | D(real) -0.031 | D(fake) -0.973\n",
            "step 7210 | loss_D 0.7428 | loss_G 1.1322 | D(real) +1.283 | D(fake) -0.536\n",
            "step 7220 | loss_D 1.2477 | loss_G 0.7914 | D(real) -0.067 | D(fake) -0.661\n",
            "step 7230 | loss_D 1.0273 | loss_G 1.2919 | D(real) +0.233 | D(fake) -1.123\n",
            "step 7240 | loss_D 0.7123 | loss_G 1.5570 | D(real) +1.656 | D(fake) -0.473\n",
            "step 7250 | loss_D 1.2539 | loss_G 1.4130 | D(real) +0.872 | D(fake) -0.036\n",
            "step 7260 | loss_D 0.8587 | loss_G 1.7430 | D(real) +0.123 | D(fake) -1.588\n",
            "step 7270 | loss_D 0.7618 | loss_G 1.3142 | D(real) +1.485 | D(fake) -0.409\n",
            "step 7280 | loss_D 1.0013 | loss_G 1.2001 | D(real) +1.846 | D(fake) +0.084\n",
            "step 7290 | loss_D 0.8296 | loss_G 1.2228 | D(real) +0.884 | D(fake) -0.629\n",
            "step 7300 | loss_D 0.8640 | loss_G 1.2544 | D(real) +1.921 | D(fake) -0.024\n",
            "step 7310 | loss_D 1.2979 | loss_G 1.0016 | D(real) -0.028 | D(fake) -0.318\n",
            "step 7320 | loss_D 0.9198 | loss_G 1.3879 | D(real) +0.928 | D(fake) -0.607\n",
            "step 7330 | loss_D 0.9793 | loss_G 0.8523 | D(real) +1.003 | D(fake) -0.464\n",
            "step 7340 | loss_D 0.5388 | loss_G 2.0316 | D(real) +1.294 | D(fake) -1.324\n",
            "step 7350 | loss_D 1.6341 | loss_G 1.2102 | D(real) +0.227 | D(fake) +0.486\n",
            "step 7360 | loss_D 0.8815 | loss_G 0.6841 | D(real) +1.099 | D(fake) -0.433\n",
            "step 7370 | loss_D 1.3045 | loss_G 1.0659 | D(real) +0.304 | D(fake) -0.188\n",
            "step 7380 | loss_D 1.0055 | loss_G 1.1728 | D(real) +0.323 | D(fake) -0.593\n",
            "step 7390 | loss_D 1.0486 | loss_G 1.2673 | D(real) +0.361 | D(fake) -0.771\n",
            "step 7400 | loss_D 0.6858 | loss_G 1.1772 | D(real) +1.228 | D(fake) -0.689\n",
            "step 7410 | loss_D 0.9696 | loss_G 0.8823 | D(real) +1.034 | D(fake) -0.268\n",
            "step 7420 | loss_D 1.2142 | loss_G 1.0190 | D(real) -0.084 | D(fake) -0.550\n",
            "step 7430 | loss_D 1.1197 | loss_G 0.8356 | D(real) +0.839 | D(fake) +0.052\n",
            "step 7440 | loss_D 0.9431 | loss_G 1.1870 | D(real) +0.907 | D(fake) -0.477\n",
            "step 7450 | loss_D 1.0232 | loss_G 1.1805 | D(real) +0.480 | D(fake) -0.830\n",
            "step 7460 | loss_D 0.9351 | loss_G 1.2883 | D(real) +1.015 | D(fake) -0.391\n",
            "step 7470 | loss_D 1.2608 | loss_G 1.1494 | D(real) +0.914 | D(fake) +0.330\n",
            "step 7480 | loss_D 0.6707 | loss_G 1.6357 | D(real) +1.166 | D(fake) -0.957\n",
            "step 7490 | loss_D 0.6911 | loss_G 1.9142 | D(real) +1.642 | D(fake) -1.203\n",
            "step 7500 | loss_D 1.4657 | loss_G 0.8061 | D(real) +0.445 | D(fake) +0.089\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_007500.pt\n",
            "step 7510 | loss_D 0.8465 | loss_G 1.7158 | D(real) +1.359 | D(fake) -0.201\n",
            "step 7520 | loss_D 1.0897 | loss_G 1.2155 | D(real) +0.141 | D(fake) -0.622\n",
            "step 7530 | loss_D 0.9547 | loss_G 0.9023 | D(real) +1.134 | D(fake) -0.113\n",
            "step 7540 | loss_D 0.8684 | loss_G 1.0868 | D(real) +1.264 | D(fake) -0.177\n",
            "step 7550 | loss_D 1.0893 | loss_G 1.2350 | D(real) +1.443 | D(fake) -0.332\n",
            "step 7560 | loss_D 0.9144 | loss_G 1.4418 | D(real) +0.949 | D(fake) -0.339\n",
            "step 7570 | loss_D 0.5321 | loss_G 1.2268 | D(real) +2.643 | D(fake) -0.585\n",
            "step 7580 | loss_D 1.0406 | loss_G 1.0453 | D(real) +0.637 | D(fake) -0.956\n",
            "step 7590 | loss_D 0.8377 | loss_G 1.4308 | D(real) +0.918 | D(fake) -0.749\n",
            "step 7600 | loss_D 0.9790 | loss_G 0.9821 | D(real) +0.662 | D(fake) -0.534\n",
            "step 7610 | loss_D 0.5647 | loss_G 1.7519 | D(real) +1.671 | D(fake) -0.859\n",
            "step 7620 | loss_D 1.0238 | loss_G 1.3077 | D(real) +0.768 | D(fake) -0.315\n",
            "step 7630 | loss_D 1.0712 | loss_G 0.9803 | D(real) +0.594 | D(fake) -0.240\n",
            "step 7640 | loss_D 0.7442 | loss_G 1.6793 | D(real) +1.096 | D(fake) -0.779\n",
            "step 7650 | loss_D 1.1211 | loss_G 0.9932 | D(real) +0.231 | D(fake) -0.466\n",
            "step 7660 | loss_D 0.6386 | loss_G 1.4110 | D(real) +1.216 | D(fake) -0.970\n",
            "step 7670 | loss_D 0.9736 | loss_G 1.3554 | D(real) +0.621 | D(fake) -0.559\n",
            "step 7680 | loss_D 0.6701 | loss_G 1.4874 | D(real) +0.862 | D(fake) -1.498\n",
            "step 7690 | loss_D 0.9944 | loss_G 1.2649 | D(real) +1.248 | D(fake) +0.009\n",
            "step 7700 | loss_D 1.3731 | loss_G 1.0872 | D(real) +0.085 | D(fake) -0.054\n",
            "step 7710 | loss_D 0.9727 | loss_G 2.2576 | D(real) +0.149 | D(fake) -1.166\n",
            "step 7720 | loss_D 1.2561 | loss_G 0.8662 | D(real) +1.078 | D(fake) +0.337\n",
            "step 7730 | loss_D 0.8080 | loss_G 1.2101 | D(real) +1.330 | D(fake) -0.372\n",
            "step 7740 | loss_D 1.1717 | loss_G 1.0228 | D(real) +0.219 | D(fake) -0.308\n",
            "step 7750 | loss_D 1.0302 | loss_G 1.2003 | D(real) +0.641 | D(fake) -0.434\n",
            "step 7760 | loss_D 1.0247 | loss_G 0.9523 | D(real) +1.618 | D(fake) +0.035\n",
            "step 7770 | loss_D 0.8797 | loss_G 1.4851 | D(real) +0.935 | D(fake) -1.046\n",
            "step 7780 | loss_D 1.2540 | loss_G 0.9254 | D(real) -0.126 | D(fake) -0.636\n",
            "step 7790 | loss_D 0.8758 | loss_G 1.0802 | D(real) +1.392 | D(fake) -0.308\n",
            "step 7800 | loss_D 1.2365 | loss_G 0.8001 | D(real) +1.085 | D(fake) +0.402\n",
            "step 7810 | loss_D 0.6099 | loss_G 1.4273 | D(real) +2.904 | D(fake) -1.118\n",
            "step 7820 | loss_D 0.8869 | loss_G 1.5714 | D(real) +0.707 | D(fake) -0.609\n",
            "step 7830 | loss_D 1.2046 | loss_G 1.1622 | D(real) +0.573 | D(fake) +0.036\n",
            "step 7840 | loss_D 0.9531 | loss_G 1.1799 | D(real) +0.540 | D(fake) -0.609\n",
            "step 7850 | loss_D 0.8890 | loss_G 1.3261 | D(real) +1.251 | D(fake) -0.266\n",
            "step 7860 | loss_D 0.8521 | loss_G 1.0620 | D(real) +0.882 | D(fake) -0.701\n",
            "step 7870 | loss_D 0.9815 | loss_G 0.9032 | D(real) +0.921 | D(fake) -0.340\n",
            "step 7880 | loss_D 0.7033 | loss_G 1.2904 | D(real) +1.209 | D(fake) -1.138\n",
            "step 7890 | loss_D 1.2754 | loss_G 0.9436 | D(real) +0.194 | D(fake) -0.105\n",
            "step 7900 | loss_D 1.0125 | loss_G 1.2911 | D(real) +2.400 | D(fake) +0.352\n",
            "step 7910 | loss_D 0.8008 | loss_G 1.2435 | D(real) +1.498 | D(fake) -0.286\n",
            "step 7920 | loss_D 0.8715 | loss_G 1.3159 | D(real) +1.624 | D(fake) -0.113\n",
            "step 7930 | loss_D 1.4956 | loss_G 1.1452 | D(real) -0.228 | D(fake) -0.476\n",
            "step 7940 | loss_D 1.0777 | loss_G 1.0171 | D(real) +0.207 | D(fake) -0.507\n",
            "step 7950 | loss_D 0.9269 | loss_G 1.7463 | D(real) +0.579 | D(fake) -0.657\n",
            "step 7960 | loss_D 1.3424 | loss_G 0.9567 | D(real) -0.078 | D(fake) -0.317\n",
            "step 7970 | loss_D 0.7529 | loss_G 1.4692 | D(real) +0.904 | D(fake) -1.024\n",
            "step 7980 | loss_D 1.3885 | loss_G 1.1060 | D(real) -0.008 | D(fake) -0.054\n",
            "step 7990 | loss_D 1.0591 | loss_G 0.8190 | D(real) +1.222 | D(fake) -0.056\n",
            "step 8000 | loss_D 1.1916 | loss_G 0.8976 | D(real) -0.215 | D(fake) -0.836\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_008000.pt\n",
            "step 8010 | loss_D 1.5193 | loss_G 1.0654 | D(real) -0.245 | D(fake) -0.050\n",
            "step 8020 | loss_D 0.7694 | loss_G 1.0335 | D(real) +1.533 | D(fake) -0.502\n",
            "step 8030 | loss_D 1.0090 | loss_G 1.3416 | D(real) +0.081 | D(fake) -0.888\n",
            "step 8040 | loss_D 1.3337 | loss_G 0.9751 | D(real) +0.032 | D(fake) -0.168\n",
            "step 8050 | loss_D 0.7795 | loss_G 1.7882 | D(real) +1.982 | D(fake) -0.686\n",
            "step 8060 | loss_D 1.3089 | loss_G 1.0053 | D(real) +0.123 | D(fake) -0.595\n",
            "step 8070 | loss_D 1.0874 | loss_G 0.8178 | D(real) +0.790 | D(fake) -0.053\n",
            "step 8080 | loss_D 0.8183 | loss_G 1.0896 | D(real) +0.707 | D(fake) -1.190\n",
            "step 8090 | loss_D 0.8844 | loss_G 1.3100 | D(real) +0.318 | D(fake) -0.983\n",
            "step 8100 | loss_D 1.1786 | loss_G 0.7963 | D(real) +0.080 | D(fake) -0.632\n",
            "step 8110 | loss_D 1.2044 | loss_G 1.3943 | D(real) +0.008 | D(fake) -0.605\n",
            "step 8120 | loss_D 0.7034 | loss_G 1.3538 | D(real) +1.031 | D(fake) -1.230\n",
            "step 8130 | loss_D 0.8815 | loss_G 1.2108 | D(real) +0.396 | D(fake) -0.951\n",
            "step 8140 | loss_D 1.4858 | loss_G 1.0157 | D(real) -0.250 | D(fake) -1.012\n",
            "step 8150 | loss_D 1.0992 | loss_G 1.3474 | D(real) +0.828 | D(fake) -0.145\n",
            "step 8160 | loss_D 1.1279 | loss_G 1.5081 | D(real) -0.166 | D(fake) -1.655\n",
            "step 8170 | loss_D 0.7805 | loss_G 1.0803 | D(real) +1.216 | D(fake) -0.766\n",
            "step 8180 | loss_D 0.8049 | loss_G 0.9549 | D(real) +1.215 | D(fake) -0.476\n",
            "step 8190 | loss_D 0.9224 | loss_G 1.0813 | D(real) +1.626 | D(fake) -0.367\n",
            "step 8200 | loss_D 0.7076 | loss_G 1.1615 | D(real) +2.045 | D(fake) -0.497\n",
            "step 8210 | loss_D 1.2745 | loss_G 1.2061 | D(real) -0.225 | D(fake) -1.321\n",
            "step 8220 | loss_D 1.1535 | loss_G 1.1480 | D(real) +0.346 | D(fake) -0.243\n",
            "step 8230 | loss_D 0.5659 | loss_G 2.1030 | D(real) +0.980 | D(fake) -2.000\n",
            "step 8240 | loss_D 1.1642 | loss_G 0.8461 | D(real) +0.686 | D(fake) -0.062\n",
            "step 8250 | loss_D 1.1661 | loss_G 0.9089 | D(real) +0.279 | D(fake) -0.323\n",
            "step 8260 | loss_D 0.9228 | loss_G 1.2204 | D(real) +0.670 | D(fake) -0.583\n",
            "step 8270 | loss_D 1.4663 | loss_G 0.7706 | D(real) -0.642 | D(fake) -0.793\n",
            "step 8280 | loss_D 0.7143 | loss_G 1.0084 | D(real) +0.808 | D(fake) -1.013\n",
            "step 8290 | loss_D 0.8681 | loss_G 1.3750 | D(real) +1.397 | D(fake) -0.366\n",
            "step 8300 | loss_D 1.2097 | loss_G 1.0814 | D(real) +0.018 | D(fake) -0.495\n",
            "step 8310 | loss_D 0.8503 | loss_G 1.3278 | D(real) +1.001 | D(fake) -1.146\n",
            "step 8320 | loss_D 0.6184 | loss_G 1.3316 | D(real) +1.432 | D(fake) -0.749\n",
            "step 8330 | loss_D 0.8207 | loss_G 1.0693 | D(real) +2.045 | D(fake) -0.159\n",
            "step 8340 | loss_D 0.7684 | loss_G 1.7700 | D(real) +1.069 | D(fake) -0.679\n",
            "step 8350 | loss_D 1.0568 | loss_G 1.4393 | D(real) +0.401 | D(fake) -0.451\n",
            "step 8360 | loss_D 1.1775 | loss_G 1.1849 | D(real) -0.128 | D(fake) -0.831\n",
            "step 8370 | loss_D 1.0462 | loss_G 1.2242 | D(real) +0.676 | D(fake) -0.406\n",
            "step 8380 | loss_D 1.2885 | loss_G 1.3592 | D(real) -0.117 | D(fake) -0.533\n",
            "step 8390 | loss_D 1.0156 | loss_G 1.3670 | D(real) +1.293 | D(fake) +0.005\n",
            "step 8400 | loss_D 1.4587 | loss_G 0.8685 | D(real) -0.008 | D(fake) -0.197\n",
            "step 8410 | loss_D 0.9591 | loss_G 0.7657 | D(real) +0.587 | D(fake) -0.526\n",
            "step 8420 | loss_D 1.0377 | loss_G 1.3346 | D(real) +0.474 | D(fake) -0.617\n",
            "step 8430 | loss_D 0.7238 | loss_G 0.7548 | D(real) +1.803 | D(fake) -0.429\n",
            "step 8440 | loss_D 1.2006 | loss_G 1.4683 | D(real) +0.430 | D(fake) -0.256\n",
            "step 8450 | loss_D 1.1859 | loss_G 0.9224 | D(real) +1.305 | D(fake) +0.159\n",
            "step 8460 | loss_D 0.8317 | loss_G 1.2279 | D(real) +0.935 | D(fake) -0.802\n",
            "step 8470 | loss_D 1.3186 | loss_G 1.0833 | D(real) -0.005 | D(fake) -0.501\n",
            "step 8480 | loss_D 1.3284 | loss_G 1.0042 | D(real) -0.188 | D(fake) -0.406\n",
            "step 8490 | loss_D 0.4401 | loss_G 1.4694 | D(real) +2.531 | D(fake) -0.908\n",
            "step 8500 | loss_D 1.2700 | loss_G 1.1565 | D(real) +0.703 | D(fake) +0.089\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_008500.pt\n",
            "step 8510 | loss_D 1.0938 | loss_G 1.3656 | D(real) +0.271 | D(fake) -0.499\n",
            "step 8520 | loss_D 1.2832 | loss_G 0.9349 | D(real) -0.334 | D(fake) -0.861\n",
            "step 8530 | loss_D 1.1646 | loss_G 1.0407 | D(real) +0.489 | D(fake) -0.511\n",
            "step 8540 | loss_D 1.2337 | loss_G 1.5556 | D(real) -0.302 | D(fake) -0.978\n",
            "step 8550 | loss_D 0.9322 | loss_G 0.9305 | D(real) +1.300 | D(fake) -0.169\n",
            "step 8560 | loss_D 1.0480 | loss_G 1.0122 | D(real) +1.142 | D(fake) +0.026\n",
            "step 8570 | loss_D 0.7360 | loss_G 1.2800 | D(real) +1.081 | D(fake) -0.834\n",
            "step 8580 | loss_D 1.5655 | loss_G 1.0008 | D(real) -0.759 | D(fake) -0.870\n",
            "step 8590 | loss_D 1.1523 | loss_G 0.7552 | D(real) +0.196 | D(fake) -0.703\n",
            "step 8600 | loss_D 1.0635 | loss_G 0.8576 | D(real) +0.185 | D(fake) -0.637\n",
            "step 8610 | loss_D 1.2081 | loss_G 1.2864 | D(real) +0.596 | D(fake) +0.015\n",
            "step 8620 | loss_D 1.5442 | loss_G 0.9357 | D(real) -0.688 | D(fake) -0.743\n",
            "step 8630 | loss_D 0.7466 | loss_G 1.2489 | D(real) +1.556 | D(fake) -0.654\n",
            "step 8640 | loss_D 1.1436 | loss_G 1.4098 | D(real) +0.734 | D(fake) -0.554\n",
            "step 8650 | loss_D 0.4619 | loss_G 2.3441 | D(real) +2.766 | D(fake) -1.013\n",
            "step 8660 | loss_D 0.8727 | loss_G 1.4322 | D(real) +1.200 | D(fake) -0.273\n",
            "step 8670 | loss_D 0.8764 | loss_G 1.0778 | D(real) +0.775 | D(fake) -0.556\n",
            "step 8680 | loss_D 1.5625 | loss_G 0.8885 | D(real) +0.023 | D(fake) +0.021\n",
            "step 8690 | loss_D 1.4588 | loss_G 0.6224 | D(real) -0.165 | D(fake) -0.244\n",
            "step 8700 | loss_D 0.9858 | loss_G 1.4273 | D(real) +0.812 | D(fake) -0.204\n",
            "step 8710 | loss_D 1.5762 | loss_G 0.6717 | D(real) -0.706 | D(fake) -0.567\n",
            "step 8720 | loss_D 1.3783 | loss_G 0.9259 | D(real) -0.365 | D(fake) -0.938\n",
            "step 8730 | loss_D 1.0670 | loss_G 1.1521 | D(real) +0.401 | D(fake) -0.909\n",
            "step 8740 | loss_D 0.8020 | loss_G 1.0089 | D(real) +0.702 | D(fake) -0.932\n",
            "step 8750 | loss_D 1.2236 | loss_G 1.1412 | D(real) -0.464 | D(fake) -1.281\n",
            "step 8760 | loss_D 0.6605 | loss_G 1.9185 | D(real) +1.374 | D(fake) -0.867\n",
            "step 8770 | loss_D 1.3923 | loss_G 1.0341 | D(real) +0.165 | D(fake) +0.095\n",
            "step 8780 | loss_D 0.5702 | loss_G 1.8260 | D(real) +1.411 | D(fake) -1.170\n",
            "step 8790 | loss_D 1.1854 | loss_G 1.2546 | D(real) +0.451 | D(fake) -0.527\n",
            "step 8800 | loss_D 0.6000 | loss_G 1.9081 | D(real) +2.027 | D(fake) -0.536\n",
            "step 8810 | loss_D 1.1211 | loss_G 0.9915 | D(real) +0.186 | D(fake) -0.936\n",
            "step 8820 | loss_D 1.2344 | loss_G 1.2025 | D(real) -0.083 | D(fake) -0.641\n",
            "step 8830 | loss_D 0.8904 | loss_G 1.4532 | D(real) +0.995 | D(fake) -0.908\n",
            "step 8840 | loss_D 0.6206 | loss_G 0.9182 | D(real) +1.840 | D(fake) -0.616\n",
            "step 8850 | loss_D 1.0290 | loss_G 0.9755 | D(real) +0.491 | D(fake) -0.498\n",
            "step 8860 | loss_D 0.9794 | loss_G 1.5424 | D(real) +0.808 | D(fake) -0.601\n",
            "step 8870 | loss_D 0.4693 | loss_G 1.4971 | D(real) +2.662 | D(fake) -0.768\n",
            "step 8880 | loss_D 1.0707 | loss_G 1.8777 | D(real) +0.951 | D(fake) -0.204\n",
            "step 8890 | loss_D 0.9199 | loss_G 1.2616 | D(real) +0.419 | D(fake) -0.935\n",
            "step 8900 | loss_D 1.5173 | loss_G 1.1467 | D(real) -0.454 | D(fake) -0.494\n",
            "step 8910 | loss_D 0.9020 | loss_G 0.8428 | D(real) +0.470 | D(fake) -0.720\n",
            "step 8920 | loss_D 1.2731 | loss_G 0.8340 | D(real) +0.010 | D(fake) -0.469\n",
            "step 8930 | loss_D 1.0799 | loss_G 1.1207 | D(real) +0.285 | D(fake) -0.587\n",
            "step 8940 | loss_D 1.2622 | loss_G 0.8373 | D(real) +0.223 | D(fake) -0.155\n",
            "step 8950 | loss_D 1.1892 | loss_G 1.3165 | D(real) +0.223 | D(fake) -0.573\n",
            "step 8960 | loss_D 1.1554 | loss_G 1.3510 | D(real) +0.300 | D(fake) -0.273\n",
            "step 8970 | loss_D 1.7848 | loss_G 0.7218 | D(real) -0.993 | D(fake) -1.020\n",
            "step 8980 | loss_D 1.0275 | loss_G 1.2672 | D(real) +0.749 | D(fake) -0.598\n",
            "step 8990 | loss_D 1.3514 | loss_G 0.8525 | D(real) -0.253 | D(fake) -0.603\n",
            "step 9000 | loss_D 1.0239 | loss_G 1.0082 | D(real) +0.119 | D(fake) -0.787\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_009000.pt\n",
            "step 9010 | loss_D 0.8021 | loss_G 1.3378 | D(real) +1.687 | D(fake) -0.439\n",
            "step 9020 | loss_D 1.0799 | loss_G 1.0322 | D(real) +0.183 | D(fake) -0.757\n",
            "step 9030 | loss_D 1.0326 | loss_G 0.9823 | D(real) +1.266 | D(fake) -0.199\n",
            "step 9040 | loss_D 1.0477 | loss_G 0.6727 | D(real) +0.446 | D(fake) -0.581\n",
            "step 9050 | loss_D 0.4655 | loss_G 1.8565 | D(real) +1.690 | D(fake) -1.287\n",
            "step 9060 | loss_D 0.4929 | loss_G 1.9863 | D(real) +1.728 | D(fake) -1.188\n",
            "step 9070 | loss_D 1.2708 | loss_G 1.4930 | D(real) -0.296 | D(fake) -1.316\n",
            "step 9080 | loss_D 0.9990 | loss_G 0.9376 | D(real) +0.797 | D(fake) -0.262\n",
            "step 9090 | loss_D 1.0507 | loss_G 1.3931 | D(real) +0.282 | D(fake) -0.590\n",
            "step 9100 | loss_D 0.9245 | loss_G 0.6692 | D(real) +0.365 | D(fake) -0.757\n",
            "step 9110 | loss_D 1.0889 | loss_G 0.8106 | D(real) +0.056 | D(fake) -0.829\n",
            "step 9120 | loss_D 0.6739 | loss_G 1.2031 | D(real) +1.538 | D(fake) -0.629\n",
            "step 9130 | loss_D 1.3017 | loss_G 0.9972 | D(real) +0.219 | D(fake) -0.139\n",
            "step 9140 | loss_D 1.1295 | loss_G 1.2089 | D(real) -0.093 | D(fake) -1.558\n",
            "step 9150 | loss_D 1.1998 | loss_G 1.0674 | D(real) -0.027 | D(fake) -0.512\n",
            "step 9160 | loss_D 1.1469 | loss_G 0.8059 | D(real) -0.033 | D(fake) -0.631\n",
            "step 9170 | loss_D 1.4626 | loss_G 0.8345 | D(real) -0.211 | D(fake) -0.243\n",
            "step 9180 | loss_D 1.0187 | loss_G 1.0983 | D(real) +0.313 | D(fake) -0.722\n",
            "step 9190 | loss_D 0.9487 | loss_G 1.0025 | D(real) +0.637 | D(fake) -0.555\n",
            "step 9200 | loss_D 0.7627 | loss_G 0.9073 | D(real) +1.841 | D(fake) -0.580\n",
            "step 9210 | loss_D 1.0468 | loss_G 1.2543 | D(real) +1.307 | D(fake) -0.788\n",
            "step 9220 | loss_D 0.7980 | loss_G 0.9574 | D(real) +1.717 | D(fake) -0.450\n",
            "step 9230 | loss_D 1.3322 | loss_G 1.2683 | D(real) -0.353 | D(fake) -0.677\n",
            "step 9240 | loss_D 1.1647 | loss_G 2.0895 | D(real) +0.678 | D(fake) -0.319\n",
            "step 9250 | loss_D 0.7736 | loss_G 1.8712 | D(real) +0.994 | D(fake) -1.241\n",
            "step 9260 | loss_D 0.6752 | loss_G 1.7571 | D(real) +1.660 | D(fake) -0.466\n",
            "step 9270 | loss_D 1.3367 | loss_G 1.1392 | D(real) -0.424 | D(fake) -0.953\n",
            "step 9280 | loss_D 1.0094 | loss_G 0.7963 | D(real) +0.801 | D(fake) -0.266\n",
            "step 9290 | loss_D 0.8897 | loss_G 0.9383 | D(real) +0.256 | D(fake) -1.116\n",
            "step 9300 | loss_D 0.9191 | loss_G 1.0075 | D(real) +0.925 | D(fake) -0.424\n",
            "step 9310 | loss_D 1.0824 | loss_G 1.2682 | D(real) +1.295 | D(fake) +0.092\n",
            "step 9320 | loss_D 1.0937 | loss_G 0.9796 | D(real) +1.025 | D(fake) +0.143\n",
            "step 9330 | loss_D 1.0095 | loss_G 0.9326 | D(real) +0.453 | D(fake) -0.514\n",
            "step 9340 | loss_D 1.3488 | loss_G 1.4548 | D(real) -0.104 | D(fake) -0.342\n",
            "step 9350 | loss_D 1.4131 | loss_G 1.3221 | D(real) -0.255 | D(fake) -0.866\n",
            "step 9360 | loss_D 0.7549 | loss_G 1.1900 | D(real) +0.974 | D(fake) -0.741\n",
            "step 9370 | loss_D 1.1445 | loss_G 0.7259 | D(real) +0.771 | D(fake) -0.092\n",
            "step 9380 | loss_D 0.8913 | loss_G 0.8675 | D(real) +0.911 | D(fake) -0.515\n",
            "step 9390 | loss_D 0.8171 | loss_G 1.2194 | D(real) +1.165 | D(fake) -0.732\n",
            "step 9400 | loss_D 0.7600 | loss_G 0.9758 | D(real) +1.121 | D(fake) -0.606\n",
            "step 9410 | loss_D 1.2242 | loss_G 0.9415 | D(real) +0.052 | D(fake) -0.513\n",
            "step 9420 | loss_D 1.0133 | loss_G 1.4933 | D(real) +0.758 | D(fake) -0.319\n",
            "step 9430 | loss_D 1.4286 | loss_G 1.3903 | D(real) +1.361 | D(fake) +0.474\n",
            "step 9440 | loss_D 0.7255 | loss_G 1.3883 | D(real) +0.665 | D(fake) -1.134\n",
            "step 9450 | loss_D 0.9400 | loss_G 0.8592 | D(real) +1.681 | D(fake) +0.002\n",
            "step 9460 | loss_D 1.0044 | loss_G 1.2932 | D(real) +0.777 | D(fake) -0.349\n",
            "step 9470 | loss_D 0.7521 | loss_G 1.0857 | D(real) +0.995 | D(fake) -0.734\n",
            "step 9480 | loss_D 1.0641 | loss_G 1.2302 | D(real) +0.488 | D(fake) -0.508\n",
            "step 9490 | loss_D 1.2692 | loss_G 0.9426 | D(real) +0.008 | D(fake) -0.544\n",
            "step 9500 | loss_D 0.7243 | loss_G 1.8081 | D(real) +1.157 | D(fake) -0.948\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_009500.pt\n",
            "step 9510 | loss_D 1.8601 | loss_G 1.1448 | D(real) -0.544 | D(fake) -0.274\n",
            "step 9520 | loss_D 1.0363 | loss_G 1.2049 | D(real) +0.904 | D(fake) -0.380\n",
            "step 9530 | loss_D 0.8232 | loss_G 0.9775 | D(real) +0.380 | D(fake) -1.395\n",
            "step 9540 | loss_D 1.2436 | loss_G 0.7431 | D(real) +2.199 | D(fake) +0.605\n",
            "step 9550 | loss_D 0.8507 | loss_G 1.1180 | D(real) +0.395 | D(fake) -1.077\n",
            "step 9560 | loss_D 0.9253 | loss_G 1.1718 | D(real) +0.750 | D(fake) -0.472\n",
            "step 9570 | loss_D 0.9419 | loss_G 1.4258 | D(real) +1.420 | D(fake) -0.479\n",
            "step 9580 | loss_D 1.3579 | loss_G 1.2101 | D(real) +0.216 | D(fake) -0.244\n",
            "step 9590 | loss_D 0.6818 | loss_G 1.0719 | D(real) +1.273 | D(fake) -0.828\n",
            "step 9600 | loss_D 1.1996 | loss_G 0.8125 | D(real) +0.589 | D(fake) +0.019\n",
            "step 9610 | loss_D 1.0609 | loss_G 1.2304 | D(real) +0.516 | D(fake) -0.450\n",
            "step 9620 | loss_D 1.2587 | loss_G 1.1129 | D(real) +0.433 | D(fake) +0.018\n",
            "step 9630 | loss_D 0.7748 | loss_G 1.8891 | D(real) +1.180 | D(fake) -0.905\n",
            "step 9640 | loss_D 0.6008 | loss_G 1.6984 | D(real) +1.278 | D(fake) -1.031\n",
            "step 9650 | loss_D 1.2899 | loss_G 0.9620 | D(real) +0.202 | D(fake) -0.434\n",
            "step 9660 | loss_D 0.8743 | loss_G 1.0750 | D(real) +1.330 | D(fake) -0.253\n",
            "step 9670 | loss_D 1.1294 | loss_G 0.8026 | D(real) +0.433 | D(fake) -0.229\n",
            "step 9680 | loss_D 0.9425 | loss_G 0.6292 | D(real) +0.286 | D(fake) -0.803\n",
            "step 9690 | loss_D 0.9268 | loss_G 1.3199 | D(real) +0.497 | D(fake) -0.645\n",
            "step 9700 | loss_D 0.7526 | loss_G 1.2325 | D(real) +0.603 | D(fake) -1.096\n",
            "step 9710 | loss_D 1.0721 | loss_G 0.9808 | D(real) -0.061 | D(fake) -1.107\n",
            "step 9720 | loss_D 1.2123 | loss_G 0.8848 | D(real) +0.238 | D(fake) -0.434\n",
            "step 9730 | loss_D 0.9607 | loss_G 1.3838 | D(real) +0.272 | D(fake) -1.276\n",
            "step 9740 | loss_D 1.1424 | loss_G 0.5864 | D(real) -0.088 | D(fake) -1.035\n",
            "step 9750 | loss_D 0.9245 | loss_G 1.1463 | D(real) +0.738 | D(fake) -0.532\n",
            "step 9760 | loss_D 0.7321 | loss_G 1.3067 | D(real) +0.589 | D(fake) -1.318\n",
            "step 9770 | loss_D 0.9701 | loss_G 1.4017 | D(real) +1.079 | D(fake) -0.157\n",
            "step 9780 | loss_D 0.9100 | loss_G 0.9270 | D(real) +1.101 | D(fake) -0.484\n",
            "step 9790 | loss_D 1.3544 | loss_G 1.1901 | D(real) -0.294 | D(fake) -0.492\n",
            "step 9800 | loss_D 0.8890 | loss_G 1.4975 | D(real) +1.471 | D(fake) -0.628\n",
            "step 9810 | loss_D 1.0130 | loss_G 0.9129 | D(real) +0.591 | D(fake) -0.552\n",
            "step 9820 | loss_D 0.7789 | loss_G 1.2407 | D(real) +0.745 | D(fake) -1.119\n",
            "step 9830 | loss_D 0.9214 | loss_G 1.2624 | D(real) +0.739 | D(fake) -0.583\n",
            "step 9840 | loss_D 1.1772 | loss_G 2.1279 | D(real) +1.449 | D(fake) -0.271\n",
            "step 9850 | loss_D 1.5024 | loss_G 1.0569 | D(real) +0.293 | D(fake) -0.027\n",
            "step 9860 | loss_D 1.1264 | loss_G 0.8729 | D(real) +0.736 | D(fake) -0.035\n",
            "step 9870 | loss_D 1.5189 | loss_G 0.8541 | D(real) -0.495 | D(fake) -0.387\n",
            "step 9880 | loss_D 0.8519 | loss_G 1.0110 | D(real) +1.121 | D(fake) -0.554\n",
            "step 9890 | loss_D 1.1745 | loss_G 0.8217 | D(real) +0.009 | D(fake) -0.593\n",
            "step 9900 | loss_D 1.0140 | loss_G 1.1799 | D(real) +0.557 | D(fake) -0.571\n",
            "step 9910 | loss_D 1.1415 | loss_G 1.1476 | D(real) +0.713 | D(fake) -0.132\n",
            "step 9920 | loss_D 1.1686 | loss_G 1.3285 | D(real) +0.683 | D(fake) -0.160\n",
            "step 9930 | loss_D 1.1120 | loss_G 1.0205 | D(real) +0.126 | D(fake) -0.612\n",
            "step 9940 | loss_D 0.8036 | loss_G 0.9280 | D(real) +0.700 | D(fake) -0.987\n",
            "step 9950 | loss_D 1.2978 | loss_G 0.9027 | D(real) +0.394 | D(fake) -0.389\n",
            "step 9960 | loss_D 0.9396 | loss_G 1.0422 | D(real) +0.604 | D(fake) -0.473\n",
            "step 9970 | loss_D 0.8966 | loss_G 1.1751 | D(real) +0.817 | D(fake) -0.490\n",
            "step 9980 | loss_D 1.0229 | loss_G 1.1719 | D(real) +0.578 | D(fake) -0.307\n",
            "step 9990 | loss_D 0.8386 | loss_G 1.1764 | D(real) +2.131 | D(fake) -0.412\n",
            "step 10000 | loss_D 1.0524 | loss_G 1.1145 | D(real) +0.174 | D(fake) -1.021\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_010000.pt\n",
            "step 10010 | loss_D 1.5499 | loss_G 0.9899 | D(real) -0.646 | D(fake) -0.572\n",
            "step 10020 | loss_D 0.8905 | loss_G 1.0475 | D(real) +1.783 | D(fake) -0.348\n",
            "step 10030 | loss_D 0.8396 | loss_G 1.3374 | D(real) +1.132 | D(fake) -0.552\n",
            "step 10040 | loss_D 1.3041 | loss_G 0.5975 | D(real) +0.183 | D(fake) -0.106\n",
            "step 10050 | loss_D 0.8981 | loss_G 0.8590 | D(real) +1.139 | D(fake) -0.292\n",
            "step 10060 | loss_D 1.1172 | loss_G 1.1104 | D(real) +0.285 | D(fake) -0.507\n",
            "step 10070 | loss_D 0.7542 | loss_G 1.4783 | D(real) +1.213 | D(fake) -0.629\n",
            "step 10080 | loss_D 0.6852 | loss_G 2.3585 | D(real) +0.979 | D(fake) -1.071\n",
            "step 10090 | loss_D 1.1821 | loss_G 1.3619 | D(real) +0.156 | D(fake) -0.309\n",
            "step 10100 | loss_D 1.1454 | loss_G 1.3130 | D(real) +1.227 | D(fake) -0.218\n",
            "step 10110 | loss_D 0.9128 | loss_G 1.4639 | D(real) +0.670 | D(fake) -0.744\n",
            "step 10120 | loss_D 0.9634 | loss_G 1.3480 | D(real) +2.264 | D(fake) -0.011\n",
            "step 10130 | loss_D 0.6959 | loss_G 1.3198 | D(real) +2.201 | D(fake) -0.649\n",
            "step 10140 | loss_D 0.8296 | loss_G 1.1414 | D(real) +0.728 | D(fake) -0.694\n",
            "step 10150 | loss_D 0.8521 | loss_G 0.9067 | D(real) +1.160 | D(fake) -0.548\n",
            "step 10160 | loss_D 1.2647 | loss_G 0.8320 | D(real) -0.080 | D(fake) -0.401\n",
            "step 10170 | loss_D 0.8270 | loss_G 1.1170 | D(real) +0.485 | D(fake) -0.986\n",
            "step 10180 | loss_D 1.2674 | loss_G 1.2899 | D(real) -0.320 | D(fake) -0.934\n",
            "step 10190 | loss_D 0.7006 | loss_G 1.1585 | D(real) +0.969 | D(fake) -1.151\n",
            "step 10200 | loss_D 1.4250 | loss_G 1.2786 | D(real) -0.455 | D(fake) -0.553\n",
            "step 10210 | loss_D 0.8960 | loss_G 1.1289 | D(real) +0.626 | D(fake) -0.828\n",
            "step 10220 | loss_D 0.7850 | loss_G 0.9896 | D(real) +1.147 | D(fake) -0.558\n",
            "step 10230 | loss_D 0.7894 | loss_G 1.3766 | D(real) +1.807 | D(fake) -0.542\n",
            "step 10240 | loss_D 0.8125 | loss_G 1.1696 | D(real) +1.428 | D(fake) -0.901\n",
            "step 10250 | loss_D 0.7009 | loss_G 1.2653 | D(real) +1.120 | D(fake) -0.736\n",
            "step 10260 | loss_D 0.8410 | loss_G 0.9708 | D(real) +0.569 | D(fake) -1.001\n",
            "step 10270 | loss_D 0.9942 | loss_G 1.3369 | D(real) +1.806 | D(fake) -0.420\n",
            "step 10280 | loss_D 1.2912 | loss_G 1.2401 | D(real) +1.507 | D(fake) -0.089\n",
            "step 10290 | loss_D 1.0605 | loss_G 1.1273 | D(real) +0.233 | D(fake) -0.544\n",
            "step 10300 | loss_D 1.1205 | loss_G 1.2169 | D(real) +0.627 | D(fake) -0.693\n",
            "step 10310 | loss_D 1.2685 | loss_G 0.7716 | D(real) -0.288 | D(fake) -0.670\n",
            "step 10320 | loss_D 0.5207 | loss_G 1.4992 | D(real) +1.723 | D(fake) -1.021\n",
            "step 10330 | loss_D 0.9692 | loss_G 1.3867 | D(real) +0.461 | D(fake) -1.103\n",
            "step 10340 | loss_D 0.9044 | loss_G 1.3081 | D(real) +0.942 | D(fake) -0.750\n",
            "step 10350 | loss_D 0.8934 | loss_G 1.3013 | D(real) +1.469 | D(fake) -0.183\n",
            "step 10360 | loss_D 0.9050 | loss_G 1.1249 | D(real) +0.959 | D(fake) -0.984\n",
            "step 10370 | loss_D 1.6636 | loss_G 1.8527 | D(real) -0.809 | D(fake) -1.441\n",
            "step 10380 | loss_D 1.1113 | loss_G 1.1736 | D(real) +1.324 | D(fake) +0.048\n",
            "step 10390 | loss_D 1.5502 | loss_G 0.7823 | D(real) -0.578 | D(fake) -1.350\n",
            "step 10400 | loss_D 0.8529 | loss_G 1.3068 | D(real) +2.744 | D(fake) -0.358\n",
            "step 10410 | loss_D 1.5637 | loss_G 1.0222 | D(real) -0.162 | D(fake) -0.432\n",
            "step 10420 | loss_D 1.3029 | loss_G 0.7963 | D(real) -0.070 | D(fake) -0.289\n",
            "step 10430 | loss_D 1.3262 | loss_G 0.8857 | D(real) -0.053 | D(fake) -0.413\n",
            "step 10440 | loss_D 0.9474 | loss_G 1.0128 | D(real) +0.465 | D(fake) -0.549\n",
            "step 10450 | loss_D 1.3180 | loss_G 0.8052 | D(real) +0.340 | D(fake) +0.035\n",
            "step 10460 | loss_D 0.5163 | loss_G 1.5430 | D(real) +1.577 | D(fake) -1.121\n",
            "step 10470 | loss_D 0.9126 | loss_G 1.0467 | D(real) +1.646 | D(fake) -0.341\n",
            "step 10480 | loss_D 0.7198 | loss_G 1.1536 | D(real) +1.223 | D(fake) -0.745\n",
            "step 10490 | loss_D 0.8374 | loss_G 1.5057 | D(real) +0.657 | D(fake) -1.125\n",
            "step 10500 | loss_D 1.2487 | loss_G 1.0730 | D(real) +0.710 | D(fake) -0.039\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_010500.pt\n",
            "step 10510 | loss_D 1.5763 | loss_G 0.9230 | D(real) +0.026 | D(fake) +0.148\n",
            "step 10520 | loss_D 0.5940 | loss_G 1.1300 | D(real) +1.936 | D(fake) -0.820\n",
            "step 10530 | loss_D 0.7265 | loss_G 1.7458 | D(real) +0.828 | D(fake) -0.908\n",
            "step 10540 | loss_D 1.0209 | loss_G 1.2552 | D(real) +1.153 | D(fake) -0.002\n",
            "step 10550 | loss_D 1.0886 | loss_G 0.6952 | D(real) +0.072 | D(fake) -0.854\n",
            "step 10560 | loss_D 1.0441 | loss_G 1.1046 | D(real) +1.000 | D(fake) -0.051\n",
            "step 10570 | loss_D 1.1730 | loss_G 0.7335 | D(real) +0.637 | D(fake) -0.171\n",
            "step 10580 | loss_D 0.8396 | loss_G 1.1494 | D(real) +1.034 | D(fake) -0.688\n",
            "step 10590 | loss_D 0.9758 | loss_G 1.1535 | D(real) +0.458 | D(fake) -0.931\n",
            "step 10600 | loss_D 0.6266 | loss_G 1.4476 | D(real) +0.735 | D(fake) -1.476\n",
            "step 10610 | loss_D 1.1658 | loss_G 1.0578 | D(real) +0.213 | D(fake) -0.656\n",
            "step 10620 | loss_D 1.1340 | loss_G 1.0432 | D(real) +0.751 | D(fake) -0.236\n",
            "step 10630 | loss_D 0.7759 | loss_G 0.9147 | D(real) +1.069 | D(fake) -0.802\n",
            "step 10640 | loss_D 1.1151 | loss_G 0.9469 | D(real) +0.087 | D(fake) -0.799\n",
            "step 10650 | loss_D 1.0797 | loss_G 0.9780 | D(real) +0.172 | D(fake) -0.543\n",
            "step 10660 | loss_D 0.7913 | loss_G 1.3685 | D(real) +1.369 | D(fake) -1.104\n",
            "step 10670 | loss_D 0.9835 | loss_G 0.8314 | D(real) +0.220 | D(fake) -0.804\n",
            "step 10680 | loss_D 1.0243 | loss_G 1.4700 | D(real) -0.003 | D(fake) -1.167\n",
            "step 10690 | loss_D 1.0237 | loss_G 1.4485 | D(real) +0.646 | D(fake) -0.357\n",
            "step 10700 | loss_D 0.9201 | loss_G 1.3691 | D(real) +0.704 | D(fake) -0.558\n",
            "step 10710 | loss_D 1.2783 | loss_G 1.1482 | D(real) +0.566 | D(fake) -0.062\n",
            "step 10720 | loss_D 0.6380 | loss_G 1.2766 | D(real) +1.302 | D(fake) -0.804\n",
            "step 10730 | loss_D 1.4519 | loss_G 0.7350 | D(real) -0.483 | D(fake) -0.711\n",
            "step 10740 | loss_D 0.9284 | loss_G 0.9145 | D(real) +0.375 | D(fake) -0.735\n",
            "step 10750 | loss_D 0.8948 | loss_G 1.3326 | D(real) +1.117 | D(fake) -0.370\n",
            "step 10760 | loss_D 0.9286 | loss_G 0.8883 | D(real) +2.324 | D(fake) +0.088\n",
            "step 10770 | loss_D 0.8053 | loss_G 1.1308 | D(real) +0.353 | D(fake) -1.491\n",
            "step 10780 | loss_D 0.8883 | loss_G 1.0967 | D(real) +0.935 | D(fake) -0.351\n",
            "step 10790 | loss_D 1.0749 | loss_G 1.8761 | D(real) +1.743 | D(fake) +0.217\n",
            "step 10800 | loss_D 0.8756 | loss_G 1.4180 | D(real) +1.729 | D(fake) -0.456\n",
            "step 10810 | loss_D 0.9037 | loss_G 1.0618 | D(real) +0.910 | D(fake) -0.342\n",
            "step 10820 | loss_D 0.9134 | loss_G 1.0352 | D(real) +1.209 | D(fake) -0.490\n",
            "step 10830 | loss_D 0.8993 | loss_G 1.3474 | D(real) +0.480 | D(fake) -0.883\n",
            "step 10840 | loss_D 0.9881 | loss_G 1.2358 | D(real) +0.764 | D(fake) -0.401\n",
            "step 10850 | loss_D 1.4912 | loss_G 0.7615 | D(real) -0.517 | D(fake) -0.508\n",
            "step 10860 | loss_D 1.0218 | loss_G 1.0887 | D(real) +0.635 | D(fake) -0.383\n",
            "step 10870 | loss_D 1.1151 | loss_G 1.1505 | D(real) +0.158 | D(fake) -1.198\n",
            "step 10880 | loss_D 0.6809 | loss_G 1.5424 | D(real) +1.177 | D(fake) -1.379\n",
            "step 10890 | loss_D 0.9303 | loss_G 1.2909 | D(real) +0.598 | D(fake) -1.035\n",
            "step 10900 | loss_D 0.8537 | loss_G 1.2204 | D(real) +1.476 | D(fake) -0.150\n",
            "step 10910 | loss_D 1.0604 | loss_G 0.9697 | D(real) +0.489 | D(fake) -0.792\n",
            "step 10920 | loss_D 1.0950 | loss_G 1.0061 | D(real) +0.335 | D(fake) -0.476\n",
            "step 10930 | loss_D 0.9881 | loss_G 1.3874 | D(real) +0.397 | D(fake) -0.674\n",
            "step 10940 | loss_D 0.8688 | loss_G 1.6216 | D(real) +1.650 | D(fake) -0.580\n",
            "step 10950 | loss_D 1.0586 | loss_G 0.5709 | D(real) +0.619 | D(fake) -0.666\n",
            "step 10960 | loss_D 1.0072 | loss_G 0.9331 | D(real) +0.570 | D(fake) -1.202\n",
            "step 10970 | loss_D 1.1833 | loss_G 0.8420 | D(real) +0.740 | D(fake) +0.036\n",
            "step 10980 | loss_D 0.7873 | loss_G 1.4544 | D(real) +1.041 | D(fake) -0.943\n",
            "step 10990 | loss_D 0.9647 | loss_G 1.0732 | D(real) +0.734 | D(fake) -0.461\n",
            "step 11000 | loss_D 1.3358 | loss_G 0.8432 | D(real) -0.208 | D(fake) -0.547\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011000.pt\n",
            "step 11010 | loss_D 0.9088 | loss_G 1.1787 | D(real) +1.317 | D(fake) -0.391\n",
            "step 11020 | loss_D 1.4373 | loss_G 1.3759 | D(real) -0.112 | D(fake) -0.082\n",
            "step 11030 | loss_D 0.9313 | loss_G 0.9848 | D(real) +1.261 | D(fake) -0.127\n",
            "step 11040 | loss_D 0.7160 | loss_G 1.5758 | D(real) +1.866 | D(fake) -0.414\n",
            "step 11050 | loss_D 0.7877 | loss_G 1.0467 | D(real) +1.231 | D(fake) -0.535\n",
            "step 11060 | loss_D 0.4701 | loss_G 2.1158 | D(real) +1.406 | D(fake) -1.492\n",
            "step 11070 | loss_D 0.9509 | loss_G 1.1491 | D(real) +0.491 | D(fake) -0.722\n",
            "step 11080 | loss_D 0.9009 | loss_G 1.3354 | D(real) +0.703 | D(fake) -0.518\n",
            "step 11090 | loss_D 1.0801 | loss_G 1.1825 | D(real) +0.374 | D(fake) -0.486\n",
            "step 11100 | loss_D 1.0565 | loss_G 0.9922 | D(real) +0.923 | D(fake) -0.405\n",
            "step 11110 | loss_D 0.8331 | loss_G 1.4825 | D(real) +2.811 | D(fake) +0.036\n",
            "step 11120 | loss_D 0.9708 | loss_G 1.5050 | D(real) +0.750 | D(fake) -0.391\n",
            "step 11130 | loss_D 1.0082 | loss_G 1.2684 | D(real) +0.522 | D(fake) -0.379\n",
            "step 11140 | loss_D 1.2091 | loss_G 0.8988 | D(real) +0.575 | D(fake) -0.126\n",
            "step 11150 | loss_D 0.7916 | loss_G 1.5270 | D(real) +1.079 | D(fake) -0.556\n",
            "step 11160 | loss_D 1.1063 | loss_G 1.2294 | D(real) +1.247 | D(fake) -0.088\n",
            "step 11170 | loss_D 0.8891 | loss_G 1.2719 | D(real) +0.641 | D(fake) -0.649\n",
            "step 11180 | loss_D 1.1693 | loss_G 0.9786 | D(real) +0.093 | D(fake) -0.495\n",
            "step 11190 | loss_D 1.0247 | loss_G 1.0998 | D(real) +1.190 | D(fake) -0.326\n",
            "step 11200 | loss_D 1.1506 | loss_G 0.9866 | D(real) +0.514 | D(fake) -0.189\n",
            "step 11210 | loss_D 1.2512 | loss_G 1.1169 | D(real) +0.506 | D(fake) +0.071\n",
            "step 11220 | loss_D 1.0362 | loss_G 1.2306 | D(real) +0.407 | D(fake) -0.584\n",
            "step 11230 | loss_D 0.5340 | loss_G 1.7797 | D(real) +1.559 | D(fake) -0.984\n",
            "step 11240 | loss_D 1.5993 | loss_G 1.5946 | D(real) +0.449 | D(fake) +0.469\n",
            "step 11250 | loss_D 1.0603 | loss_G 1.2037 | D(real) +0.298 | D(fake) -0.655\n",
            "step 11260 | loss_D 0.9941 | loss_G 1.3998 | D(real) +0.697 | D(fake) -0.257\n",
            "step 11270 | loss_D 0.9355 | loss_G 1.0835 | D(real) +0.308 | D(fake) -0.922\n",
            "step 11280 | loss_D 1.0130 | loss_G 1.1416 | D(real) +0.535 | D(fake) -0.417\n",
            "step 11290 | loss_D 1.5065 | loss_G 0.6172 | D(real) -0.113 | D(fake) -0.004\n",
            "step 11300 | loss_D 0.7690 | loss_G 1.3138 | D(real) +0.981 | D(fake) -0.972\n",
            "step 11310 | loss_D 0.6848 | loss_G 1.2515 | D(real) +1.920 | D(fake) -0.408\n",
            "step 11320 | loss_D 0.7960 | loss_G 1.5322 | D(real) +1.617 | D(fake) -0.405\n",
            "step 11330 | loss_D 0.8185 | loss_G 1.0993 | D(real) +1.292 | D(fake) -0.393\n",
            "step 11340 | loss_D 1.4352 | loss_G 1.3422 | D(real) +0.151 | D(fake) -0.063\n",
            "step 11350 | loss_D 0.7167 | loss_G 1.5463 | D(real) +0.943 | D(fake) -0.874\n",
            "step 11360 | loss_D 1.0976 | loss_G 1.0609 | D(real) +0.260 | D(fake) -0.457\n",
            "step 11370 | loss_D 1.0839 | loss_G 1.4973 | D(real) +1.482 | D(fake) +0.051\n",
            "step 11380 | loss_D 1.0451 | loss_G 1.1416 | D(real) +0.295 | D(fake) -0.668\n",
            "step 11390 | loss_D 0.6595 | loss_G 1.8153 | D(real) +1.543 | D(fake) -0.693\n",
            "step 11400 | loss_D 0.8703 | loss_G 1.3810 | D(real) +0.565 | D(fake) -1.044\n",
            "step 11410 | loss_D 1.1042 | loss_G 1.2739 | D(real) +0.007 | D(fake) -0.782\n",
            "step 11420 | loss_D 1.1725 | loss_G 1.3635 | D(real) +0.837 | D(fake) +0.094\n",
            "step 11430 | loss_D 0.8840 | loss_G 0.9261 | D(real) +0.523 | D(fake) -0.695\n",
            "step 11440 | loss_D 0.9500 | loss_G 1.1383 | D(real) +0.819 | D(fake) -0.405\n",
            "step 11450 | loss_D 1.3272 | loss_G 0.8950 | D(real) +0.191 | D(fake) -0.210\n",
            "step 11460 | loss_D 1.2374 | loss_G 0.8961 | D(real) +0.872 | D(fake) -0.023\n",
            "step 11470 | loss_D 0.8820 | loss_G 1.7637 | D(real) +0.849 | D(fake) -0.552\n",
            "step 11480 | loss_D 1.0961 | loss_G 1.2472 | D(real) +0.646 | D(fake) -0.331\n",
            "step 11490 | loss_D 0.9250 | loss_G 1.5636 | D(real) +0.606 | D(fake) -1.241\n",
            "step 11500 | loss_D 0.9476 | loss_G 0.9033 | D(real) +1.475 | D(fake) +0.050\n",
            "ðŸ’¾ Saved: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\n",
            "step 11510 | loss_D 0.5822 | loss_G 1.5324 | D(real) +2.006 | D(fake) -0.647\n",
            "step 11520 | loss_D 1.5743 | loss_G 0.8225 | D(real) +0.029 | D(fake) +0.114\n",
            "step 11530 | loss_D 0.9461 | loss_G 1.0334 | D(real) +1.099 | D(fake) -0.165\n",
            "step 11540 | loss_D 0.9821 | loss_G 1.1304 | D(real) +1.151 | D(fake) -0.080\n",
            "step 11550 | loss_D 1.0866 | loss_G 0.9872 | D(real) +0.038 | D(fake) -0.916\n",
            "step 11560 | loss_D 1.0052 | loss_G 1.3534 | D(real) -0.028 | D(fake) -1.281\n",
            "step 11570 | loss_D 0.7092 | loss_G 0.8707 | D(real) +0.916 | D(fake) -1.049\n",
            "step 11580 | loss_D 1.0734 | loss_G 1.0904 | D(real) +0.162 | D(fake) -0.743\n",
            "step 11590 | loss_D 1.1935 | loss_G 0.6849 | D(real) -0.078 | D(fake) -0.883\n",
            "step 11600 | loss_D 0.8303 | loss_G 1.0669 | D(real) +0.721 | D(fake) -0.753\n",
            "step 11610 | loss_D 1.1787 | loss_G 1.0106 | D(real) +0.663 | D(fake) -0.656\n",
            "step 11620 | loss_D 1.0252 | loss_G 1.0685 | D(real) +0.255 | D(fake) -0.659\n",
            "step 11630 | loss_D 0.7002 | loss_G 0.7377 | D(real) +0.980 | D(fake) -1.361\n",
            "step 11640 | loss_D 0.9099 | loss_G 1.2683 | D(real) +0.381 | D(fake) -0.767\n",
            "step 11650 | loss_D 0.9013 | loss_G 1.7095 | D(real) +1.102 | D(fake) -0.547\n",
            "step 11660 | loss_D 0.9979 | loss_G 1.1327 | D(real) +0.388 | D(fake) -0.740\n",
            "step 11670 | loss_D 1.1802 | loss_G 1.4890 | D(real) -0.235 | D(fake) -0.905\n",
            "step 11680 | loss_D 1.3935 | loss_G 1.0494 | D(real) -0.177 | D(fake) -0.538\n",
            "step 11690 | loss_D 1.4220 | loss_G 1.1582 | D(real) -0.343 | D(fake) -0.374\n",
            "step 11700 | loss_D 0.8825 | loss_G 0.6854 | D(real) +0.707 | D(fake) -0.559\n",
            "step 11710 | loss_D 0.9951 | loss_G 0.8703 | D(real) +1.363 | D(fake) -0.003\n",
            "step 11720 | loss_D 1.2532 | loss_G 0.9086 | D(real) -0.385 | D(fake) -0.917\n",
            "step 11730 | loss_D 1.2762 | loss_G 0.8143 | D(real) +0.207 | D(fake) -0.557\n",
            "step 11740 | loss_D 0.5888 | loss_G 1.6127 | D(real) +1.060 | D(fake) -1.336\n",
            "step 11750 | loss_D 1.0290 | loss_G 0.6407 | D(real) +0.182 | D(fake) -0.829\n",
            "step 11760 | loss_D 0.8854 | loss_G 1.1877 | D(real) +0.659 | D(fake) -0.644\n",
            "step 11770 | loss_D 1.1157 | loss_G 1.2266 | D(real) +0.016 | D(fake) -1.039\n",
            "step 11780 | loss_D 1.5316 | loss_G 1.2024 | D(real) -0.446 | D(fake) -0.558\n",
            "step 11790 | loss_D 0.5619 | loss_G 1.3250 | D(real) +2.029 | D(fake) -0.728\n",
            "step 11800 | loss_D 0.8415 | loss_G 1.0235 | D(real) +0.987 | D(fake) -0.639\n",
            "step 11810 | loss_D 0.9912 | loss_G 1.2247 | D(real) +1.034 | D(fake) -0.230\n",
            "step 11820 | loss_D 0.8900 | loss_G 0.7676 | D(real) +1.350 | D(fake) -0.202\n",
            "step 11830 | loss_D 0.8704 | loss_G 1.3096 | D(real) +0.874 | D(fake) -0.646\n",
            "step 11840 | loss_D 1.2559 | loss_G 0.8915 | D(real) +0.687 | D(fake) -0.045\n",
            "step 11850 | loss_D 0.6734 | loss_G 1.2539 | D(real) +1.001 | D(fake) -0.981\n",
            "step 11860 | loss_D 0.9883 | loss_G 0.7329 | D(real) +0.305 | D(fake) -0.742\n",
            "step 11870 | loss_D 1.0847 | loss_G 0.9148 | D(real) +0.029 | D(fake) -0.823\n",
            "step 11880 | loss_D 1.1495 | loss_G 0.8572 | D(real) -0.019 | D(fake) -0.764\n",
            "step 11890 | loss_D 1.2206 | loss_G 1.0591 | D(real) -0.166 | D(fake) -0.665\n",
            "step 11900 | loss_D 1.3876 | loss_G 1.1009 | D(real) +0.093 | D(fake) +0.072\n",
            "step 11910 | loss_D 0.8159 | loss_G 1.0956 | D(real) +1.087 | D(fake) -0.552\n",
            "step 11920 | loss_D 1.5831 | loss_G 1.2545 | D(real) +0.583 | D(fake) +0.414\n",
            "step 11930 | loss_D 1.0350 | loss_G 0.9991 | D(real) +1.170 | D(fake) -0.252\n",
            "step 11940 | loss_D 1.2145 | loss_G 1.2866 | D(real) -0.364 | D(fake) -1.269\n",
            "step 11950 | loss_D 1.1114 | loss_G 1.1692 | D(real) +0.444 | D(fake) -0.182\n",
            "step 11960 | loss_D 1.2996 | loss_G 0.8227 | D(real) +0.319 | D(fake) +0.105\n",
            "step 11970 | loss_D 0.9366 | loss_G 1.2292 | D(real) +0.611 | D(fake) -0.491\n",
            "step 11980 | loss_D 1.1893 | loss_G 1.4127 | D(real) +0.573 | D(fake) +0.050\n",
            "step 11990 | loss_D 0.9937 | loss_G 1.3253 | D(real) +1.167 | D(fake) -0.130\n"
          ]
        }
      ],
      "source": [
        "resume_from_ckpt(\n",
        "    ckpt_path=\"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_128_12000_iters/gan_step_002500.pt\",\n",
        "    total_iters=12000,\n",
        "    RUN_DIR=\"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters\",\n",
        "    SAMPLE_EVERY=500,\n",
        "    CHKPT_EVERY=500,\n",
        "    dl=dl, G=G, D=D,\n",
        "    opt_G=opt_G, opt_D=opt_D,\n",
        "    criterion=criterion,\n",
        "    save_samples=save_samples,\n",
        "    DEVICE=DEVICE,\n",
        "    Z_DIM=Z_DIM,\n",
        "    use_amp=use_amp,\n",
        "    scaler_D=scaler_D,\n",
        "    scaler_G=scaler_G\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m8VObUFUCZqy",
      "metadata": {
        "id": "m8VObUFUCZqy"
      },
      "source": [
        "# Implement RL Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I8Ti4ZTQCdz3",
      "metadata": {
        "id": "I8Ti4ZTQCdz3"
      },
      "source": [
        "### Load weights from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HQtPf4JoC2K9",
      "metadata": {
        "id": "HQtPf4JoC2K9"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dOET8jiDJaO",
      "metadata": {
        "id": "3dOET8jiDJaO"
      },
      "outputs": [],
      "source": [
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)\n",
        "D = models.Discriminator_64(img_channels=3, base=64).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pjhi61VbCm1n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjhi61VbCm1n",
        "outputId": "6500eb93-4e4d-4406-e4b5-422807563ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded checkpoint step: 11500\n"
          ]
        }
      ],
      "source": [
        "ckpt_path = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\"\n",
        "ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
        "\n",
        "G.load_state_dict(ckpt[\"G\"])\n",
        "D.load_state_dict(ckpt[\"D\"])\n",
        "\n",
        "G.eval()\n",
        "D.eval()\n",
        "\n",
        "print(\"Loaded checkpoint step:\", ckpt.get(\"step\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CKip372aG5-f",
      "metadata": {
        "id": "CKip372aG5-f"
      },
      "outputs": [],
      "source": [
        "# Freezing weights\n",
        "for p in G.parameters(): p.requires_grad_(False)\n",
        "for p in D.parameters(): p.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XZfG5p43IBDt",
      "metadata": {
        "id": "XZfG5p43IBDt"
      },
      "source": [
        "### Latent Bank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-EwLZa9nHT9g",
      "metadata": {
        "id": "-EwLZa9nHT9g"
      },
      "outputs": [],
      "source": [
        "K = 512\n",
        "Z_DIM = 128\n",
        "\n",
        "Z_bank = torch.randn(K, Z_DIM, device=DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "khYFmTt-IFvr",
      "metadata": {
        "id": "khYFmTt-IFvr"
      },
      "source": [
        "### Reward Function Using Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t6Rgcm7xILjv",
      "metadata": {
        "id": "t6Rgcm7xILjv"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def reward_from_latent(z_batch):\n",
        "\n",
        "    fake = G(z_batch)\n",
        "    logits = D(fake)\n",
        "    r = torch.sigmoid(logits)\n",
        "    return r"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pBxWXdVqLvUG",
      "metadata": {
        "id": "pBxWXdVqLvUG"
      },
      "source": [
        "### Tabular Q-Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LJ_V2iBNLz-J",
      "metadata": {
        "id": "LJ_V2iBNLz-J"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kev0_oVQLxmq",
      "metadata": {
        "id": "Kev0_oVQLxmq"
      },
      "outputs": [],
      "source": [
        "Q = torch.zeros(K, device=DEVICE) \n",
        "\n",
        "def epsilon_by_step(t, eps_start=0.2, eps_end=0.05, decay_steps=5000):\n",
        "    if t >= decay_steps:\n",
        "        return eps_end\n",
        "    return eps_end + (eps_start - eps_end) * (1 - t / decay_steps)\n",
        "\n",
        "def sample_action(Q, eps):\n",
        "    if torch.rand(()) < eps:\n",
        "        return torch.randint(0, K, (1,), device=Q.device).item()\n",
        "    return torch.argmax(Q).item()\n",
        "\n",
        "def update_Q(Q, a, r, alpha=0.1):\n",
        "    \n",
        "    Q[a] = (1 - alpha) * Q[a] + alpha * r"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FSBnQOGHMNCE",
      "metadata": {
        "id": "FSBnQOGHMNCE"
      },
      "source": [
        "## Train RL Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ZFseoWaMOu4",
      "metadata": {
        "id": "0ZFseoWaMOu4"
      },
      "outputs": [],
      "source": [
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LOuzUnzwMQzN",
      "metadata": {
        "id": "LOuzUnzwMQzN"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def run_rl_latent_selection(\n",
        "    steps=10000,\n",
        "    batch_size=16,\n",
        "    alpha=0.1,\n",
        "    print_every=50,\n",
        "):\n",
        "    rewards_ma = deque(maxlen=200)\n",
        "    action_hist = torch.zeros(K, device=DEVICE)\n",
        "\n",
        "    for t in range(steps):\n",
        "        eps = epsilon_by_step(t)\n",
        "\n",
        "        a = sample_action(Q, eps)\n",
        "        action_hist[a] += 1\n",
        "\n",
        "        # evaluate chosen latent \n",
        "        z = Z_bank[a].unsqueeze(0).repeat(batch_size, 1)  # [B, Z_DIM]\n",
        "        r = reward_from_latent(z).mean().item()\n",
        "\n",
        "        update_Q(Q, a, r, alpha=alpha)\n",
        "        rewards_ma.append(r)\n",
        "\n",
        "        if (t % print_every) == 0:\n",
        "            # policy entropy estimate from action histogram\n",
        "            p = (action_hist / action_hist.sum()).clamp_min(1e-12)\n",
        "            entropy = float(-(p * p.log()).sum().item())\n",
        "\n",
        "            print(f\"t={t:05d} | eps={eps:.3f} | r={r:.3f} | r_ma={sum(rewards_ma)/len(rewards_ma):.3f} | H={entropy:.2f}\")\n",
        "\n",
        "    return Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rbrq6CVRMVu7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbrq6CVRMVu7",
        "outputId": "c32d52cd-c854-4b18-e616-f839fe8311b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t=00000 | eps=0.200 | r=0.475 | r_ma=0.475 | H=0.00\n",
            "t=00050 | eps=0.199 | r=0.475 | r_ma=0.462 | H=0.48\n",
            "t=00100 | eps=0.197 | r=0.475 | r_ma=0.455 | H=0.88\n",
            "t=00150 | eps=0.196 | r=0.475 | r_ma=0.451 | H=0.94\n",
            "t=00200 | eps=0.194 | r=0.475 | r_ma=0.454 | H=0.83\n",
            "t=00250 | eps=0.193 | r=0.475 | r_ma=0.450 | H=0.89\n",
            "t=00300 | eps=0.191 | r=0.475 | r_ma=0.454 | H=0.92\n",
            "t=00350 | eps=0.190 | r=0.475 | r_ma=0.456 | H=0.95\n",
            "t=00400 | eps=0.188 | r=0.475 | r_ma=0.457 | H=0.98\n",
            "t=00450 | eps=0.187 | r=0.475 | r_ma=0.460 | H=1.05\n",
            "t=00500 | eps=0.185 | r=0.475 | r_ma=0.460 | H=1.06\n",
            "t=00550 | eps=0.184 | r=0.475 | r_ma=0.458 | H=1.18\n",
            "t=00600 | eps=0.182 | r=0.475 | r_ma=0.452 | H=1.20\n",
            "t=00650 | eps=0.180 | r=0.475 | r_ma=0.454 | H=1.19\n",
            "t=00700 | eps=0.179 | r=0.475 | r_ma=0.455 | H=1.15\n",
            "t=00750 | eps=0.177 | r=0.338 | r_ma=0.453 | H=1.23\n",
            "t=00800 | eps=0.176 | r=0.475 | r_ma=0.455 | H=1.24\n",
            "t=00850 | eps=0.175 | r=0.475 | r_ma=0.453 | H=1.26\n",
            "t=00900 | eps=0.173 | r=0.475 | r_ma=0.446 | H=1.30\n",
            "t=00950 | eps=0.172 | r=0.475 | r_ma=0.451 | H=1.29\n",
            "t=01000 | eps=0.170 | r=0.299 | r_ma=0.449 | H=1.30\n",
            "t=01050 | eps=0.169 | r=0.475 | r_ma=0.454 | H=1.27\n",
            "t=01100 | eps=0.167 | r=0.257 | r_ma=0.455 | H=1.28\n",
            "t=01150 | eps=0.166 | r=0.398 | r_ma=0.455 | H=1.29\n",
            "t=01200 | eps=0.164 | r=0.431 | r_ma=0.455 | H=1.32\n",
            "t=01250 | eps=0.163 | r=0.281 | r_ma=0.449 | H=1.34\n",
            "t=01300 | eps=0.161 | r=0.351 | r_ma=0.450 | H=1.36\n",
            "t=01350 | eps=0.160 | r=0.475 | r_ma=0.449 | H=1.36\n",
            "t=01400 | eps=0.158 | r=0.475 | r_ma=0.453 | H=1.35\n",
            "t=01450 | eps=0.157 | r=0.475 | r_ma=0.456 | H=1.34\n",
            "t=01500 | eps=0.155 | r=0.245 | r_ma=0.453 | H=1.36\n",
            "t=01550 | eps=0.154 | r=0.475 | r_ma=0.455 | H=1.34\n",
            "t=01600 | eps=0.152 | r=0.475 | r_ma=0.455 | H=1.34\n",
            "t=01650 | eps=0.151 | r=0.475 | r_ma=0.455 | H=1.33\n",
            "t=01700 | eps=0.149 | r=0.475 | r_ma=0.462 | H=1.31\n",
            "t=01750 | eps=0.148 | r=0.475 | r_ma=0.456 | H=1.32\n",
            "t=01800 | eps=0.146 | r=0.475 | r_ma=0.459 | H=1.31\n",
            "t=01850 | eps=0.145 | r=0.475 | r_ma=0.456 | H=1.31\n",
            "t=01900 | eps=0.143 | r=0.475 | r_ma=0.454 | H=1.30\n",
            "t=01950 | eps=0.142 | r=0.475 | r_ma=0.453 | H=1.32\n",
            "t=02000 | eps=0.140 | r=0.475 | r_ma=0.453 | H=1.31\n",
            "t=02050 | eps=0.139 | r=0.475 | r_ma=0.457 | H=1.31\n",
            "t=02100 | eps=0.137 | r=0.475 | r_ma=0.458 | H=1.30\n",
            "t=02150 | eps=0.136 | r=0.475 | r_ma=0.464 | H=1.31\n",
            "t=02200 | eps=0.134 | r=0.475 | r_ma=0.464 | H=1.30\n",
            "t=02250 | eps=0.133 | r=0.475 | r_ma=0.460 | H=1.31\n",
            "t=02300 | eps=0.131 | r=0.475 | r_ma=0.458 | H=1.31\n",
            "t=02350 | eps=0.130 | r=0.475 | r_ma=0.459 | H=1.31\n",
            "t=02400 | eps=0.128 | r=0.475 | r_ma=0.458 | H=1.31\n",
            "t=02450 | eps=0.127 | r=0.552 | r_ma=0.465 | H=1.29\n",
            "t=02500 | eps=0.125 | r=0.475 | r_ma=0.465 | H=1.30\n",
            "t=02550 | eps=0.124 | r=0.475 | r_ma=0.462 | H=1.29\n",
            "t=02600 | eps=0.122 | r=0.475 | r_ma=0.463 | H=1.28\n",
            "t=02650 | eps=0.121 | r=0.348 | r_ma=0.458 | H=1.29\n",
            "t=02700 | eps=0.119 | r=0.475 | r_ma=0.453 | H=1.30\n",
            "t=02750 | eps=0.118 | r=0.475 | r_ma=0.451 | H=1.31\n",
            "t=02800 | eps=0.116 | r=0.475 | r_ma=0.449 | H=1.30\n",
            "t=02850 | eps=0.115 | r=0.475 | r_ma=0.448 | H=1.30\n",
            "t=02900 | eps=0.113 | r=0.475 | r_ma=0.455 | H=1.29\n",
            "t=02950 | eps=0.112 | r=0.520 | r_ma=0.458 | H=1.30\n",
            "t=03000 | eps=0.110 | r=0.475 | r_ma=0.460 | H=1.29\n",
            "t=03050 | eps=0.109 | r=0.475 | r_ma=0.463 | H=1.28\n",
            "t=03100 | eps=0.107 | r=0.475 | r_ma=0.463 | H=1.27\n",
            "t=03150 | eps=0.106 | r=0.475 | r_ma=0.466 | H=1.27\n",
            "t=03200 | eps=0.104 | r=0.475 | r_ma=0.464 | H=1.27\n",
            "t=03250 | eps=0.103 | r=0.475 | r_ma=0.462 | H=1.27\n",
            "t=03300 | eps=0.101 | r=0.475 | r_ma=0.464 | H=1.25\n",
            "t=03350 | eps=0.100 | r=0.475 | r_ma=0.463 | H=1.25\n",
            "t=03400 | eps=0.098 | r=0.475 | r_ma=0.466 | H=1.23\n",
            "t=03450 | eps=0.097 | r=0.475 | r_ma=0.468 | H=1.22\n",
            "t=03500 | eps=0.095 | r=0.475 | r_ma=0.466 | H=1.22\n",
            "t=03550 | eps=0.094 | r=0.475 | r_ma=0.464 | H=1.22\n",
            "t=03600 | eps=0.092 | r=0.475 | r_ma=0.465 | H=1.21\n",
            "t=03650 | eps=0.091 | r=0.475 | r_ma=0.464 | H=1.20\n",
            "t=03700 | eps=0.089 | r=0.475 | r_ma=0.461 | H=1.20\n",
            "t=03750 | eps=0.088 | r=0.475 | r_ma=0.463 | H=1.20\n",
            "t=03800 | eps=0.086 | r=0.475 | r_ma=0.462 | H=1.19\n",
            "t=03850 | eps=0.085 | r=0.475 | r_ma=0.462 | H=1.18\n",
            "t=03900 | eps=0.083 | r=0.536 | r_ma=0.465 | H=1.18\n",
            "t=03950 | eps=0.082 | r=0.475 | r_ma=0.468 | H=1.18\n",
            "t=04000 | eps=0.080 | r=0.475 | r_ma=0.468 | H=1.17\n",
            "t=04050 | eps=0.079 | r=0.229 | r_ma=0.468 | H=1.16\n",
            "t=04100 | eps=0.077 | r=0.475 | r_ma=0.466 | H=1.16\n",
            "t=04150 | eps=0.076 | r=0.475 | r_ma=0.465 | H=1.16\n",
            "t=04200 | eps=0.074 | r=0.475 | r_ma=0.464 | H=1.16\n",
            "t=04250 | eps=0.073 | r=0.475 | r_ma=0.464 | H=1.15\n",
            "t=04300 | eps=0.071 | r=0.475 | r_ma=0.467 | H=1.15\n",
            "t=04350 | eps=0.070 | r=0.475 | r_ma=0.467 | H=1.14\n",
            "t=04400 | eps=0.068 | r=0.429 | r_ma=0.469 | H=1.14\n",
            "t=04450 | eps=0.067 | r=0.475 | r_ma=0.469 | H=1.13\n",
            "t=04500 | eps=0.065 | r=0.475 | r_ma=0.469 | H=1.13\n",
            "t=04550 | eps=0.064 | r=0.475 | r_ma=0.467 | H=1.13\n",
            "t=04600 | eps=0.062 | r=0.475 | r_ma=0.464 | H=1.13\n",
            "t=04650 | eps=0.060 | r=0.475 | r_ma=0.465 | H=1.13\n",
            "t=04700 | eps=0.059 | r=0.475 | r_ma=0.466 | H=1.12\n",
            "t=04750 | eps=0.058 | r=0.475 | r_ma=0.468 | H=1.12\n",
            "t=04800 | eps=0.056 | r=0.475 | r_ma=0.469 | H=1.11\n",
            "t=04850 | eps=0.055 | r=0.475 | r_ma=0.469 | H=1.10\n",
            "t=04900 | eps=0.053 | r=0.475 | r_ma=0.469 | H=1.09\n",
            "t=04950 | eps=0.052 | r=0.475 | r_ma=0.471 | H=1.08\n",
            "t=05000 | eps=0.050 | r=0.475 | r_ma=0.472 | H=1.08\n",
            "t=05050 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.08\n",
            "t=05100 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.07\n",
            "t=05150 | eps=0.050 | r=0.475 | r_ma=0.466 | H=1.07\n",
            "t=05200 | eps=0.050 | r=0.475 | r_ma=0.468 | H=1.06\n",
            "t=05250 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.05\n",
            "t=05300 | eps=0.050 | r=0.475 | r_ma=0.468 | H=1.05\n",
            "t=05350 | eps=0.050 | r=0.475 | r_ma=0.471 | H=1.04\n",
            "t=05400 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.04\n",
            "t=05450 | eps=0.050 | r=0.475 | r_ma=0.470 | H=1.03\n",
            "t=05500 | eps=0.050 | r=0.475 | r_ma=0.473 | H=1.03\n",
            "t=05550 | eps=0.050 | r=0.475 | r_ma=0.471 | H=1.02\n",
            "t=05600 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.02\n",
            "t=05650 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.01\n",
            "t=05700 | eps=0.050 | r=0.475 | r_ma=0.467 | H=1.01\n",
            "t=05750 | eps=0.050 | r=0.475 | r_ma=0.469 | H=1.01\n",
            "t=05800 | eps=0.050 | r=0.475 | r_ma=0.472 | H=1.00\n",
            "t=05850 | eps=0.050 | r=0.475 | r_ma=0.471 | H=1.00\n",
            "t=05900 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.99\n",
            "t=05950 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.99\n",
            "t=06000 | eps=0.050 | r=0.475 | r_ma=0.466 | H=0.99\n",
            "t=06050 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.98\n",
            "t=06100 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.98\n",
            "t=06150 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.98\n",
            "t=06200 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.98\n",
            "t=06250 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.97\n",
            "t=06300 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.97\n",
            "t=06350 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.96\n",
            "t=06400 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.96\n",
            "t=06450 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.96\n",
            "t=06500 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.95\n",
            "t=06550 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.95\n",
            "t=06600 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.95\n",
            "t=06650 | eps=0.050 | r=0.256 | r_ma=0.472 | H=0.94\n",
            "t=06700 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.94\n",
            "t=06750 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.94\n",
            "t=06800 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.94\n",
            "t=06850 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.93\n",
            "t=06900 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.93\n",
            "t=06950 | eps=0.050 | r=0.475 | r_ma=0.466 | H=0.93\n",
            "t=07000 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.93\n",
            "t=07050 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.93\n",
            "t=07100 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.92\n",
            "t=07150 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.92\n",
            "t=07200 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.92\n",
            "t=07250 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.91\n",
            "t=07300 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.91\n",
            "t=07350 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.91\n",
            "t=07400 | eps=0.050 | r=0.475 | r_ma=0.469 | H=0.91\n",
            "t=07450 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.90\n",
            "t=07500 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.90\n",
            "t=07550 | eps=0.050 | r=0.475 | r_ma=0.471 | H=0.90\n",
            "t=07600 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.90\n",
            "t=07650 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.89\n",
            "t=07700 | eps=0.050 | r=0.475 | r_ma=0.472 | H=0.89\n",
            "t=07750 | eps=0.050 | r=0.475 | r_ma=0.472 | H=0.89\n",
            "t=07800 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.89\n",
            "t=07850 | eps=0.050 | r=0.475 | r_ma=0.470 | H=0.88\n",
            "t=07900 | eps=0.050 | r=0.475 | r_ma=0.467 | H=0.88\n",
            "t=07950 | eps=0.050 | r=0.475 | r_ma=0.468 | H=0.88\n"
          ]
        }
      ],
      "source": [
        "Q = run_rl_latent_selection(steps=8000, batch_size=16, alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WN3alNEOhEZe",
      "metadata": {
        "id": "WN3alNEOhEZe"
      },
      "source": [
        "### Visualize RL-Selected VS Random Latents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EZbpasZNhW2t",
      "metadata": {
        "id": "EZbpasZNhW2t"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid, save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vG27FuoZhLOV",
      "metadata": {
        "id": "vG27FuoZhLOV"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def save_compare_grids(out_dir, n=64, nrow=8):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # RL best latents\n",
        "    top_idx = torch.topk(Q, k=n).indices\n",
        "    z_rl = Z_bank[top_idx]  # [n, Z_DIM]\n",
        "    x_rl = G(z_rl)\n",
        "    grid_rl = make_grid(denorm(x_rl), nrow=nrow)\n",
        "    save_image(grid_rl, os.path.join(out_dir, \"rl_topk.png\"))\n",
        "\n",
        "    # Random latents\n",
        "    z_rand = torch.randn(n, Z_DIM, device=DEVICE)\n",
        "    x_rand = G(z_rand)\n",
        "    grid_rand = make_grid(denorm(x_rand), nrow=nrow)\n",
        "    save_image(grid_rand, os.path.join(out_dir, \"random.png\"))\n",
        "\n",
        "    print(\"Saved grids to:\", out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qltTKelLhQI_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qltTKelLhQI_",
        "outputId": "c0730080-e5c5-4bcb-d24b-f8af90be73e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved grids to: /content/drive/MyDrive/gan-rl-runs/rl_eval_64\n"
          ]
        }
      ],
      "source": [
        "save_compare_grids(\"/content/drive/MyDrive/gan-rl-runs/rl_eval_64\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e44C-AGJzbgi",
      "metadata": {
        "id": "e44C-AGJzbgi"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SzMTD6sPzdxH",
      "metadata": {
        "id": "SzMTD6sPzdxH"
      },
      "source": [
        "## FID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6HLIDHqUzaTi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HLIDHqUzaTi",
        "outputId": "548d4442-0355-4b57-a7a6-7e0202548fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_4EjH7VMzo-a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4EjH7VMzo-a",
        "outputId": "e5231fbe-b5b2-402c-862e-453d56b7f00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CKPT_DIR: /content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters\n",
            "REAL_DIR: /content/drive/MyDrive/gan-rl-eval/fid_eval_64/real_2000\n",
            "FAKE_ROOT: /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step\n"
          ]
        }
      ],
      "source": [
        "import os, glob, re, math\n",
        "from pathlib import Path\n",
        "\n",
        "CKPT_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters\"\n",
        "FID_ROOT = \"/content/drive/MyDrive/gan-rl-eval/fid_eval_64\"\n",
        "REAL_DIR = os.path.join(FID_ROOT, \"real_2000\")\n",
        "FAKE_ROOT = os.path.join(FID_ROOT, \"fake_by_step\")\n",
        "\n",
        "os.makedirs(REAL_DIR, exist_ok=True)\n",
        "os.makedirs(FAKE_ROOT, exist_ok=True)\n",
        "\n",
        "print(\"CKPT_DIR:\", CKPT_DIR)\n",
        "print(\"REAL_DIR:\", REAL_DIR)\n",
        "print(\"FAKE_ROOT:\", FAKE_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8A6K4aYm0Iq8",
      "metadata": {
        "id": "8A6K4aYm0Iq8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SfkRvttq00xn",
      "metadata": {
        "id": "SfkRvttq00xn"
      },
      "outputs": [],
      "source": [
        "def load_G_from_ckpt(G, ckpt_path, device=\"cuda\"):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    G.load_state_dict(ckpt[\"G\"])\n",
        "    G.eval()\n",
        "    for p in G.parameters():\n",
        "        p.requires_grad_(False)\n",
        "    step = int(ckpt.get(\"step\", -1))\n",
        "    return step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ne_LSeUC0GR3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_LSeUC0GR3",
        "outputId": "47620b35-563e-4cc2-e71a-ec59cf255420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Real images already exist: 2000\n"
          ]
        }
      ],
      "source": [
        "N_REAL = 2000\n",
        "DEVICE = \"cuda\"\n",
        "\n",
        "# IMPORTANT:\n",
        "# You need a dataloader that yields real images as tensors in [-1, 1]\n",
        "# Example: imgs, folder_ids = next(iter(dl))\n",
        "# We'll assume your dataloader is called `dl`.\n",
        "\n",
        "def denorm(x):\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def export_real_images(dl, out_dir, n_total=2000):\n",
        "    # If already done, skip\n",
        "    existing = len(list(Path(out_dir).glob(\"*.png\")))\n",
        "    if existing >= n_total:\n",
        "        print(f\"âœ… Real images already exist: {existing}\")\n",
        "        return\n",
        "\n",
        "    print(\"Exporting real images...\")\n",
        "    count = 0\n",
        "    for batch in dl:\n",
        "        imgs = batch[0]  # works for (img, folder_id) or (img, meta, folder_id)\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        imgs = denorm(imgs)\n",
        "\n",
        "        for i in range(imgs.size(0)):\n",
        "            path = os.path.join(out_dir, f\"real_{count:05d}.png\")\n",
        "            save_image(imgs[i], path)\n",
        "            count += 1\n",
        "            if count >= n_total:\n",
        "                print(f\"âœ… Exported {count} real images to {out_dir}\")\n",
        "                return\n",
        "\n",
        "export_real_images(dl, REAL_DIR, N_REAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z1WCHjAE1GFJ",
      "metadata": {
        "id": "Z1WCHjAE1GFJ"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def compute_fid(real_dir, fake_dir):\n",
        "    cmd = [\"python\", \"-m\", \"pytorch_fid\", real_dir, fake_dir, \"--device\", \"cuda\"]\n",
        "    out = subprocess.check_output(cmd, text=True)\n",
        "    # pytorch-fid prints: \"FID: XX.XXXX\"\n",
        "    m = re.search(r\"FID:\\s*([0-9.]+)\", out)\n",
        "    fid = float(m.group(1)) if m else None\n",
        "    return fid, out\n",
        "\n",
        "# Example usage:\n",
        "# fid_val, raw = compute_fid(REAL_DIR, \"/content/fid_eval_64/fake_by_step/fake_step_009000\")\n",
        "# print(fid_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rU1EDNgv1BJR",
      "metadata": {
        "id": "rU1EDNgv1BJR"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "N_FAKE = 2000\n",
        "Z_DIM = 128  # set to your actual Z_DIM\n",
        "BATCH = 64\n",
        "\n",
        "@torch.no_grad()\n",
        "def export_fake_images_for_ckpt(G, ckpt_path, out_root, n_total=2000, batch_size=64):\n",
        "    step = load_G_from_ckpt(G, ckpt_path, device=DEVICE)\n",
        "\n",
        "    out_dir = os.path.join(out_root, f\"fake_step_{step:06d}\")\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    existing = len(list(Path(out_dir).glob(\"*.png\")))\n",
        "    if existing >= n_total:\n",
        "        print(f\"âœ… Fake images already exist for step {step}: {existing}\")\n",
        "        return step, out_dir\n",
        "\n",
        "    print(f\"Exporting fake images for step {step} ...\")\n",
        "    count = 0\n",
        "    while count < n_total:\n",
        "        b = min(batch_size, n_total - count)\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        fake = G(z)\n",
        "        fake = denorm(fake)\n",
        "\n",
        "        for i in range(fake.size(0)):\n",
        "            path = os.path.join(out_dir, f\"fake_{count:05d}.png\")\n",
        "            save_image(fake[i], path)\n",
        "            count += 1\n",
        "\n",
        "    print(f\"âœ… Exported {n_total} fake images to {out_dir}\")\n",
        "    return step, out_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sKt8t7YU33ig",
      "metadata": {
        "id": "sKt8t7YU33ig"
      },
      "outputs": [],
      "source": [
        "from src import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZfDBfut43882",
      "metadata": {
        "id": "ZfDBfut43882"
      },
      "outputs": [],
      "source": [
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(\"cuda\")\n",
        "D = models.Discriminator_64(img_channels=3, base=64).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x86rA1741J2T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x86rA1741J2T",
        "outputId": "52944531-90bc-4dc2-e908-52560c985703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoints selected: [3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500]\n",
            "Exporting fake images for step 3000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_003000\n",
            "step=3000 | FID=300.37646800373574\n",
            "Exporting fake images for step 3500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_003500\n",
            "step=3500 | FID=264.46975874077464\n",
            "Exporting fake images for step 4000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_004000\n",
            "step=4000 | FID=199.50375775585388\n",
            "Exporting fake images for step 4500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_004500\n",
            "step=4500 | FID=246.25538491467358\n",
            "Exporting fake images for step 5000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_005000\n",
            "step=5000 | FID=320.64035893390314\n",
            "Exporting fake images for step 5500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_005500\n",
            "step=5500 | FID=212.30712302931818\n",
            "Exporting fake images for step 6000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_006000\n",
            "step=6000 | FID=315.9072017608338\n",
            "Exporting fake images for step 6500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_006500\n",
            "step=6500 | FID=195.45032060911055\n",
            "Exporting fake images for step 7000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_007000\n",
            "step=7000 | FID=252.2338826105988\n",
            "Exporting fake images for step 7500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_007500\n",
            "step=7500 | FID=381.61469646101324\n",
            "Exporting fake images for step 8000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_008000\n",
            "step=8000 | FID=166.7767328366765\n",
            "Exporting fake images for step 8500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_008500\n",
            "step=8500 | FID=226.88216744126385\n",
            "Exporting fake images for step 9000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_009000\n",
            "step=9000 | FID=193.93763080714297\n",
            "Exporting fake images for step 9500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_009500\n",
            "step=9500 | FID=201.36661070359546\n",
            "Exporting fake images for step 10000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_010000\n",
            "step=10000 | FID=157.44017393310372\n",
            "Exporting fake images for step 10500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_010500\n",
            "step=10500 | FID=164.68553381632395\n",
            "Exporting fake images for step 11000 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_011000\n",
            "step=11000 | FID=161.9504731099006\n",
            "Exporting fake images for step 11500 ...\n",
            "âœ… Exported 2000 fake images to /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fake_by_step/fake_step_011500\n",
            "step=11500 | FID=180.92448833949132\n",
            "âœ… Saved: /content/drive/MyDrive/gan-rl-eval/fid_eval_64/fid_results.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2669,\n        \"min\": 3000,\n        \"max\": 11500,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          3000,\n          3500,\n          7000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64.45061017467438,\n        \"min\": 157.44017393310372,\n        \"max\": 381.61469646101324,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          300.37646800373574,\n          264.46975874077464,\n          252.2338826105988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>fid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3000</td>\n",
              "      <td>300.376468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3500</td>\n",
              "      <td>264.469759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4000</td>\n",
              "      <td>199.503758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4500</td>\n",
              "      <td>246.255385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>320.640359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5500</td>\n",
              "      <td>212.307123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6000</td>\n",
              "      <td>315.907202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6500</td>\n",
              "      <td>195.450321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7000</td>\n",
              "      <td>252.233883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7500</td>\n",
              "      <td>381.614696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8000</td>\n",
              "      <td>166.776733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>8500</td>\n",
              "      <td>226.882167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9000</td>\n",
              "      <td>193.937631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>9500</td>\n",
              "      <td>201.366611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10000</td>\n",
              "      <td>157.440174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10500</td>\n",
              "      <td>164.685534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11000</td>\n",
              "      <td>161.950473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>11500</td>\n",
              "      <td>180.924488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c47d4c1-98c6-4e46-ad7a-ef2afd6b86cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7aec50bb-3c8a-47e6-9944-350b382d2dca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aec50bb-3c8a-47e6-9944-350b382d2dca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7aec50bb-3c8a-47e6-9944-350b382d2dca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ba3164d6-8540-41ff-b386-b742d488f233\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba3164d6-8540-41ff-b386-b742d488f233 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     step         fid\n",
              "0    3000  300.376468\n",
              "1    3500  264.469759\n",
              "2    4000  199.503758\n",
              "3    4500  246.255385\n",
              "4    5000  320.640359\n",
              "5    5500  212.307123\n",
              "6    6000  315.907202\n",
              "7    6500  195.450321\n",
              "8    7000  252.233883\n",
              "9    7500  381.614696\n",
              "10   8000  166.776733\n",
              "11   8500  226.882167\n",
              "12   9000  193.937631\n",
              "13   9500  201.366611\n",
              "14  10000  157.440174\n",
              "15  10500  164.685534\n",
              "16  11000  161.950473\n",
              "17  11500  180.924488"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "EVAL_EVERY = 500  # evaluate at steps multiple of 500\n",
        "\n",
        "\n",
        "ckpts = sorted(glob.glob(os.path.join(CKPT_DIR, \"gan_step_*.pt\")))\n",
        "\n",
        "def step_from_name(p):\n",
        "    m = re.search(r\"gan_step_(\\d+)\\.pt\", os.path.basename(p))\n",
        "    return int(m.group(1)) if m else -1\n",
        "\n",
        "ckpts = [(step_from_name(p), p) for p in ckpts]\n",
        "ckpts = [(s, p) for (s, p) in ckpts if s >= 0 and (s % EVAL_EVERY == 0)]\n",
        "ckpts = sorted(ckpts, key=lambda x: x[0])\n",
        "\n",
        "\n",
        "print(\"Checkpoints selected:\", [s for s,_ in ckpts])\n",
        "\n",
        "results = []\n",
        "for s, p in ckpts:\n",
        "    step, fake_dir = export_fake_images_for_ckpt(G, p, FAKE_ROOT, n_total=N_FAKE, batch_size=BATCH)\n",
        "    fid, _ = compute_fid(REAL_DIR, fake_dir)\n",
        "    print(f\"step={step} | FID={fid}\")\n",
        "    results.append({\"step\": step, \"fid\": fid})\n",
        "\n",
        "df = pd.DataFrame(results).sort_values(\"step\")\n",
        "csv_path = os.path.join(FID_ROOT, \"fid_results.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"âœ… Saved:\", csv_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TLk0ZfAJ1MMm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "TLk0ZfAJ1MMm",
        "outputId": "7933fb5d-d482-455c-9e4e-374341ab3e6d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df[\"step\"], df[\"fid\"])\n",
        "plt.xlabel(\"Training step\")\n",
        "plt.ylabel(\"FID\")\n",
        "plt.title(\"FID vs Training Step (64x64, N=2000)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LslH2sIzVWbN",
      "metadata": {
        "id": "LslH2sIzVWbN"
      },
      "source": [
        "## LPIPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4ZtE85piVbTr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZtE85piVbTr",
        "outputId": "5dc89a87-53a1-464a-84ed-1ff31ac71409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.2.1->lpips) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.3)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install lpips\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JUivb-GUVfNQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUivb-GUVfNQ",
        "outputId": "20901e92-b5f8-483f-841a-09890bfaceb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded step: 10000\n"
          ]
        }
      ],
      "source": [
        "CKPT_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\"\n",
        "\n",
        "\n",
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "G.load_state_dict(ckpt[\"G\"])\n",
        "G.eval()\n",
        "for p in G.parameters(): p.requires_grad_(False)\n",
        "\n",
        "print(\"Loaded step:\", ckpt.get(\"step\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "twmnKzHxWVHp",
      "metadata": {
        "id": "twmnKzHxWVHp"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3B8_4kKiWZXR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B8_4kKiWZXR",
        "outputId": "2bb44db5-06c7-4ab4-c356-bbd178c056de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating fake pool: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fake_pool: torch.Size([200, 3, 64, 64]) -0.9978187084197998 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "Z_DIM = 128\n",
        "M = 200          # pool size\n",
        "GEN_BS = 64      # generation batch size\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_pool(G, m=200, bs=64):\n",
        "    imgs = []\n",
        "    n_batches = math.ceil(m / bs)\n",
        "    for _ in tqdm(range(n_batches), desc=\"Generating fake pool\"):\n",
        "        b = min(bs, m - len(imgs))\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        x = G(z)  # [-1,1], shape [b,3,64,64]\n",
        "        imgs.append(x.detach().cpu())\n",
        "    return torch.cat(imgs, dim=0)[:m]  # [M,3,64,64] on CPU\n",
        "\n",
        "fake_pool = generate_pool(G, M, GEN_BS)\n",
        "print(\"fake_pool:\", fake_pool.shape, fake_pool.min().item(), fake_pool.max().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "JuaBfE7ZXYH5",
      "metadata": {
        "id": "JuaBfE7ZXYH5"
      },
      "outputs": [],
      "source": [
        "import lpips\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "mPeT3NQpXbpK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPeT3NQpXbpK",
        "outputId": "080893ca-fd8c-4b01-9eee-f9a62ddb3e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:01<00:00, 188MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing LPIPS: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 122.82it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(     i    j     lpips\n",
              " 0  144   80  0.037875\n",
              " 1  161  184  0.045185\n",
              " 2   20  160  0.047257\n",
              " 3   46  185  0.063983\n",
              " 4   80  187  0.066130,\n",
              "       i    j     lpips\n",
              " 95   41  107  0.325548\n",
              " 96  123   45  0.329598\n",
              " 97   86  141  0.341604\n",
              " 98  113   96  0.347586\n",
              " 99   14  194  0.365928)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lpips_fn = lpips.LPIPS(net='alex').to(DEVICE)\n",
        "lpips_fn.eval()\n",
        "\n",
        "NUM_PAIRS = 100   # >= 20 required; 100 gives nicer stats\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_lpips_pairs(fake_pool, num_pairs=100):\n",
        "    M = fake_pool.size(0)\n",
        "    pairs = []\n",
        "    scores = []\n",
        "\n",
        "    for _ in tqdm(range(num_pairs), desc=\"Computing LPIPS\"):\n",
        "        i, j = random.sample(range(M), 2)\n",
        "        x1 = fake_pool[i].unsqueeze(0).to(DEVICE)  # [1,3,64,64] in [-1,1]\n",
        "        x2 = fake_pool[j].unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        d = lpips_fn(x1, x2)  # [1,1,1,1] or [1]\n",
        "        d_val = float(d.view(-1).item())\n",
        "\n",
        "        pairs.append((i, j))\n",
        "        scores.append(d_val)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"i\": [p[0] for p in pairs],\n",
        "        \"j\": [p[1] for p in pairs],\n",
        "        \"lpips\": scores\n",
        "    }).sort_values(\"lpips\").reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "df_lpips = compute_lpips_pairs(fake_pool, NUM_PAIRS)\n",
        "df_lpips.head(), df_lpips.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b-ZAHQ1qXzxM",
      "metadata": {
        "id": "b-ZAHQ1qXzxM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision.utils import make_grid, save_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mZIFQolNXudX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZIFQolNXudX",
        "outputId": "b9d6bb88-747b-42b9-a4f4-7052a031bc01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved pairs + CSV to: /content/drive/MyDrive/gan-rl-runs/12000_iters/lpips_eval_step_10000\n",
            "CSV: /content/drive/MyDrive/gan-rl-runs/12000_iters/lpips_eval_step_10000/lpips_pairs.csv\n"
          ]
        }
      ],
      "source": [
        "OUT_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/lpips_eval_step_11500\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def denorm(x):\n",
        "    return (x * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_pair(fake_pool, i, j, fname):\n",
        "    x1 = denorm(fake_pool[i])\n",
        "    x2 = denorm(fake_pool[j])\n",
        "    grid = make_grid(torch.stack([x1, x2], dim=0), nrow=2)\n",
        "    save_image(grid, os.path.join(OUT_DIR, fname))\n",
        "\n",
        "low3 = df_lpips.iloc[:3]\n",
        "high3 = df_lpips.iloc[-3:]\n",
        "\n",
        "for k, row in enumerate(low3.itertuples(index=False), 1):\n",
        "    save_pair(fake_pool, row.i, row.j, f\"low_lpips_{k}_val_{row.lpips:.4f}.png\")\n",
        "\n",
        "for k, row in enumerate(high3.itertuples(index=False), 1):\n",
        "    save_pair(fake_pool, row.i, row.j, f\"high_lpips_{k}_val_{row.lpips:.4f}.png\")\n",
        "\n",
        "csv_path = os.path.join(OUT_DIR, \"lpips_pairs.csv\")\n",
        "df_lpips.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"Saved pairs + CSV to:\", OUT_DIR)\n",
        "print(\"CSV:\", csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "DERtMIM7X3jn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DERtMIM7X3jn",
        "outputId": "840a214b-9dca-4b5e-d239-ef10c1043f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LPIPS summary over 100 pairs\n",
            "mean: 0.1969504700601101\n",
            "std : 0.07549478722596183\n",
            "min : 0.03787526115775108\n",
            "max : 0.36592790484428406\n",
            "\n",
            "Lowest 3 pairs:\n",
            "     i    j     lpips\n",
            "0  144   80  0.037875\n",
            "1  161  184  0.045185\n",
            "2   20  160  0.047257\n",
            "\n",
            "Highest 3 pairs:\n",
            "      i    j     lpips\n",
            "97   86  141  0.341604\n",
            "98  113   96  0.347586\n",
            "99   14  194  0.365928\n"
          ]
        }
      ],
      "source": [
        "print(\"LPIPS summary over\", NUM_PAIRS, \"pairs\")\n",
        "print(\"mean:\", df_lpips[\"lpips\"].mean())\n",
        "print(\"std :\", df_lpips[\"lpips\"].std())\n",
        "print(\"min :\", df_lpips[\"lpips\"].min())\n",
        "print(\"max :\", df_lpips[\"lpips\"].max())\n",
        "\n",
        "print(\"\\nLowest 3 pairs:\")\n",
        "print(low3)\n",
        "\n",
        "print(\"\\nHighest 3 pairs:\")\n",
        "print(high3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IZYmKk_saVRW",
      "metadata": {
        "id": "IZYmKk_saVRW"
      },
      "source": [
        "## Discriminator Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oqV0HmqmaYlu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqV0HmqmaYlu",
        "outputId": "6bbdfa23-b2cb-406e-fbfb-0749be4c7eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded step: 10000\n"
          ]
        }
      ],
      "source": [
        "CKPT_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/checkpoints_64_12000_iters/checkpoints_64_12000_iters/gan_step_011500.pt\"\n",
        "\n",
        "G = models.Generator_64(z_dim=128, img_channels=3, base=64).to(DEVICE)\n",
        "D = models.Discriminator_64(img_channels=3, base=64).to(DEVICE)\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "G.load_state_dict(ckpt[\"G\"])\n",
        "D.load_state_dict(ckpt[\"D\"])\n",
        "\n",
        "G.eval(); D.eval()\n",
        "for p in G.parameters(): p.requires_grad_(False)\n",
        "for p in D.parameters(): p.requires_grad_(False)\n",
        "\n",
        "print(\"Loaded step:\", ckpt.get(\"step\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gJJbhZ11awPR",
      "metadata": {
        "id": "gJJbhZ11awPR"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Z6KhLrKXavsp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6KhLrKXavsp",
        "outputId": "a7190e45-1ba1-4fd7-eed0-ade69b526a4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[1739,  261],\n",
              "        [ 540, 1460]]),\n",
              " {'TP': 1460,\n",
              "  'TN': 1739,\n",
              "  'FP': 261,\n",
              "  'FN': 540,\n",
              "  'acc': 0.79975,\n",
              "  'real_prob_mean': 0.6446483731269836,\n",
              "  'fake_prob_mean': 0.3693080246448517})"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "Z_DIM = 128\n",
        "N_EVAL = 2000\n",
        "BATCH = 64\n",
        "THRESH = 0.5  # sigmoid threshold\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_batch_imgs(batch):\n",
        "    # Works for (img, folder_id) and (img, meta, folder_id)\n",
        "    return batch[0]\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_discriminator_confusion(dl, G, D, n_eval=2000, batch_size=64, thresh=0.5):\n",
        "    TP=TN=FP=FN=0\n",
        "    real_probs_all = []\n",
        "    fake_probs_all = []\n",
        "\n",
        "    # --- Real pass ---\n",
        "    seen = 0\n",
        "    data_iter = iter(dl)\n",
        "    while seen < n_eval:\n",
        "        batch = next(data_iter)\n",
        "        real = get_batch_imgs(batch).to(DEVICE, non_blocking=True)\n",
        "        b = min(real.size(0), n_eval - seen)\n",
        "        real = real[:b]\n",
        "        seen += b\n",
        "\n",
        "        logits = D(real)               # [b]\n",
        "        probs  = torch.sigmoid(logits) # [b]\n",
        "        real_probs_all.append(probs.detach().cpu())\n",
        "\n",
        "        pred_real = (probs >= thresh).cpu().numpy()  # predicted \"real\"?\n",
        "        # real label = 1 => TP if pred_real=1 else FN\n",
        "        TP += int(pred_real.sum())\n",
        "        FN += int((~pred_real).sum())\n",
        "\n",
        "    # --- Fake pass ---\n",
        "    seen = 0\n",
        "    while seen < n_eval:\n",
        "        b = min(batch_size, n_eval - seen)\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        fake = G(z)\n",
        "        seen += b\n",
        "\n",
        "        logits = D(fake)\n",
        "        probs  = torch.sigmoid(logits)\n",
        "        fake_probs_all.append(probs.detach().cpu())\n",
        "\n",
        "        pred_real = (probs >= thresh).cpu().numpy()\n",
        "        # fake label = 0 => FP if pred_real=1 else TN\n",
        "        FP += int(pred_real.sum())\n",
        "        TN += int((~pred_real).sum())\n",
        "\n",
        "    real_probs_all = torch.cat(real_probs_all).numpy()\n",
        "    fake_probs_all = torch.cat(fake_probs_all).numpy()\n",
        "\n",
        "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "    cm = np.array([[TN, FP],\n",
        "                   [FN, TP]])  # rows=true (0 fake,1 real), cols=pred (0 fake,1 real)\n",
        "\n",
        "    stats = {\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
        "        \"acc\": acc,\n",
        "        \"real_prob_mean\": float(real_probs_all.mean()),\n",
        "        \"fake_prob_mean\": float(fake_probs_all.mean()),\n",
        "    }\n",
        "    return cm, stats, real_probs_all, fake_probs_all\n",
        "\n",
        "cm, stats, real_probs, fake_probs = eval_discriminator_confusion(dl, G, D, n_eval=N_EVAL, batch_size=BATCH, thresh=THRESH)\n",
        "cm, stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QsJLUt66a3Cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "QsJLUt66a3Cc",
        "outputId": "cfda90e2-f5ba-4773-e0cd-b74e7fe24824"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stats: {'TP': 1460, 'TN': 1739, 'FP': 261, 'FN': 540, 'acc': 0.79975, 'real_prob_mean': 0.6446483731269836, 'fake_prob_mean': 0.3693080246448517}\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrix plot\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation=\"nearest\")\n",
        "plt.title(\"Confusion Matrix (D at step 11500)\")\n",
        "plt.xticks([0,1], [\"Pred Fake\", \"Pred Real\"])\n",
        "plt.yticks([0,1], [\"True Fake\", \"True Real\"])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, str(cm[i,j]), ha=\"center\", va=\"center\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Probability histograms\n",
        "plt.figure()\n",
        "plt.hist(real_probs, bins=30, alpha=0.7, label=\"Real (sigmoid(D))\")\n",
        "plt.hist(fake_probs, bins=30, alpha=0.7, label=\"Fake (sigmoid(D))\")\n",
        "plt.title(\"Discriminator Output Probabilities\")\n",
        "plt.xlabel(\"sigmoid(D(x))\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Stats:\", stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5_rqEb30cKGY",
      "metadata": {
        "id": "5_rqEb30cKGY"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jhrc2LXDcHu2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhrc2LXDcHu2",
        "outputId": "baf04e18-cb8c-4cff-8be2-294b5e297aaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved TP -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_10000/TP_examples.png\n",
            "Saved TN -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_10000/TN_examples.png\n",
            "Saved FP -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_10000/FP_examples.png\n",
            "Saved FN -> /content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_10000/FN_examples.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/disc_eval_step_11500\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def denorm(x): return (x*0.5 + 0.5).clamp(0,1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_examples(dl, G, D, thresh=0.5, max_each=8):\n",
        "    examples = {\"TP\": [], \"TN\": [], \"FP\": [], \"FN\": []}\n",
        "\n",
        "    # collect from real\n",
        "    for batch in dl:\n",
        "        real = get_batch_imgs(batch).to(DEVICE, non_blocking=True)\n",
        "        probs = torch.sigmoid(D(real))\n",
        "        pred_real = probs >= thresh\n",
        "        for i in range(real.size(0)):\n",
        "            if pred_real[i] and len(examples[\"TP\"]) < max_each:\n",
        "                examples[\"TP\"].append(real[i].cpu())\n",
        "            if (not pred_real[i]) and len(examples[\"FN\"]) < max_each:\n",
        "                examples[\"FN\"].append(real[i].cpu())\n",
        "        if len(examples[\"TP\"])>=max_each and len(examples[\"FN\"])>=max_each:\n",
        "            break\n",
        "\n",
        "    # collect from fake\n",
        "    while len(examples[\"TN\"]) < max_each or len(examples[\"FP\"]) < max_each:\n",
        "        b = 64\n",
        "        z = torch.randn(b, Z_DIM, device=DEVICE)\n",
        "        fake = G(z)\n",
        "        probs = torch.sigmoid(D(fake))\n",
        "        pred_real = probs >= thresh\n",
        "        for i in range(fake.size(0)):\n",
        "            if (not pred_real[i]) and len(examples[\"TN\"]) < max_each:\n",
        "                examples[\"TN\"].append(fake[i].cpu())\n",
        "            if pred_real[i] and len(examples[\"FP\"]) < max_each:\n",
        "                examples[\"FP\"].append(fake[i].cpu())\n",
        "\n",
        "    return examples\n",
        "\n",
        "ex = collect_examples(dl, G, D, THRESH, max_each=8)\n",
        "\n",
        "for k, imgs in ex.items():\n",
        "    if len(imgs) == 0:\n",
        "        continue\n",
        "    grid = torch.stack(imgs, dim=0)\n",
        "    save_image(denorm(grid), os.path.join(OUT_DIR, f\"{k}_examples.png\"), nrow=4)\n",
        "    print(\"Saved\", k, \"->\", os.path.join(OUT_DIR, f\"{k}_examples.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aEMt0wUwcvZW",
      "metadata": {
        "id": "aEMt0wUwcvZW"
      },
      "source": [
        "## Training Stability Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9uX4qmSBfQli",
      "metadata": {
        "id": "9uX4qmSBfQli"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yKkiGGZHctKb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKkiGGZHctKb",
        "outputId": "358e2529-a618-4fc9-8386-59904084bf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   step  loss_D  loss_G\n",
            "0  2510  1.2668  0.7779\n",
            "1  2520  0.8847  1.1308\n",
            "2  2530  0.8540  1.2237\n",
            "3  2540  1.2627  1.0067\n",
            "4  2550  1.3379  0.7821 \n",
            "...\n",
            "       step  loss_D  loss_G\n",
            "944  11950  1.1114  1.1692\n",
            "945  11960  1.2996  0.8227\n",
            "946  11970  0.9366  1.2292\n",
            "947  11980  1.1893  1.4127\n",
            "948  11990  0.9937  1.3253\n",
            "Parsed points: 949\n"
          ]
        }
      ],
      "source": [
        "LOG_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/gan_train.log\"\n",
        "OUT_PREFIX = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/gan_losses\"\n",
        "\n",
        "step_pat = re.compile(\n",
        "    r\"step\\s+(\\d+)\\s+\\|\\s+loss_D\\s+([0-9]*\\.?[0-9]+)\\s+\\|\\s+loss_G\\s+([0-9]*\\.?[0-9]+)\"\n",
        ")\n",
        "\n",
        "rows = []\n",
        "with open(LOG_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        m = step_pat.search(line)\n",
        "        if m:\n",
        "            step = int(m.group(1))\n",
        "            loss_d = float(m.group(2))\n",
        "            loss_g = float(m.group(3))\n",
        "            rows.append((step, loss_d, loss_g))\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"step\", \"loss_D\", \"loss_G\"]).sort_values(\"step\").drop_duplicates(\"step\")\n",
        "print(df.head(), \"\\n...\\n\", df.tail())\n",
        "print(\"Parsed points:\", len(df))\n",
        "\n",
        "# Loss_D plot\n",
        "plt.figure()\n",
        "plt.plot(df[\"step\"], df[\"loss_D\"])\n",
        "plt.xlabel(\"Training step\")\n",
        "plt.ylabel(\"Discriminator loss\")\n",
        "plt.title(\"GAN training: Discriminator loss\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_PREFIX}_lossD.png\", dpi=200)\n",
        "plt.close()\n",
        "\n",
        "# Loss_G plot\n",
        "plt.figure()\n",
        "plt.plot(df[\"step\"], df[\"loss_G\"])\n",
        "plt.xlabel(\"Training step\")\n",
        "plt.ylabel(\"Generator loss\")\n",
        "plt.title(\"GAN training: Generator loss\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_PREFIX}_lossG.png\", dpi=200)\n",
        "plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2RNAOhb7cusk",
      "metadata": {
        "id": "2RNAOhb7cusk"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Fixed Seed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zahy641Qcthk",
      "metadata": {
        "id": "Zahy641Qcthk"
      },
      "outputs": [],
      "source": [
        "\n",
        "OUT_REPRO = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/repro_eval_step_11500\"\n",
        "os.makedirs(OUT_REPRO, exist_ok=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_fixed_seed_grid(G, seed, path, n=64, nrow=8):\n",
        "    torch.manual_seed(seed)\n",
        "    z = torch.randn(n, Z_DIM, device=DEVICE)\n",
        "    x = denorm(G(z))\n",
        "    grid = make_grid(x, nrow=nrow)\n",
        "    save_image(grid, path)\n",
        "\n",
        "save_fixed_seed_grid(G, seed=2025, path=os.path.join(OUT_REPRO, \"fixed_seed_run1.png\"))\n",
        "save_fixed_seed_grid(G, seed=2025, path=os.path.join(OUT_REPRO, \"fixed_seed_run2.png\"))\n",
        "print(\"Saved reproducibility grids to:\", OUT_REPRO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QTPvfLKviQrk",
      "metadata": {
        "id": "QTPvfLKviQrk"
      },
      "source": [
        "## RL Entropy Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wO8BRy6_iYXr",
      "metadata": {
        "id": "wO8BRy6_iYXr"
      },
      "outputs": [],
      "source": [
        "LOG_PATH = \"/content/drive/MyDrive/gan-rl-runs/12000_iters/rl_train.log\"\n",
        "OUT_PREFIX = \"/content/drive/MyDrive/gan-rl-runs/12000_iters\"\n",
        "\n",
        "pat = re.compile(\n",
        "    r\"t=(\\d+)\\s*\\|\\s*eps=([0-9]*\\.?[0-9]+)\\s*\\|\\s*r=([0-9]*\\.?[0-9]+)\\s*\\|\\s*r_ma=([0-9]*\\.?[0-9]+)\\s*\\|\\s*H=([0-9]*\\.?[0-9]+)\"\n",
        ")\n",
        "\n",
        "rows = []\n",
        "with open(LOG_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        m = pat.search(line)\n",
        "        if m:\n",
        "            t = int(m.group(1))\n",
        "            eps = float(m.group(2))\n",
        "            r = float(m.group(3))\n",
        "            r_ma = float(m.group(4))\n",
        "            H = float(m.group(5))\n",
        "            rows.append((t, eps, r, r_ma, H))\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"t\", \"eps\", \"r\", \"r_ma\", \"H\"]).sort_values(\"t\").drop_duplicates(\"t\")\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(df[\"t\"], df[\"H\"])\n",
        "plt.xlabel(\"t\")\n",
        "plt.ylabel(\"entropy (H)\")\n",
        "plt.title(\"Policy Entropy\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUT_PREFIX}_entropy.png\", dpi=200)\n",
        "plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
